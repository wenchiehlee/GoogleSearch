"""
GoogleSearch.py - Multi-Query PDF Search and Conversion Tool

Version: 2.0.0
Date: 2025-06-19
Author: Generated by ChatGPT based on instructions
License: MIT

Description:
    A comprehensive tool for searching, downloading, and converting PDF documents
    using Google Custom Search API and Microsoft Markitdown conversion.

Version History:
    v1.0.0 (Initial) - Basic Google search with single query support
    v1.1.0 - Added PDF download functionality
    v1.2.0 - Added Markitdown conversion support
    v2.0.0 - Multi-query support, enhanced error handling, improved structure

Dependencies:
    - requests
    - python-dotenv
    - markitdown (external tool)
"""

import requests
import os
import csv
from urllib.parse import urlparse, unquote, parse_qs
from dotenv import load_dotenv
import subprocess  # For executing Markitdown command
import platform  # For platform-specific logic

# Version Information
__version__ = "2.0.0"
__date__ = "2025-06-19"
__author__ = "Generated by ChatGPT"

# Load environment variables
load_dotenv()

GOOGLE_SEARCH_API_KEY = os.getenv("GOOGLE_SEARCH_API_KEY")
GOOGLE_SEARCH_CSE_ID = os.getenv("GOOGLE_SEARCH_CSE_ID")
os.environ["PYTHONIOENCODING"] = "utf-8"

def is_markitdown_valid():
    """
    Check if the Markitdown command is available on the system.

    Returns:
        bool: True if Markitdown is available, False otherwise.
    """
    command = "where" if platform.system() == "Windows" else "which"
    try:
        # result = subprocess.run(
        #     [command, "markitdown"],
        #     stdout=subprocess.PIPE,
        #     stderr=subprocess.PIPE,
        #     check=True,
        #     shell=True
        # )
        # return result.returncode == 0
        return True
    except subprocess.CalledProcessError as e:
        print(f"Error: Markitdown is not available. Please ensure it is installed and accessible in your PATH. {e}")
        return False

def google_search(api_key, cse_id, query, num_results=10, max_results=500, last_days=180, language="lang_zh-TW", country="countryTW"):
    """
    Perform a Google Custom Search using the Custom Search JSON API.

    Args:
        api_key (str): Your Google API key.
        cse_id (str): Your Custom Search Engine ID.
        query (str): The search query.
        num_results (int): Number of results per request (max is 10).
        max_results (int): Maximum total results to retrieve (default is 500).
        last_days (int): Number of days to restrict the search to recent results.
        language (str): Language filter.
        country (str): Country restriction.

    Returns:
        list: A list of search results.
    """
    url = "https://www.googleapis.com/customsearch/v1"
    results = []
    date_limit = f"d{last_days}"

    for start in range(1, max_results + 1, num_results):
        params = {
            "key": api_key,
            "cx": cse_id,
            "q": query,
            "num": num_results,
            "start": start,
            "dateRestrict": date_limit,
            "sort": "date",
            "lr": language,
            "cr": country
        }
        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            if "items" in data:
                results.extend(data["items"])
            else:
                print("No more results.")
                break
        else:
            print(f"Error: {response.status_code}, {response.text}")
            break
        if len(results) >= max_results:
            break
    return results[:max_results]

def save_results_to_csv(results, filename):
    """
    Save search results to a CSV file.

    Args:
        results (list): A list of search result items.
        filename (str): Name of the output CSV file.
    """
    with open(filename, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.DictWriter(file, fieldnames=["Title", "Link", "Snippet", "File", "MD File"])
        writer.writeheader()
        for item in results:
            writer.writerow({
                "Title": item.get("title"),
                "Link": item.get("link"),
                "Snippet": item.get("snippet"),
                "File": "",
                "MD File": ""
            })

def download_files_from_links_and_convert(csv_filename):
    """
    Download files from links in the CSV, convert PDFs to Markdown, and update the "File" and "MD File" columns.

    Args:
        csv_filename (str): Name of the input/output CSV file.
    """
    if not is_markitdown_valid():
        print("Markitdown is not installed or cannot be found. Exiting.")
        return

    with open(csv_filename, mode="r", newline="", encoding="utf-8") as file:
        reader = csv.DictReader(file)
        rows = list(reader)

    total_rows = len(rows)
    print(f"Total rows to process for {csv_filename}: {total_rows}")

    pdf_counter = 1

    for index, row in enumerate(rows):
        link = row["Link"]
        if link:
            try:
                decoded_link = unquote(link)
                if decoded_link.lower().endswith(".pdf") or "fileredirect.aspx" in decoded_link:
                    response = requests.get(link, stream=True, allow_redirects=True)
                    if response.status_code == 200:
                        final_url = response.url
                        parsed_url = urlparse(final_url)
                        if "fileredirect.aspx" in parsed_url.path:
                            query_params = parse_qs(parsed_url.query)
                            if "Path" in query_params:
                                clean_path = unquote(query_params["Path"][0])
                                filename = os.path.basename(clean_path)
                                filepath = os.path.join("PDF", filename)
                                os.makedirs("PDF", exist_ok=True)
                            else:
                                filepath = os.path.join("PDF", f"pdf{pdf_counter}.pdf")
                                pdf_counter += 1
                        else:
                            filename = os.path.basename(parsed_url.path) or f"pdf{pdf_counter}.pdf"
                            filepath = os.path.join("PDF", filename)
                            os.makedirs("PDF", exist_ok=True)
                            pdf_counter += 1

                        with open(filepath, "wb") as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                        row["File"] = filepath

                        md_filepath = os.path.join("MD", os.path.basename(filepath).replace(".pdf", ".md"))
                        os.makedirs("MD", exist_ok=True)
                        try:
                            with open(md_filepath, "w", encoding="utf-8") as md_file:
                                subprocess.run([
                                    "markitdown", filepath
                                ], stdout=md_file, check=True)
                            row["MD File"] = md_filepath
                        except subprocess.CalledProcessError as e:
                            print(f"Error converting {filepath} to Markdown: {e}")
                            row["MD File"] = ""
                    else:
                        print(f"Failed to download {link}: {response.status_code}")
                else:
                    print(f"Skipped non-PDF link: {link}")
                    row["File"] = ""
                    row["MD File"] = ""
            except Exception as e:
                print(f"Error processing {link}: {e}")

        print(f"Processed row {index + 1} of {total_rows} for {csv_filename}")

    with open(csv_filename, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.DictWriter(file, fieldnames=["Title", "Link", "Snippet", "File", "MD File"])
        writer.writeheader()
        writer.writerows(rows)

def process_search_query(query, output_filename, description):
    """
    Process a single search query: search, save to CSV, download PDFs, and convert to Markdown.
    
    Args:
        query (str): The search query string.
        output_filename (str): The CSV filename to save results to.
        description (str): Description of the search for logging purposes.
    """
    print(f"\n{'='*60}")
    print(f"Starting {description}")
    print(f"Query: {query}")
    print(f"Output file: {output_filename}")
    print(f"{'='*60}")
    
    search_results = google_search(GOOGLE_SEARCH_API_KEY, GOOGLE_SEARCH_CSE_ID, query, max_results=500, last_days=360)
    
    if search_results:
        print(f"Found {len(search_results)} results for {description}")
        save_results_to_csv(search_results, output_filename)
        print(f"Saved search results to {output_filename}")
        download_files_from_links_and_convert(output_filename)
        print(f"Completed processing for {description}")
    else:
        print(f"No search results found for {description}")

def main():
    """
    Main function to execute all search queries and processing.
    """
    print(f"GoogleSearch.py v{__version__} - Multi-Query PDF Search and Conversion Tool")
    print(f"Date: {__date__} | Author: {__author__}")
    print("=" * 80)
    
    # Check if API credentials are available
    if not GOOGLE_SEARCH_API_KEY or not GOOGLE_SEARCH_CSE_ID:
        print("Error: Missing Google Search API credentials.")
        print("Please ensure GOOGLE_SEARCH_API_KEY and GOOGLE_SEARCH_CSE_ID are set in your .env file.")
        return
    
    # Check if Markitdown is available
    if not is_markitdown_valid():
        print("Error: Markitdown is not available. Please install it before proceeding.")
        return
    
    # Define search queries
    search_queries = [
        {
            "query": "得標統計表 T004 -公司債 filetype:pdf",
            "filename": "GoogleResults.csv",
            "description": "Financial Documents Search (得標統計表 T004)"
        },
        {
            "query": "FactSet filetype:pdf",
            "filename": "FactSetResults.csv", 
            "description": "FactSet Documents Search"
        }
    ]
    
    # Process each search query
    for search_config in search_queries:
        try:
            process_search_query(
                search_config["query"],
                search_config["filename"],
                search_config["description"]
            )
        except Exception as e:
            print(f"Error processing {search_config['description']}: {e}")
            continue
    
    print(f"\n{'='*60}")
    print("All search queries completed!")
    print("Generated files:")
    for search_config in search_queries:
        if os.path.exists(search_config["filename"]):
            print(f"- {search_config['filename']}")
    print("- PDF/ (downloaded PDF files)")
    print("- MD/ (converted Markdown files)")
    print(f"{'='*60}")
    print(f"GoogleSearch.py v{__version__} - Process completed successfully!")

# Execute the main function when script is run directly
if __name__ == "__main__":
    main()