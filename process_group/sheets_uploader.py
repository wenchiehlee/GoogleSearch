#!/usr/bin/env python3
"""
Sheets Uploader - FactSet Pipeline v3.5.1 (CSV Validation Summary Solution)
å®Œæ•´è§£æ±ºæ–¹æ¡ˆï¼šç”Ÿæˆ CSV é©—è­‰æ‘˜è¦æª”æ¡ˆï¼Œé¿å… Google Sheets API æ ¼å¼å•é¡Œ
å¢å¼·å°è§€å¯Ÿåå–®é©—è­‰çš„æ”¯æ´ï¼Œæ›´å¥½åœ°è™•ç†é©—è­‰ç‹€æ…‹
"""

import os
import gspread
import pandas as pd
import math
from datetime import datetime
from typing import Dict, Any, List, Optional
from google.oauth2.service_account import Credentials
import json

# ğŸ”§ è¼‰å…¥ç’°å¢ƒè®Šæ•¸
try:
    from dotenv import load_dotenv
    # è¼‰å…¥ .env æª”æ¡ˆ - å˜—è©¦å¤šå€‹è·¯å¾‘
    env_paths = [
        '.env',
        '../.env', 
        '../../.env',
        os.path.join(os.path.dirname(__file__), '.env'),
        os.path.join(os.path.dirname(__file__), '../.env')
    ]
    
    for env_path in env_paths:
        if os.path.exists(env_path):
            load_dotenv(env_path)
            break
except ImportError:
    pass

class SheetsUploader:
    """Google Sheets ä¸Šå‚³å™¨ v3.5.1 - CSV é©—è­‰æ‘˜è¦è§£æ±ºæ–¹æ¡ˆ"""
    
    def __init__(self, github_repo_base="https://raw.githubusercontent.com/wenchiehlee/GoogleSearch/refs/heads/main"):
        self.github_repo_base = github_repo_base
        self.client = None
        self.spreadsheet = None
        self.sheet_id = os.getenv('GOOGLE_SHEET_ID')
        
        # ğŸ”§ v3.5.1 æ›´æ–°çš„é©—è­‰è¨­å®š
        self.validation_settings = {
            'check_before_upload': True,
            'allow_warning_data': True,
            'allow_error_data': False,
            'max_validation_errors': 5,
            'skip_not_block': True,
            'enhanced_validation': True,
            'generate_validation_csv': True,      # ğŸ†• ç”Ÿæˆé©—è­‰æ‘˜è¦ CSV
            'upload_validation_to_sheets': True,  # ğŸ†• ä¸Šå‚³é©—è­‰æ‘˜è¦åˆ° Sheetsï¼ˆç°¡åŒ–ç‰ˆï¼‰
            'csv_output_dir': 'data/reports'      # ğŸ†• CSV è¼¸å‡ºç›®éŒ„
        }
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(self.validation_settings['csv_output_dir'], exist_ok=True)

    def _clean_stock_code(self, code):
        """æ¸…ç†è‚¡ç¥¨ä»£è™Ÿæ ¼å¼"""
        if pd.isna(code) or code is None:
            return ''
        
        code_str = str(code).strip()
        
        if code_str.startswith("'"):
            code_str = code_str[1:]
        
        if code_str.isdigit() and len(code_str) == 4:
            return int(code_str)
        
        if '-TW' in code_str:
            parts = code_str.split('-TW')
            if len(parts) == 2 and parts[0].isdigit() and len(parts[0]) == 4:
                return f"{int(parts[0])}-TW"
        
        return code_str
        
    def upload_reports(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame) -> bool:
        """ğŸ”§ v3.5.1 ä¸»è¦ä¸Šå‚³æ–¹æ³• - åŒ…å« CSV é©—è­‰æ‘˜è¦"""
        try:
            # ğŸ”§ ä¸Šå‚³å‰é©—è­‰
            if self.validation_settings['check_before_upload']:
                validation_result = self._validate_before_upload_v351(portfolio_df, detailed_df)
                
                if not validation_result['safe_to_upload']:
                    print(f"ğŸš¨ ä¸Šå‚³é©—è­‰å¤±æ•—: {validation_result['reason']}")
                    print(f"ğŸ“Š å•é¡Œæ‘˜è¦: {validation_result['summary']}")
                    
                    if validation_result['severity'] == 'critical':
                        print("âŒ ç™¼ç¾é—œéµå•é¡Œï¼Œåœæ­¢ä¸Šå‚³")
                        return False
                    elif validation_result['severity'] == 'warning' and not self._ask_force_upload():
                        print("âŒ å–æ¶ˆä¸Šå‚³")
                        return False
                    else:
                        print("âš ï¸ å¿½ç•¥è­¦å‘Šï¼Œç¹¼çºŒä¸Šå‚³")
                else:
                    if validation_result.get('reason'):
                        print(f"ğŸ“Š é©—è­‰çµ±è¨ˆ: {validation_result['reason']}")
                        print(f"ğŸ“Š å•é¡Œæ‘˜è¦: {validation_result['summary']}")
                    else:
                        print("âœ… ä¸Šå‚³å‰é©—è­‰é€šé")
            
            # è¨­å®šé€£ç·š
            if not self._setup_connection():
                print("âŒ Google Sheets é€£ç·šå¤±æ•—")
                return False
            
            # æ¨™è¨˜å•é¡Œè³‡æ–™
            portfolio_df_marked = self._mark_problematic_data_v351(portfolio_df)
            detailed_df_marked = self._mark_problematic_data_v351(detailed_df)
            
            # ä¸Šå‚³æŠ•è³‡çµ„åˆæ‘˜è¦
            if not self._upload_portfolio_summary(portfolio_df_marked):
                print("âŒ æŠ•è³‡çµ„åˆæ‘˜è¦ä¸Šå‚³å¤±æ•—")
                return False
            
            # ä¸Šå‚³è©³ç´°å ±å‘Š
            if not self._upload_detailed_report(detailed_df_marked):
                print("âŒ è©³ç´°å ±å‘Šä¸Šå‚³å¤±æ•—")
                return False
            
            # ğŸ†• è™•ç†é©—è­‰æ‘˜è¦ - CSV ç”Ÿæˆå’Œå¯é¸çš„ Sheets ä¸Šå‚³
            self._handle_validation_summary(portfolio_df, detailed_df)
            
            print("âœ… æ‰€æœ‰å ±å‘Šä¸Šå‚³æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ ä¸Šå‚³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def _handle_validation_summary(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame):
        """ğŸ†• è™•ç†é©—è­‰æ‘˜è¦ - ç”Ÿæˆ CSV å’Œå¯é¸çš„ Sheets ä¸Šå‚³"""
        try:
            # 1. ç”Ÿæˆé©—è­‰æ‘˜è¦æ•¸æ“š
            validation_data = self._generate_validation_summary_data(portfolio_df, detailed_df)
            
            # 2. ç”Ÿæˆ CSV æª”æ¡ˆ
            if self.validation_settings.get('generate_validation_csv', True):
                csv_file = self._save_validation_summary_csv(validation_data)
                if csv_file:
                    print(f"ğŸ“Š é©—è­‰æ‘˜è¦ CSV å·²ç”Ÿæˆ: {csv_file}")
            
            # 3. å˜—è©¦ä¸Šå‚³åˆ° Google Sheetsï¼ˆç°¡åŒ–ç‰ˆï¼Œç„¡æ ¼å¼è¨­å®šï¼‰
            if self.validation_settings.get('upload_validation_to_sheets', True):
                try:
                    self._upload_validation_summary_simple(validation_data)
                    print("ğŸ“Š é©—è­‰æ‘˜è¦å·²ä¸Šå‚³åˆ° Google Sheets")
                except Exception as e:
                    print(f"âš ï¸ Google Sheets é©—è­‰æ‘˜è¦ä¸Šå‚³å¤±æ•—: {e}")
                    print("ğŸ’¡ ä½† CSV æª”æ¡ˆå·²ç”Ÿæˆï¼Œå¯æ‰‹å‹•ä¸Šå‚³")
            
        except Exception as e:
            print(f"âš ï¸ é©—è­‰æ‘˜è¦è™•ç†å¤±æ•—: {e}")

    def _generate_validation_summary_data(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame) -> pd.DataFrame:
        """ğŸ†• ç”Ÿæˆé©—è­‰æ‘˜è¦æ•¸æ“šç‚º DataFrame"""
        summary_rows = []
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # åŸºæœ¬çµ±è¨ˆ
        summary_rows.append({
            'é …ç›®': 'ç¸½å…¬å¸æ•¸',
            'æ•¸å€¼': len(portfolio_df),
            'èªªæ˜': 'æŠ•è³‡çµ„åˆä¸­çš„å…¬å¸ç¸½æ•¸',
            'è©³ç´°è³‡è¨Š': f'è©³ç´°è¨˜éŒ„: {len(detailed_df)}',
            'æ›´æ–°æ™‚é–“': current_time
        })
        
        # é©—è­‰ç‹€æ…‹çµ±è¨ˆ
        if 'é©—è­‰ç‹€æ…‹' in detailed_df.columns:
            validation_counts = detailed_df['é©—è­‰ç‹€æ…‹'].value_counts()
            
            # åˆ†é¡çµ±è¨ˆ
            passed_count = 0
            warning_count = 0
            disabled_count = 0
            critical_count = 0
            
            for status, count in validation_counts.items():
                status_str = str(status)
                if 'âœ…' in status_str:
                    passed_count += count
                elif 'âš ï¸ é©—è­‰åœç”¨' in status_str:
                    disabled_count += count
                elif 'âš ï¸' in status_str:
                    warning_count += count
                elif any(marker in status_str for marker in ['âŒ', 'ğŸš«', 'ğŸ“', 'ğŸ”„']):
                    critical_count += count
            
            # è©³ç´°é©—è­‰çµ±è¨ˆ
            total_records = len(detailed_df)
            summary_rows.extend([
                {
                    'é …ç›®': 'é©—è­‰é€šé',
                    'æ•¸å€¼': passed_count,
                    'èªªæ˜': 'é€šéå…§å®¹é©—è­‰çš„è¨˜éŒ„æ•¸',
                    'è©³ç´°è³‡è¨Š': f'æˆåŠŸç‡: {passed_count/total_records*100:.1f}%',
                    'æ›´æ–°æ™‚é–“': current_time
                },
                {
                    'é …ç›®': 'é©—è­‰åœç”¨',
                    'æ•¸å€¼': disabled_count,
                    'èªªæ˜': 'å› è§€å¯Ÿåå–®æœªè¼‰å…¥è€Œåœç”¨é©—è­‰',
                    'è©³ç´°è³‡è¨Š': 'é€™äº›å…¬å¸ä»æœƒåŒ…å«åœ¨å ±å‘Šä¸­',
                    'æ›´æ–°æ™‚é–“': current_time
                },
                {
                    'é …ç›®': 'é©—è­‰è­¦å‘Š',
                    'æ•¸å€¼': warning_count,
                    'èªªæ˜': 'æœ‰é©—è­‰è­¦å‘Šçš„è¨˜éŒ„æ•¸',
                    'è©³ç´°è³‡è¨Š': 'éœ€è¦äººå·¥æª¢æŸ¥',
                    'æ›´æ–°æ™‚é–“': current_time
                },
                {
                    'é …ç›®': 'é—œéµå•é¡Œ',
                    'æ•¸å€¼': critical_count,
                    'èªªæ˜': 'åš´é‡é©—è­‰å•é¡Œçš„è¨˜éŒ„æ•¸',
                    'è©³ç´°è³‡è¨Š': 'æ‡‰å·²è¢«éæ¿¾æ’é™¤',
                    'æ›´æ–°æ™‚é–“': current_time
                }
            ])
            
            # é©—è­‰å“è³ªæŒ‡æ¨™
            total_validation_active = total_records - disabled_count
            if total_validation_active > 0:
                validation_quality = (passed_count / total_validation_active) * 100
                summary_rows.append({
                    'é …ç›®': 'é©—è­‰å“è³ª',
                    'æ•¸å€¼': f'{validation_quality:.1f}%',
                    'èªªæ˜': 'å•Ÿç”¨é©—è­‰ä¸­çš„é€šéç‡',
                    'è©³ç´°è³‡è¨Š': f'æ´»èºé©—è­‰: {total_validation_active}',
                    'æ›´æ–°æ™‚é–“': current_time
                })
        
        # å“è³ªçµ±è¨ˆ
        if 'å“è³ªè©•åˆ†' in detailed_df.columns:
            quality_scores = detailed_df['å“è³ªè©•åˆ†'].dropna()
            if not quality_scores.empty:
                avg_quality = quality_scores.mean()
                high_quality = len(quality_scores[quality_scores >= 8.0])
                low_quality = len(quality_scores[quality_scores <= 3.0])
                zero_quality = len(quality_scores[quality_scores == 0.0])
                
                quality_rows = [
                    {
                        'é …ç›®': 'å¹³å‡å“è³ªè©•åˆ†',
                        'æ•¸å€¼': f'{avg_quality:.1f}',
                        'èªªæ˜': 'æ‰€æœ‰è¨˜éŒ„çš„å¹³å‡å“è³ªè©•åˆ†',
                        'è©³ç´°è³‡è¨Š': f'æœ€é«˜: {quality_scores.max():.1f}, æœ€ä½: {quality_scores.min():.1f}',
                        'æ›´æ–°æ™‚é–“': current_time
                    },
                    {
                        'é …ç›®': 'é«˜å“è³ªè¨˜éŒ„',
                        'æ•¸å€¼': high_quality,
                        'èªªæ˜': 'å“è³ªè©•åˆ† â‰¥ 8.0 çš„è¨˜éŒ„æ•¸',
                        'è©³ç´°è³‡è¨Š': f'ä½”æ¯”: {high_quality/len(quality_scores)*100:.1f}%',
                        'æ›´æ–°æ™‚é–“': current_time
                    },
                    {
                        'é …ç›®': 'ä½å“è³ªè¨˜éŒ„',
                        'æ•¸å€¼': low_quality,
                        'èªªæ˜': 'å“è³ªè©•åˆ† â‰¤ 3.0 çš„è¨˜éŒ„æ•¸',
                        'è©³ç´°è³‡è¨Š': f'ä½”æ¯”: {low_quality/len(quality_scores)*100:.1f}%',
                        'æ›´æ–°æ™‚é–“': current_time
                    }
                ]
                
                summary_rows.extend(quality_rows)
                
                if zero_quality > 0:
                    summary_rows.append({
                        'é …ç›®': 'é›¶åˆ†è¨˜éŒ„',
                        'æ•¸å€¼': zero_quality,
                        'èªªæ˜': 'å“è³ªè©•åˆ†ç‚º 0 çš„è¨˜éŒ„æ•¸',
                        'è©³ç´°è³‡è¨Š': 'é€šå¸¸è¡¨ç¤ºé©—è­‰å¤±æ•—',
                        'æ›´æ–°æ™‚é–“': current_time
                    })
        
        # ç³»çµ±å¥åº·åº¦æŒ‡æ¨™
        system_health = self._calculate_system_health(detailed_df)
        summary_rows.append({
            'é …ç›®': 'ç³»çµ±å¥åº·åº¦',
            'æ•¸å€¼': f'{system_health:.1f}%',
            'èªªæ˜': 'æ•´é«”è³‡æ–™è™•ç†å“è³ªæŒ‡æ¨™',
            'è©³ç´°è³‡è¨Š': 'ç¶œåˆé©—è­‰å’Œå“è³ªè©•åˆ†',
            'æ›´æ–°æ™‚é–“': current_time
        })
        
        # é¡å¤–çš„é©—è­‰ç‹€æ…‹è©³ç´°åˆ†è§£
        if 'é©—è­‰ç‹€æ…‹' in detailed_df.columns:
            status_breakdown = detailed_df['é©—è­‰ç‹€æ…‹'].value_counts()
            for status, count in status_breakdown.items():
                if count > 0:
                    summary_rows.append({
                        'é …ç›®': f'ç‹€æ…‹è©³ç´°: {status}',
                        'æ•¸å€¼': count,
                        'èªªæ˜': f'å…·æœ‰ã€Œ{status}ã€ç‹€æ…‹çš„è¨˜éŒ„æ•¸',
                        'è©³ç´°è³‡è¨Š': f'ä½”ç¸½æ•¸ {count/len(detailed_df)*100:.1f}%',
                        'æ›´æ–°æ™‚é–“': current_time
                    })
        
        return pd.DataFrame(summary_rows)

    def _save_validation_summary_csv(self, validation_df: pd.DataFrame) -> str:
        """ğŸ†• å„²å­˜é©—è­‰æ‘˜è¦ç‚º CSV æª”æ¡ˆ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            csv_filename = f'validation_summary_{timestamp}.csv'
            csv_path = os.path.join(self.validation_settings['csv_output_dir'], csv_filename)
            
            # å„²å­˜ CSV
            validation_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            # åŒæ™‚å„²å­˜æœ€æ–°ç‰ˆæœ¬
            latest_csv_path = os.path.join(self.validation_settings['csv_output_dir'], 'validation_summary_latest.csv')
            validation_df.to_csv(latest_csv_path, index=False, encoding='utf-8-sig')
            
            return csv_path
            
        except Exception as e:
            print(f"âŒ å„²å­˜é©—è­‰æ‘˜è¦ CSV å¤±æ•—: {e}")
            return ""

    def _upload_validation_summary_simple(self, validation_df: pd.DataFrame):
        """ğŸ†• ç°¡åŒ–ç‰ˆé©—è­‰æ‘˜è¦ä¸Šå‚³ - åªä¸Šå‚³æ•¸æ“šï¼Œä¸è¨­å®šæ ¼å¼"""
        try:
            # å˜—è©¦æ‰¾åˆ°æˆ–å»ºç«‹é©—è­‰æ‘˜è¦å·¥ä½œè¡¨
            try:
                validation_worksheet = self.spreadsheet.worksheet("é©—è­‰æ‘˜è¦")
            except gspread.WorksheetNotFound:
                print("ğŸ“Š å»ºç«‹é©—è­‰æ‘˜è¦å·¥ä½œè¡¨...")
                validation_worksheet = self.spreadsheet.add_worksheet(title="é©—è­‰æ‘˜è¦", rows=200, cols=10)
            
            # æ¸…ç©ºç¾æœ‰å…§å®¹
            validation_worksheet.clear()
            
            # æº–å‚™æ•¸æ“š
            headers = validation_df.columns.tolist()
            data = validation_df.values.tolist()
            
            # ç¢ºä¿æ‰€æœ‰æ•¸æ“šéƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…æ ¼å¼å•é¡Œ
            clean_data = []
            for row in data:
                clean_row = []
                for cell in row:
                    if pd.isna(cell):
                        clean_row.append('')
                    else:
                        clean_row.append(str(cell))
                clean_data.append(clean_row)
            
            # ä¸Šå‚³æ¨™é¡Œ
            validation_worksheet.update('A1', [headers])
            
            # ä¸Šå‚³æ•¸æ“š
            if clean_data:
                validation_worksheet.update('A2', clean_data)
            
            # ğŸ”§ åªè¨­å®šæœ€åŸºæœ¬çš„æ¨™é¡Œæ ¼å¼ï¼Œé¿å… columnWidth å•é¡Œ
            try:
                validation_worksheet.format('A1:E1', {
                    'textFormat': {'bold': True}
                })
            except:
                # å¦‚æœé€£åŸºæœ¬æ ¼å¼éƒ½å¤±æ•—ï¼Œå°±å®Œå…¨è·³éæ ¼å¼è¨­å®š
                pass
            
        except Exception as e:
            raise Exception(f"ç°¡åŒ–ä¸Šå‚³å¤±æ•—: {e}")

    def _validate_before_upload_v351(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame) -> Dict[str, Any]:
        """ğŸ”§ v3.5.1 å¢å¼·çš„ä¸Šå‚³å‰é©—è­‰æª¢æŸ¥"""
        validation_result = {
            'safe_to_upload': True,
            'reason': '',
            'summary': {},
            'issues': [],
            'severity': 'info'
        }
        
        if portfolio_df.empty:
            validation_result['safe_to_upload'] = False
            validation_result['reason'] = 'æŠ•è³‡çµ„åˆæ‘˜è¦ç‚ºç©º'
            validation_result['severity'] = 'critical'
            return validation_result
        
        if detailed_df.empty:
            validation_result['safe_to_upload'] = False
            validation_result['reason'] = 'è©³ç´°å ±å‘Šç‚ºç©º'
            validation_result['severity'] = 'critical'
            return validation_result
        
        # é©—è­‰ç‹€æ…‹åˆ†æ
        validation_issues = []
        critical_issues = 0
        warning_issues = 0
        validation_disabled_count = 0
        
        if 'é©—è­‰ç‹€æ…‹' in detailed_df.columns:
            for idx, row in detailed_df.iterrows():
                validation_status = str(row.get('é©—è­‰ç‹€æ…‹', ''))
                company_name = row.get('åç¨±', 'Unknown')
                company_code = row.get('ä»£è™Ÿ', 'Unknown')
                
                if 'ğŸš«' in validation_status or 'âŒ' in validation_status:
                    critical_issues += 1
                    validation_issues.append({
                        'company': f"{company_name}({company_code})",
                        'type': 'critical',
                        'status': validation_status
                    })
                elif 'âš ï¸' in validation_status:
                    if 'é©—è­‰åœç”¨' in validation_status:
                        validation_disabled_count += 1
                    else:
                        warning_issues += 1
                    validation_issues.append({
                        'company': f"{company_name}({company_code})",
                        'type': 'warning',
                        'status': validation_status
                    })
        
        total_companies = len(detailed_df)
        validation_result['summary'] = {
            'total_companies': total_companies,
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'validation_disabled': validation_disabled_count,
            'validation_issues': len(validation_issues)
        }
        
        validation_result['issues'] = validation_issues
        
        if self.validation_settings.get('enhanced_validation', False):
            if critical_issues > 0:
                validation_result['safe_to_upload'] = False
                validation_result['severity'] = 'critical'
                validation_result['reason'] = f'ç™¼ç¾ {critical_issues} å€‹é—œéµé©—è­‰å•é¡Œ'
            elif warning_issues > total_companies * 0.5:
                validation_result['safe_to_upload'] = False
                validation_result['severity'] = 'warning'
                validation_result['reason'] = f'è­¦å‘Šå•é¡Œéå¤š: {warning_issues}/{total_companies}'
            else:
                validation_result['safe_to_upload'] = True
                if validation_disabled_count > 0 or warning_issues > 0:
                    validation_result['reason'] = f'ç™¼ç¾ {warning_issues} å€‹è­¦å‘Šã€{validation_disabled_count} å€‹é©—è­‰åœç”¨ï¼Œå°‡ç¹¼çºŒä¸Šå‚³'
                    validation_result['severity'] = 'info'
        
        return validation_result

    def _mark_problematic_data_v351(self, df: pd.DataFrame) -> pd.DataFrame:
        """ğŸ”§ v3.5.1 å¢å¼·çš„å•é¡Œè³‡æ–™æ¨™è¨˜"""
        df_marked = df.copy()
        
        if 'é©—è­‰ç‹€æ…‹' in df_marked.columns and 'åç¨±' in df_marked.columns:
            for idx, row in df_marked.iterrows():
                validation_status = str(row.get('é©—è­‰ç‹€æ…‹', ''))
                company_name = str(row.get('åç¨±', ''))
                
                if 'ğŸš«' in validation_status:
                    df_marked.at[idx, 'åç¨±'] = f"ğŸš« {company_name}"
                elif 'âŒ' in validation_status:
                    df_marked.at[idx, 'åç¨±'] = f"âŒ {company_name}"
                elif 'ğŸ“' in validation_status:
                    df_marked.at[idx, 'åç¨±'] = f"ğŸ“ {company_name}"
                elif 'ğŸ”„' in validation_status:
                    df_marked.at[idx, 'åç¨±'] = f"ğŸ”„ {company_name}"
                elif 'âš ï¸ é©—è­‰åœç”¨' in validation_status:
                    df_marked.at[idx, 'åç¨±'] = f"âš ï¸ {company_name}"
                elif 'âš ï¸' in validation_status:
                    df_marked.at[idx, 'åç¨±'] = f"âš ï¸ {company_name}"
        
        if 'å“è³ªè©•åˆ†' in df_marked.columns and 'åç¨±' in df_marked.columns:
            for idx, row in df_marked.iterrows():
                quality_score = row.get('å“è³ªè©•åˆ†', 10)
                company_name = str(row.get('åç¨±', ''))
                
                if not any(marker in company_name for marker in ['ğŸš«', 'âŒ', 'ğŸ“', 'ğŸ”„', 'âš ï¸']):
                    if quality_score <= 2.0:
                        df_marked.at[idx, 'åç¨±'] = f"ğŸ”´ {company_name}"
        
        return df_marked

    def _calculate_system_health(self, detailed_df: pd.DataFrame) -> float:
        """ğŸ”§ v3.5.1 è¨ˆç®—ç³»çµ±å¥åº·åº¦æŒ‡æ¨™"""
        if detailed_df.empty:
            return 0.0
        
        health_score = 100.0
        
        if 'é©—è­‰ç‹€æ…‹' in detailed_df.columns:
            validation_counts = detailed_df['é©—è­‰ç‹€æ…‹'].value_counts()
            total_records = len(detailed_df)
            
            critical_issues = sum(count for status, count in validation_counts.items() 
                                if any(marker in str(status) for marker in ['âŒ', 'ğŸš«']))
            
            if critical_issues > 0:
                health_score -= (critical_issues / total_records) * 40
        
        if 'å“è³ªè©•åˆ†' in detailed_df.columns:
            quality_scores = detailed_df['å“è³ªè©•åˆ†'].dropna()
            if not quality_scores.empty:
                avg_quality = quality_scores.mean()
                quality_health = (avg_quality / 10) * 60
                health_score = health_score * 0.4 + quality_health
        
        return max(0.0, min(100.0, health_score))

    def _ask_force_upload(self) -> bool:
        """è©¢å•æ˜¯å¦å¼·åˆ¶ä¸Šå‚³"""
        return False

    def test_connection(self) -> bool:
        """æ¸¬è©¦ Google Sheets é€£ç·š"""
        try:
            if self._setup_connection():
                spreadsheet_info = self.spreadsheet.title
                print(f"âœ… Google Sheets é€£ç·šæˆåŠŸ: {spreadsheet_info}")
                return True
            else:
                print("âŒ Google Sheets é€£ç·šå¤±æ•—")
                return False
        except Exception as e:
            print(f"âŒ Google Sheets é€£ç·šæ¸¬è©¦å¤±æ•—: {e}")
            return False

    def _setup_connection(self) -> bool:
        """è¨­å®š Google Sheets é€£ç·š"""
        try:
            if not self.sheet_id:
                print("âŒ æœªè¨­å®š GOOGLE_SHEET_ID ç’°å¢ƒè®Šæ•¸")
                return False
            
            credentials_json = os.getenv('GOOGLE_SHEETS_CREDENTIALS')
            if not credentials_json:
                print("âŒ æœªè¨­å®š GOOGLE_SHEETS_CREDENTIALS ç’°å¢ƒè®Šæ•¸")
                return False
            
            credentials_info = json.loads(credentials_json)
            
            scopes = [
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/drive'
            ]
            
            credentials = Credentials.from_service_account_info(
                credentials_info, scopes=scopes
            )
            
            self.client = gspread.authorize(credentials)
            self.spreadsheet = self.client.open_by_key(self.sheet_id)
            
            return True
            
        except Exception as e:
            print(f"âŒ Google Sheets é€£ç·šè¨­å®šå¤±æ•—: {e}")
            return False

    def _upload_portfolio_summary(self, portfolio_df: pd.DataFrame) -> bool:
        """ä¸Šå‚³æŠ•è³‡çµ„åˆæ‘˜è¦"""
        try:
            try:
                portfolio_worksheet = self.spreadsheet.worksheet("æŠ•è³‡çµ„åˆæ‘˜è¦")
            except gspread.WorksheetNotFound:
                print("ğŸ“Š å»ºç«‹æŠ•è³‡çµ„åˆæ‘˜è¦å·¥ä½œè¡¨...")
                portfolio_worksheet = self.spreadsheet.add_worksheet(title="æŠ•è³‡çµ„åˆæ‘˜è¦", rows=1000, cols=20)
            
            portfolio_worksheet.clear()
            
            portfolio_df_clean = portfolio_df.copy()
            portfolio_df_clean = portfolio_df_clean.fillna('')
            
            if 'ä»£è™Ÿ' in portfolio_df_clean.columns:
                portfolio_df_clean['ä»£è™Ÿ'] = portfolio_df_clean['ä»£è™Ÿ'].apply(self._clean_stock_code)
            
            if 'è‚¡ç¥¨ä»£è™Ÿ' in portfolio_df_clean.columns:
                portfolio_df_clean['è‚¡ç¥¨ä»£è™Ÿ'] = portfolio_df_clean['è‚¡ç¥¨ä»£è™Ÿ'].apply(self._clean_stock_code)
            
            numeric_columns = ['åˆ†æå¸«æ•¸é‡', 'ç›®æ¨™åƒ¹', '2025EPSå¹³å‡å€¼', '2026EPSå¹³å‡å€¼', '2027EPSå¹³å‡å€¼', 'å“è³ªè©•åˆ†']
            for col in numeric_columns:
                if col in portfolio_df_clean.columns:
                    portfolio_df_clean[col] = portfolio_df_clean[col].apply(self._format_numeric_value)
            
            headers = portfolio_df_clean.columns.tolist()
            data = portfolio_df_clean.values.tolist()
            
            data = [[self._ensure_json_compatible(cell) for cell in row] for row in data]
            
            portfolio_worksheet.update('A1', [headers])
            
            if data:
                portfolio_worksheet.update('A2', data)
            
            print("ğŸ“Š æŠ•è³‡çµ„åˆæ‘˜è¦ä¸Šå‚³å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æŠ•è³‡çµ„åˆæ‘˜è¦ä¸Šå‚³å¤±æ•—: {e}")
            return False

    def _upload_detailed_report(self, detailed_df: pd.DataFrame) -> bool:
        """ä¸Šå‚³è©³ç´°å ±å‘Š"""
        try:
            try:
                detailed_worksheet = self.spreadsheet.worksheet("è©³ç´°å ±å‘Š")
            except gspread.WorksheetNotFound:
                print("ğŸ“Š å»ºç«‹è©³ç´°å ±å‘Šå·¥ä½œè¡¨...")
                detailed_worksheet = self.spreadsheet.add_worksheet(title="è©³ç´°å ±å‘Š", rows=2000, cols=25)
            
            detailed_worksheet.clear()
            
            detailed_df_clean = detailed_df.copy()
            detailed_df_clean = detailed_df_clean.fillna('')
            
            if 'ä»£è™Ÿ' in detailed_df_clean.columns:
                detailed_df_clean['ä»£è™Ÿ'] = detailed_df_clean['ä»£è™Ÿ'].apply(self._clean_stock_code)
            
            if 'è‚¡ç¥¨ä»£è™Ÿ' in detailed_df_clean.columns:
                detailed_df_clean['è‚¡ç¥¨ä»£è™Ÿ'] = detailed_df_clean['è‚¡ç¥¨ä»£è™Ÿ'].apply(self._clean_stock_code)
            
            numeric_columns = [
                'åˆ†æå¸«æ•¸é‡', 'ç›®æ¨™åƒ¹', 'å“è³ªè©•åˆ†',
                '2025EPSæœ€é«˜å€¼', '2025EPSæœ€ä½å€¼', '2025EPSå¹³å‡å€¼',
                '2026EPSæœ€é«˜å€¼', '2026EPSæœ€ä½å€¼', '2026EPSå¹³å‡å€¼',
                '2027EPSæœ€é«˜å€¼', '2027EPSæœ€ä½å€¼', '2027EPSå¹³å‡å€¼'
            ]
            for col in numeric_columns:
                if col in detailed_df_clean.columns:
                    detailed_df_clean[col] = detailed_df_clean[col].apply(self._format_numeric_value)
            
            headers = detailed_df_clean.columns.tolist()
            data = detailed_df_clean.values.tolist()
            
            data = [[self._ensure_json_compatible(cell) for cell in row] for row in data]
            
            detailed_worksheet.update('A1', [headers])
            
            if data:
                detailed_worksheet.update('A2', data)
            
            print("ğŸ“Š è©³ç´°å ±å‘Šä¸Šå‚³å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ è©³ç´°å ±å‘Šä¸Šå‚³å¤±æ•—: {e}")
            return False

    def _format_numeric_value(self, value):
        """æ ¼å¼åŒ–æ•¸å€¼ï¼Œè™•ç† NaN å’Œç‰¹æ®Šå€¼"""
        if pd.isna(value) or value is None:
            return ''
        
        if isinstance(value, (int, float)):
            if math.isnan(value) or math.isinf(value):
                return ''
            if isinstance(value, float):
                if value.is_integer():
                    return str(int(value))
                else:
                    return f"{value:.2f}"
            else:
                return str(value)
        
        return str(value)

    def _ensure_json_compatible(self, value):
        """ç¢ºä¿å€¼èˆ‡ JSON ç›¸å®¹"""
        if pd.isna(value) or value is None:
            return ''
        
        if isinstance(value, (int, float)):
            if math.isnan(value) or math.isinf(value):
                return ''
            return str(value)
        
        str_value = str(value)
        if str_value.startswith("'"):
            str_value = str_value[1:]
        
        return str_value if str_value != '' else ''

    # ğŸ†• å…¬ç”¨æ–¹æ³•ï¼šæ‰‹å‹•ç”Ÿæˆé©—è­‰æ‘˜è¦ CSV
    def generate_validation_csv_only(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame) -> str:
        """ğŸ†• åªç”Ÿæˆé©—è­‰æ‘˜è¦ CSVï¼Œä¸ä¸Šå‚³åˆ° Google Sheets"""
        try:
            validation_data = self._generate_validation_summary_data(portfolio_df, detailed_df)
            csv_file = self._save_validation_summary_csv(validation_data)
            
            if csv_file:
                print(f"ğŸ“Š é©—è­‰æ‘˜è¦ CSV å·²ç”Ÿæˆ: {csv_file}")
                print(f"ğŸ’¡ æ‚¨å¯ä»¥æ‰‹å‹•å°‡æ­¤ CSV æª”æ¡ˆä¸Šå‚³åˆ° Google Sheets")
                return csv_file
            else:
                print("âŒ é©—è­‰æ‘˜è¦ CSV ç”Ÿæˆå¤±æ•—")
                return ""
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé©—è­‰æ‘˜è¦ CSV å¤±æ•—: {e}")
            return ""


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    uploader = SheetsUploader()
    
    print("=== ğŸ”’ v3.5.1 CSV é©—è­‰æ‘˜è¦è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦ ===")
    
    # æ¸¬è©¦è³‡æ–™
    import pandas as pd
    
    test_detailed_data = [
        {
            'ä»£è™Ÿ': '2330',
            'åç¨±': 'å°ç©é›»',
            'å“è³ªè©•åˆ†': 10.0,
            'ç‹€æ…‹': 'ğŸŸ¢ å®Œæ•´',
            'é©—è­‰ç‹€æ…‹': 'âœ… é€šé'
        },
        {
            'ä»£è™Ÿ': '6462',
            'åç¨±': 'ç¥ç›¾',
            'å“è³ªè©•åˆ†': 7.0,
            'ç‹€æ…‹': 'ğŸŸ  éƒ¨åˆ†',
            'é©—è­‰ç‹€æ…‹': 'âš ï¸ é©—è­‰åœç”¨'
        },
        {
            'ä»£è™Ÿ': '1234',
            'åç¨±': 'æ¸¬è©¦å…¬å¸',
            'å“è³ªè©•åˆ†': 0.0,
            'ç‹€æ…‹': 'âŒ é©—è­‰å¤±æ•—',
            'é©—è­‰ç‹€æ…‹': 'ğŸš« ä¸åœ¨è§€å¯Ÿåå–®'
        }
    ]
    
    detailed_df = pd.DataFrame(test_detailed_data)
    portfolio_df = pd.DataFrame([
        {'ä»£è™Ÿ': '2330', 'åç¨±': 'å°ç©é›»', 'å“è³ªè©•åˆ†': 10.0},
        {'ä»£è™Ÿ': '6462', 'åç¨±': 'ç¥ç›¾', 'å“è³ªè©•åˆ†': 7.0}
    ])
    
    print("æ¸¬è©¦ 1: ç”Ÿæˆé©—è­‰æ‘˜è¦æ•¸æ“š")
    validation_data = uploader._generate_validation_summary_data(portfolio_df, detailed_df)
    print(f"   ç”Ÿæˆçš„é©—è­‰æ‘˜è¦åŒ…å« {len(validation_data)} è¡Œæ•¸æ“š")
    print("   å‰å¹¾è¡Œæ•¸æ“š:")
    for i, row in validation_data.head().iterrows():
        print(f"     {row['é …ç›®']}: {row['æ•¸å€¼']} - {row['èªªæ˜']}")
    
    print("\næ¸¬è©¦ 2: å„²å­˜ CSV æª”æ¡ˆ")
    csv_file = uploader._save_validation_summary_csv(validation_data)
    if csv_file:
        print(f"   âœ… CSV æª”æ¡ˆå·²å„²å­˜: {csv_file}")
    else:
        print("   âŒ CSV æª”æ¡ˆå„²å­˜å¤±æ•—")
    
    print("\næ¸¬è©¦ 3: åªç”Ÿæˆ CSV çš„æ–¹æ³•")
    csv_only_file = uploader.generate_validation_csv_only(portfolio_df, detailed_df)
    if csv_only_file:
        print(f"   âœ… åªç”Ÿæˆ CSV æˆåŠŸ: {csv_only_file}")
    
    print(f"\nğŸ‰ CSV é©—è­‰æ‘˜è¦è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦å®Œæˆ!")
    print(f"âœ… ç”Ÿæˆè©³ç´°çš„é©—è­‰çµ±è¨ˆ CSV")
    print(f"âœ… å¯é¸æ“‡æ€§ä¸Šå‚³åˆ° Google Sheets (ç°¡åŒ–ç‰ˆ)")
    print(f"âœ… å®Œå…¨é¿å… columnWidth API å•é¡Œ")
    print(f"âœ… æä¾›æ‰‹å‹•ä¸Šå‚³çš„ CSV æª”æ¡ˆ")
    
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹å¼:")
    print(f"1. CSV æª”æ¡ˆæœƒè‡ªå‹•ç”Ÿæˆåœ¨ data/reports/ ç›®éŒ„")
    print(f"2. å¯ä»¥æ‰‹å‹•å°‡ CSV æª”æ¡ˆä¸Šå‚³åˆ° Google Sheets")
    print(f"3. æˆ–è€…è®“ç³»çµ±å˜—è©¦ç°¡åŒ–ä¸Šå‚³ï¼ˆç„¡æ ¼å¼è¨­å®šï¼‰")
    print(f"4. ä¸»è¦å ±å‘ŠåŠŸèƒ½å®Œå…¨ä¸å—å½±éŸ¿")