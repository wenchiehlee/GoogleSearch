#!/usr/bin/env python3
"""
Sheets Uploader - FactSet Pipeline v3.6.1 (‰øÆÂæ©Áâà)
‰øÆÂæ© columnWidth API ÈåØË™§ÔºåÂ¢ûÂä† CSV-only Ê®°Âºè
"""

import os
import gspread
import pandas as pd
import math
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
from google.oauth2.service_account import Credentials
import json

# üîß ËºâÂÖ•Áí∞Â¢ÉËÆäÊï∏
try:
    from dotenv import load_dotenv
    # ËºâÂÖ• .env Ê™îÊ°à - ÂòóË©¶Â§öÂÄãË∑ØÂæë
    env_paths = [
        '.env',
        '../.env', 
        '../../.env',
        os.path.join(os.path.dirname(__file__), '.env'),
        os.path.join(os.path.dirname(__file__), '../.env')
    ]
    
    for env_path in env_paths:
        if os.path.exists(env_path):
            load_dotenv(env_path)
            break
except ImportError:
    pass

class SheetsUploader:
    """Google Sheets ‰∏äÂÇ≥Âô® v3.6.1 - ‰øÆÂæ©ÁâàÊú¨ + CSV-only Ê®°Âºè"""
    
    def __init__(self, github_repo_base="https://raw.githubusercontent.com/wenchiehlee/GoogleSearch/refs/heads/main"):
        self.github_repo_base = github_repo_base
        self.client = None
        self.spreadsheet = None
        self.sheet_id = os.getenv('GOOGLE_SHEET_ID')
        
        # üîß v3.6.1 Êõ¥Êñ∞ÁöÑÈ©óË≠âË®≠ÂÆö
        self.validation_settings = {
            'check_before_upload': True,
            'allow_warning_data': True,
            'allow_error_data': False,
            'max_validation_errors': 5,
            'skip_not_block': True,
            'enhanced_validation': True,
            'generate_validation_csv': True,
            'upload_validation_to_sheets': True,  # üîß ÈªòË™çÈóúÈñâ Sheets ‰∏äÂÇ≥
            'csv_output_dir': 'data/reports',
            'csv_only_mode': False  # üÜï Êñ∞Â¢û CSV-only Ê®°Âºè
        }
        
        # üÜï v3.6.1 Â∑•‰ΩúË°®ÂêçÁ®±
        self.worksheet_names = {
            'portfolio': 'ÊäïË≥áÁµÑÂêàÊëòË¶Å',
            'detailed': 'Ë©≥Á¥∞Â†±Âëä',
            'validation': 'È©óË≠âÊëòË¶Å',  
            'keywords': 'Êü•Ë©¢Ê®°ÂºèÊëòË¶Å',
            'watchlist': 'ËßÄÂØüÂêçÂñÆÊëòË¶Å'  # Êñ∞Â¢û
        }
        
        # Á¢∫‰øùËº∏Âá∫ÁõÆÈåÑÂ≠òÂú®
        os.makedirs(self.validation_settings['csv_output_dir'], exist_ok=True)
        
        # üÜï API ÈôêÂà∂Ë®≠ÂÆö
        self.api_settings = {
            'max_retries': 3,
            'retry_delay': 2,  # Áßí
            'batch_size': 100,  # ÊØèÊ¨°ÊâπÈáèÊìç‰ΩúÁöÑË°åÊï∏
            'rate_limit_delay': 0.5  # API Ë™øÁî®ÈñìÈöî
        }

    def upload_all_reports(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                          keyword_df: pd.DataFrame = None, watchlist_df: pd.DataFrame = None, 
                          csv_only=False) -> bool:
        """üîß v3.6.1 ‰∏ªË¶Å‰∏äÂÇ≥ÊñπÊ≥ï - ÊîØÊè¥ CSV-only Ê®°Âºè"""
        
        # üÜï Â¶ÇÊûúÂïüÁî® CSV-only Ê®°ÂºèÔºåÂè™ÁîüÊàê CSV
        if csv_only or self.validation_settings.get('csv_only_mode', False):
            return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)
        
        try:
            # ‰∏äÂÇ≥ÂâçÈ©óË≠â
            if self.validation_settings['check_before_upload']:
                validation_result = self._validate_before_upload_v361(portfolio_df, detailed_df, watchlist_df)
                
                if not validation_result['safe_to_upload']:
                    print(f"üö® ‰∏äÂÇ≥È©óË≠âÂ§±Êïó: {validation_result['reason']}")
                    print(f"üìä ÂïèÈ°åÊëòË¶Å: {validation_result['summary']}")
                    
                    if validation_result['severity'] == 'critical':
                        print("‚ùå ÁôºÁèæÈóúÈçµÂïèÈ°åÔºåÊîπÁî® CSV-only Ê®°Âºè")
                        return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)
                    elif validation_result['severity'] == 'warning':
                        print("‚ö†Ô∏è ÁôºÁèæË≠¶ÂëäÔºåÂª∫Ë≠∞‰ΩøÁî® CSV-only Ê®°Âºè")
                        return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)
                else:
                    if validation_result.get('reason'):
                        print(f"üìä È©óË≠âÁµ±Ë®à: {validation_result['reason']}")
                        print(f"üìä ÂïèÈ°åÊëòË¶Å: {validation_result['summary']}")
                    else:
                        print("‚úÖ ‰∏äÂÇ≥ÂâçÈ©óË≠âÈÄöÈÅé")
            
            # üîß Â¢ûÂä† API ÈôêÂà∂Ê™¢Êü•
            if not self._check_api_availability():
                print("‚ö†Ô∏è Google Sheets API ÂèØËÉΩÊé•ËøëÈôêÂà∂ÔºåÊîπÁî® CSV-only Ê®°Âºè")
                return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)
            
            # Ë®≠ÂÆöÈÄ£Á∑ö
            if not self._setup_connection():
                print("‚ùå Google Sheets ÈÄ£Á∑öÂ§±ÊïóÔºåÊîπÁî® CSV-only Ê®°Âºè")
                return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)
            
            # Ê®ôË®òÂïèÈ°åË≥áÊñô
            portfolio_df_marked = self._mark_problematic_data_v361(portfolio_df)
            detailed_df_marked = self._mark_problematic_data_v361(detailed_df)
            
            success_count = 0
            total_uploads = 4  # Âü∫Êú¨‰∏äÂÇ≥Êï∏Èáè
            
            # ‰∏äÂÇ≥ÊäïË≥áÁµÑÂêàÊëòË¶Å
            if self._upload_portfolio_summary_safe(portfolio_df_marked):
                success_count += 1
                print("üìä ÊäïË≥áÁµÑÂêàÊëòË¶Å‰∏äÂÇ≥ÊàêÂäü")
            else:
                print("‚ùå ÊäïË≥áÁµÑÂêàÊëòË¶Å‰∏äÂÇ≥Â§±Êïó")
            
            # ‰∏äÂÇ≥Ë©≥Á¥∞Â†±Âëä
            if self._upload_detailed_report_safe(detailed_df_marked):
                success_count += 1
                print("üìä Ë©≥Á¥∞Â†±Âëä‰∏äÂÇ≥ÊàêÂäü")
            else:
                print("‚ùå Ë©≥Á¥∞Â†±Âëä‰∏äÂÇ≥Â§±Êïó")
            
            # ‰∏äÂÇ≥ÈóúÈçµÂ≠óÂ†±Âëä
            if keyword_df is not None and not keyword_df.empty:
                if self._upload_keyword_summary_safe(keyword_df):
                    success_count += 1
                    print("üìä ÈóúÈçµÂ≠óÂ†±Âëä‰∏äÂÇ≥ÊàêÂäü")
                else:
                    print("‚ö†Ô∏è ÈóúÈçµÂ≠óÂ†±Âëä‰∏äÂÇ≥Â§±Êïó")
            
            # ‰∏äÂÇ≥ËßÄÂØüÂêçÂñÆÂ†±Âëä
            if watchlist_df is not None and not watchlist_df.empty:
                if self._upload_watchlist_summary_safe(watchlist_df):
                    success_count += 1
                    print("üìä ËßÄÂØüÂêçÂñÆÂ†±Âëä‰∏äÂÇ≥ÊàêÂäü")
                else:
                    print("‚ö†Ô∏è ËßÄÂØüÂêçÂñÆÂ†±Âëä‰∏äÂÇ≥Â§±Êïó")
            
            # üîß ÂêåÊôÇÁîüÊàê CSV ÂÇô‰ªΩ
            self._generate_csv_backup(portfolio_df, detailed_df, keyword_df, watchlist_df)
            
            # ËôïÁêÜÈ©óË≠âÊëòË¶Å
            self._handle_validation_summary_v361_safe(portfolio_df, detailed_df, watchlist_df)
            
            # Ë©ï‰º∞‰∏äÂÇ≥ÊàêÂäüÁéá
            success_rate = success_count / max(total_uploads, 1)
            if success_rate >= 0.5:
                print(f"‚úÖ ‰∏äÂÇ≥ÂÆåÊàê (ÊàêÂäüÁéá: {success_rate:.1%})")
                return True
            else:
                print(f"‚ö†Ô∏è ÈÉ®ÂàÜ‰∏äÂÇ≥Â§±Êïó (ÊàêÂäüÁéá: {success_rate:.1%})")
                print("üí° Âª∫Ë≠∞‰ΩøÁî®ÁîüÊàêÁöÑ CSV Ê™îÊ°à")
                return False
            
        except Exception as e:
            print(f"‚ùå ‰∏äÂÇ≥ÈÅéÁ®ã‰∏≠ÁôºÁîüÈåØË™§: {e}")
            print("üîÑ ÊîπÁî® CSV-only Ê®°Âºè...")
            return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)

    def _csv_only_mode(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                      keyword_df: pd.DataFrame = None, watchlist_df: pd.DataFrame = None) -> bool:
        """üÜï CSV-only Ê®°Âºè - ÂÆåÂÖ®ÈÅøÂÖç Google Sheets API"""
        try:
            print("üìÅ ÂïüÂãï CSV-only Ê®°Âºè...")
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            saved_files = {}
            
            # 1. ÊäïË≥áÁµÑÂêàÊëòË¶Å CSV
            portfolio_path = os.path.join(self.validation_settings['csv_output_dir'], f'portfolio_summary_{timestamp}.csv')
            portfolio_latest = os.path.join(self.validation_settings['csv_output_dir'], 'portfolio_summary_latest.csv')
            
            portfolio_df_clean = portfolio_df.fillna('')
            portfolio_df_clean.to_csv(portfolio_path, index=False, encoding='utf-8-sig')
            portfolio_df_clean.to_csv(portfolio_latest, index=False, encoding='utf-8-sig')
            
            saved_files['portfolio'] = portfolio_path
            print(f"‚úÖ ÊäïË≥áÁµÑÂêàÊëòË¶Å CSV: {os.path.basename(portfolio_path)}")
            
            # 2. Ë©≥Á¥∞Â†±Âëä CSV
            detailed_path = os.path.join(self.validation_settings['csv_output_dir'], f'detailed_report_{timestamp}.csv')
            detailed_latest = os.path.join(self.validation_settings['csv_output_dir'], 'detailed_report_latest.csv')
            
            detailed_df_clean = detailed_df.fillna('')
            detailed_df_clean.to_csv(detailed_path, index=False, encoding='utf-8-sig')
            detailed_df_clean.to_csv(detailed_latest, index=False, encoding='utf-8-sig')
            
            saved_files['detailed'] = detailed_path
            print(f"‚úÖ Ë©≥Á¥∞Â†±Âëä CSV: {os.path.basename(detailed_path)}")
            
            # 3. ÈóúÈçµÂ≠ó/Êü•Ë©¢Ê®°ÂºèÂ†±Âëä CSV
            if keyword_df is not None and not keyword_df.empty:
                # Ê™¢Êü•ÊòØÂê¶ÁÇ∫Êü•Ë©¢Ê®°ÂºèÂ†±Âëä
                if len(keyword_df.columns) > 0 and keyword_df.columns[0] == 'Query pattern':
                    keyword_path = os.path.join(self.validation_settings['csv_output_dir'], f'query_pattern_summary_{timestamp}.csv')
                    keyword_latest = os.path.join(self.validation_settings['csv_output_dir'], 'query_pattern_summary_latest.csv')
                    report_type = "Êü•Ë©¢Ê®°ÂºèÁµ±Ë®à"
                else:
                    keyword_path = os.path.join(self.validation_settings['csv_output_dir'], f'keyword_summary_{timestamp}.csv')
                    keyword_latest = os.path.join(self.validation_settings['csv_output_dir'], 'keyword_summary_latest.csv')
                    report_type = "ÈóúÈçµÂ≠óÁµ±Ë®à"
                
                keyword_df_clean = keyword_df.fillna('')
                keyword_df_clean.to_csv(keyword_path, index=False, encoding='utf-8-sig')
                keyword_df_clean.to_csv(keyword_latest, index=False, encoding='utf-8-sig')
                
                saved_files['keyword'] = keyword_path
                print(f"‚úÖ {report_type} CSV: {os.path.basename(keyword_path)}")
            
            # 4. ËßÄÂØüÂêçÂñÆÂ†±Âëä CSV
            if watchlist_df is not None and not watchlist_df.empty:
                watchlist_path = os.path.join(self.validation_settings['csv_output_dir'], f'watchlist_summary_{timestamp}.csv')
                watchlist_latest = os.path.join(self.validation_settings['csv_output_dir'], 'watchlist_summary_latest.csv')
                
                watchlist_df_clean = watchlist_df.fillna('')
                watchlist_df_clean.to_csv(watchlist_path, index=False, encoding='utf-8-sig')
                watchlist_df_clean.to_csv(watchlist_latest, index=False, encoding='utf-8-sig')
                
                saved_files['watchlist'] = watchlist_path
                print(f"‚úÖ ËßÄÂØüÂêçÂñÆÁµ±Ë®à CSV: {os.path.basename(watchlist_path)}")
            
            # 5. ÁîüÊàêÈ©óË≠âÊëòË¶Å CSV
            validation_data = self._generate_validation_summary_data_v361(portfolio_df, detailed_df, watchlist_df)
            validation_path = os.path.join(self.validation_settings['csv_output_dir'], f'validation_summary_{timestamp}.csv')
            validation_latest = os.path.join(self.validation_settings['csv_output_dir'], 'validation_summary_latest.csv')
            
            validation_data.to_csv(validation_path, index=False, encoding='utf-8-sig')
            validation_data.to_csv(validation_latest, index=False, encoding='utf-8-sig')
            
            saved_files['validation'] = validation_path
            print(f"‚úÖ È©óË≠âÊëòË¶Å CSV: {os.path.basename(validation_path)}")
            
            # 6. ÁîüÊàê‰ΩøÁî®ÊåáÂçó
            self._generate_usage_guide(saved_files, timestamp)
            
            print(f"\nüéâ CSV-only Ê®°ÂºèÂÆåÊàêÔºÅ")
            print(f"üìÅ ÊâÄÊúâÊ™îÊ°à‰ΩçÊñº: {os.path.abspath(self.validation_settings['csv_output_dir'])}")
            print(f"üìã ‰ΩøÁî®ÊåáÂçó: generation_guide_{timestamp}.md")
            print(f"\nüí° ÊâãÂãï‰∏äÂÇ≥Âª∫Ë≠∞:")
            print(f"   1. ÈñãÂïü Google Sheets")
            print(f"   2. ÂåØÂÖ•ÂêÑÂÄã *_latest.csv Ê™îÊ°à")
            print(f"   3. ÊØèÂÄã CSV Âª∫Á´ãÁÇ∫‰∏ÄÂÄãÂ∑•‰ΩúË°®")
            
            return True
            
        except Exception as e:
            print(f"‚ùå CSV-only Ê®°ÂºèÂ§±Êïó: {e}")
            return False

    def _upload_watchlist_summary_safe(self, watchlist_df: pd.DataFrame) -> bool:
        """üîß ÂÆâÂÖ®ÁâàÊú¨ÁöÑËßÄÂØüÂêçÂñÆ‰∏äÂÇ≥ - ‰øÆÂæ© columnWidth ÂïèÈ°å"""
        try:
            # Âª∫Á´ãÊàñÂèñÂæóËßÄÂØüÂêçÂñÆÂ∑•‰ΩúË°®
            try:
                worksheet = self.spreadsheet.worksheet(self.worksheet_names['watchlist'])
            except gspread.WorksheetNotFound:
                print("üìä Âª∫Á´ãËßÄÂØüÂêçÂñÆÂ∑•‰ΩúË°®...")
                worksheet = self.spreadsheet.add_worksheet(
                    title=self.worksheet_names['watchlist'], 
                    rows=1000, 
                    cols=15
                )
            
            # Ê∏ÖÁ©∫ÁèæÊúâË≥áÊñô
            worksheet.clear()
            time.sleep(self.api_settings['rate_limit_delay'])
            
            # Ê∏ÖÁêÜË≥áÊñô
            watchlist_df_clean = watchlist_df.copy()
            watchlist_df_clean = watchlist_df_clean.fillna('')
            
            # Á¢∫‰øùÂÖ¨Âè∏‰ª£ËôüÊ†ºÂºèÊ≠£Á¢∫
            if 'ÂÖ¨Âè∏‰ª£Ëôü' in watchlist_df_clean.columns:
                watchlist_df_clean['ÂÖ¨Âè∏‰ª£Ëôü'] = watchlist_df_clean['ÂÖ¨Âè∏‰ª£Ëôü'].apply(self._clean_stock_code)
            
            # Ê†ºÂºèÂåñÊï∏ÂÄºÊ¨Ñ‰Ωç
            numeric_columns = ['MDÊ™îÊ°àÊï∏Èáè', 'Âπ≥ÂùáÂìÅË≥™Ë©ïÂàÜ', 'ÊúÄÈ´òÂìÅË≥™Ë©ïÂàÜ', 'ÊêúÂ∞ãÈóúÈçµÂ≠óÊï∏Èáè', 'ÈóúÈçµÂ≠óÂπ≥ÂùáÂìÅË≥™']
            for col in numeric_columns:
                if col in watchlist_df_clean.columns:
                    watchlist_df_clean[col] = watchlist_df_clean[col].apply(self._format_numeric_value)
            
            # Ê∫ñÂÇô‰∏äÂÇ≥Ë≥áÊñô
            headers = watchlist_df_clean.columns.tolist()
            data = watchlist_df_clean.values.tolist()
            
            # Á¢∫‰øùÊâÄÊúâË≥áÊñôÈÉΩÊòØ JSON Áõ∏ÂÆπÁöÑ
            data = [[self._ensure_json_compatible(cell) for cell in row] for row in data]
            
            # ‰∏äÂÇ≥Ê®ôÈ°å
            worksheet.update('A1', [headers])
            time.sleep(self.api_settings['rate_limit_delay'])
            
            # ÂàÜÊâπ‰∏äÂÇ≥Ë≥áÊñô
            if data:
                batch_size = self.api_settings['batch_size']
                for i in range(0, len(data), batch_size):
                    batch_data = data[i:i + batch_size]
                    start_row = i + 2  # +2 Âõ†ÁÇ∫Ê®ôÈ°å‰ΩîÁ¨¨1Ë°åÔºåË≥áÊñôÂæûÁ¨¨2Ë°åÈñãÂßã
                    range_name = f'A{start_row}'
                    
                    worksheet.update(range_name, batch_data)
                    time.sleep(self.api_settings['rate_limit_delay'])
                    
                    if i + batch_size < len(data):
                        print(f"   Â∑≤‰∏äÂÇ≥ {i + batch_size}/{len(data)} Ë°å...")
            
            # üîß ‰øÆÂæ©ÂæåÁöÑÊ†ºÂºèË®≠ÂÆö - ‰∏ç‰ΩøÁî® columnWidth
            self._format_watchlist_worksheet_fixed(worksheet, len(watchlist_df_clean))
            
            print("üìä ËßÄÂØüÂêçÂñÆÂ†±Âëä‰∏äÂÇ≥ÂÆåÊàê")
            return True
            
        except Exception as e:
            print(f"‚ùå ËßÄÂØüÂêçÂñÆÂ†±Âëä‰∏äÂÇ≥Â§±Êïó: {e}")
            return False

    def _format_watchlist_worksheet_fixed(self, worksheet, data_rows: int):
        """üîß ‰øÆÂæ©ÁâàÊú¨ÔºöÊ†ºÂºèÂåñËßÄÂØüÂêçÂñÆÂ∑•‰ΩúË°® - ‰∏ç‰ΩøÁî® columnWidth"""
        try:
            # Ë®≠ÂÆöÊ®ôÈ°åÂàóÊ†ºÂºè
            worksheet.format('A1:L1', {
                'backgroundColor': {'red': 0.2, 'green': 0.7, 'blue': 0.9},
                'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}}
            })
            time.sleep(self.api_settings['rate_limit_delay'])
            
            if data_rows > 0:
                try:
                    # Ë®≠ÂÆöÊï∏ÂÄºÊ¨Ñ‰ΩçÊ†ºÂºè - ÂàÜÊâπËôïÁêÜ
                    ranges_to_format = [
                        ('E:F', {'numberFormat': {'type': 'NUMBER', 'pattern': '0.00'}}),  # ÂìÅË≥™Ë©ïÂàÜÊ¨Ñ‰Ωç
                        ('I:I', {'numberFormat': {'type': 'NUMBER', 'pattern': '0.00'}})   # ÈóúÈçµÂ≠óÂπ≥ÂùáÂìÅË≥™
                    ]
                    
                    for range_name, format_dict in ranges_to_format:
                        try:
                            worksheet.format(range_name, format_dict)
                            time.sleep(self.api_settings['rate_limit_delay'])
                        except Exception as format_error:
                            print(f"‚ö†Ô∏è Ë®≠ÂÆö {range_name} Ê†ºÂºèÂ§±Êïó: {format_error}")
                
                except Exception as number_format_error:
                    print(f"‚ö†Ô∏è Ë®≠ÂÆöÊï∏ÂÄºÊ†ºÂºèÂ§±Êïó: {number_format_error}")
                
                # üîß ÁßªÈô§ columnWidth Ë®≠ÂÆöÔºåÊîπÁî®Á∞°ÂñÆÁöÑÊñáÂ≠óÊ†ºÂºè
                try:
                    # Ë®≠ÂÆöÊñáÂ≠óÂ∞çÈΩä
                    worksheet.format('A:A', {'horizontalAlignment': 'CENTER'})   # ÂÖ¨Âè∏‰ª£ËôüÁΩÆ‰∏≠
                    time.sleep(self.api_settings['rate_limit_delay'])
                    
                    worksheet.format('B:B', {'horizontalAlignment': 'LEFT'})     # ÂÖ¨Âè∏ÂêçÁ®±Â∑¶Â∞çÈΩä
                    time.sleep(self.api_settings['rate_limit_delay'])
                    
                except Exception as align_error:
                    print(f"‚ö†Ô∏è Ë®≠ÂÆöÂ∞çÈΩäÊ†ºÂºèÂ§±Êïó: {align_error}")
                    
        except Exception as e:
            print(f"‚ö†Ô∏è ËßÄÂØüÂêçÂñÆÂ∑•‰ΩúË°®Ê†ºÂºèË®≠ÂÆöÂ§±Êïó: {e}")

    def _upload_portfolio_summary_safe(self, portfolio_df: pd.DataFrame) -> bool:
        """ÂÆâÂÖ®ÁâàÊú¨ÁöÑÊäïË≥áÁµÑÂêàÊëòË¶Å‰∏äÂÇ≥"""
        return self._upload_with_retry("ÊäïË≥áÁµÑÂêàÊëòË¶Å", portfolio_df, self._upload_portfolio_summary)

    def _upload_detailed_report_safe(self, detailed_df: pd.DataFrame) -> bool:
        """ÂÆâÂÖ®ÁâàÊú¨ÁöÑË©≥Á¥∞Â†±Âëä‰∏äÂÇ≥"""
        return self._upload_with_retry("Ë©≥Á¥∞Â†±Âëä", detailed_df, self._upload_detailed_report)

    def _upload_keyword_summary_safe(self, keyword_df: pd.DataFrame) -> bool:
        """ÂÆâÂÖ®ÁâàÊú¨ÁöÑÈóúÈçµÂ≠óÂ†±Âëä‰∏äÂÇ≥"""
        return self._upload_with_retry("ÈóúÈçµÂ≠óÂ†±Âëä", keyword_df, self._upload_keyword_summary)

    def _upload_with_retry(self, report_name: str, df: pd.DataFrame, upload_func) -> bool:
        """ÈÄöÁî®ÁöÑÈáçË©¶‰∏äÂÇ≥ÊñπÊ≥ï"""
        for attempt in range(self.api_settings['max_retries']):
            try:
                result = upload_func(df)
                if result:
                    return True
                else:
                    print(f"‚ö†Ô∏è {report_name} ‰∏äÂÇ≥ÂòóË©¶ {attempt + 1} Â§±Êïó")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è {report_name} ‰∏äÂÇ≥ÂòóË©¶ {attempt + 1} ÈåØË™§: {e}")
                
                # Ê™¢Êü•ÊòØÂê¶ÁÇ∫ API ÈôêÂà∂ÈåØË™§
                if "quota exceeded" in str(e).lower() or "429" in str(e):
                    print(f"üö´ API ÈôêÂà∂ÔºåÂÅúÊ≠¢ÈáçË©¶ {report_name}")
                    return False
                
                if attempt < self.api_settings['max_retries'] - 1:
                    wait_time = self.api_settings['retry_delay'] * (attempt + 1)
                    print(f"‚è≥ Á≠âÂæÖ {wait_time} ÁßíÂæåÈáçË©¶...")
                    time.sleep(wait_time)
        
        print(f"‚ùå {report_name} ÊâÄÊúâÈáçË©¶Â§±Êïó")
        return False

    def _check_api_availability(self) -> bool:
        """Ê™¢Êü• API ÂèØÁî®ÊÄß"""
        try:
            if not self.sheet_id:
                return False
            
            # Á∞°ÂñÆÁöÑÈÄ£Á∑öÊ∏¨Ë©¶
            if self.client is None:
                return self._setup_connection()
            
            return True
            
        except Exception as e:
            if "quota exceeded" in str(e).lower() or "429" in str(e):
                return False
            return True

    def _generate_csv_backup(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                           keyword_df: pd.DataFrame = None, watchlist_df: pd.DataFrame = None):
        """ÁîüÊàê CSV ÂÇô‰ªΩÊ™îÊ°à"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_dir = os.path.join(self.validation_settings['csv_output_dir'], 'backup')
            os.makedirs(backup_dir, exist_ok=True)
            
            # ÂÇô‰ªΩ‰∏ªË¶ÅÂ†±Âëä
            portfolio_df.to_csv(os.path.join(backup_dir, f'portfolio_backup_{timestamp}.csv'), 
                               index=False, encoding='utf-8-sig')
            detailed_df.to_csv(os.path.join(backup_dir, f'detailed_backup_{timestamp}.csv'), 
                              index=False, encoding='utf-8-sig')
            
            if keyword_df is not None and not keyword_df.empty:
                keyword_df.to_csv(os.path.join(backup_dir, f'keyword_backup_{timestamp}.csv'), 
                                 index=False, encoding='utf-8-sig')
            
            if watchlist_df is not None and not watchlist_df.empty:
                watchlist_df.to_csv(os.path.join(backup_dir, f'watchlist_backup_{timestamp}.csv'), 
                                   index=False, encoding='utf-8-sig')
            
            print(f"üíæ CSV ÂÇô‰ªΩÂ∑≤ÁîüÊàê: {backup_dir}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è CSV ÂÇô‰ªΩÁîüÊàêÂ§±Êïó: {e}")

    def _generate_usage_guide(self, saved_files: Dict[str, str], timestamp: str):
        """ÁîüÊàê‰ΩøÁî®ÊåáÂçó"""
        guide_content = f"""
# FactSet Pipeline v3.6.1 - CSV Â†±Âëä‰ΩøÁî®ÊåáÂçó
ÁîüÊàêÊôÇÈñì: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ÊôÇÈñìÊà≥: {timestamp}

## üìÅ ÁîüÊàêÁöÑÊ™îÊ°àÊ∏ÖÂñÆ

### ‰∏ªË¶ÅÂ†±ÂëäÊ™îÊ°à
"""
        
        for report_type, file_path in saved_files.items():
            filename = os.path.basename(file_path)
            guide_content += f"- {report_type}: `{filename}`\n"
        
        guide_content += f"""

### ÊúÄÊñ∞ÁâàÊú¨Ê™îÊ°à (ÁÑ°ÊôÇÈñìÊà≥)
- `portfolio_summary_latest.csv` - ÊäïË≥áÁµÑÂêàÊëòË¶Å
- `detailed_report_latest.csv` - Ë©≥Á¥∞Â†±Âëä
- `query_pattern_summary_latest.csv` - Êü•Ë©¢Ê®°ÂºèÁµ±Ë®à (Â¶ÇÊúâ)
- `watchlist_summary_latest.csv` - ËßÄÂØüÂêçÂñÆÁµ±Ë®à (Â¶ÇÊúâ)
- `validation_summary_latest.csv` - È©óË≠âÊëòË¶Å

## üîß Google Sheets ÊâãÂãï‰∏äÂÇ≥Ê≠•È©ü

### ÊñπÊ≥ï 1: Ê™îÊ°àÂåØÂÖ•
1. ÈñãÂïü Google Sheets
2. Âª∫Á´ãÊñ∞ÁöÑË©¶ÁÆóË°®ÊàñÈñãÂïüÁèæÊúâË©¶ÁÆóË°®
3. ÈªûÈÅ∏„ÄåÊ™îÊ°à„Äç‚Üí„ÄåÂåØÂÖ•„Äç
4. ‰∏äÂÇ≥ CSV Ê™îÊ°à
5. ÈÅ∏Êìá„ÄåÂª∫Á´ãÊñ∞Â∑•‰ΩúË°®„Äç
6. ÈáçË§áÊ≠•È©ü 3-5 for ÊØèÂÄã CSV Ê™îÊ°à

### ÊñπÊ≥ï 2: Ë§áË£ΩË≤º‰∏ä
1. Áî® Excel ÊàñÊñáÂ≠óÁ∑®ËºØÂô®ÈñãÂïü CSV Ê™îÊ°à
2. ÂÖ®ÈÅ∏‰∏¶Ë§áË£ΩÂÖßÂÆπ
3. Âú® Google Sheets ‰∏≠Âª∫Á´ãÊñ∞Â∑•‰ΩúË°®
4. Ë≤º‰∏äÂÖßÂÆπ
5. Â¶ÇÊûúÊ†ºÂºèÊúâÂïèÈ°åÔºå‰ΩøÁî®„ÄåË≥áÊñô„Äç‚Üí„ÄåÂàÜÊ¨Ñ„ÄçÂäüËÉΩ

## üìä ÂêÑÂ†±ÂëäÊ™îÊ°àË™™Êòé

### ÊäïË≥áÁµÑÂêàÊëòË¶Å (portfolio_summary_*.csv)
- **Áî®ÈÄî**: ÊØèÂÆ∂ÂÖ¨Âè∏ÁöÑÈóúÈçµÊåáÊ®ôÊëòË¶Å
- **Ê¨Ñ‰Ωç**: 14 ÂÄãÊ¨Ñ‰ΩçÔºåÂåÖÂê´‰ª£Ëôü„ÄÅÂêçÁ®±„ÄÅEPS È†êÊ∏¨„ÄÅÂìÅË≥™Ë©ïÂàÜÁ≠â
- **ÈÅ©Áî®**: È´òÈöé‰∏ªÁÆ°Â†±Âëä„ÄÅÂø´ÈÄüÊ¶ÇË¶Ω

### Ë©≥Á¥∞Â†±Âëä (detailed_report_*.csv)
- **Áî®ÈÄî**: ÊâÄÊúâË®òÈåÑÁöÑÂÆåÊï¥Ë©≥Á¥∞Ë≥áË®ä
- **Ê¨Ñ‰Ωç**: 22 ÂÄãÊ¨Ñ‰ΩçÔºåÂåÖÂê´ÊâÄÊúâ EPS Êï∏Êìö„ÄÅÈ©óË≠âÁãÄÊÖã„ÄÅMD Ê™îÊ°àÈÄ£Áµê
- **ÈÅ©Áî®**: ÂàÜÊûêÂ∏´Ê∑±Â∫¶ÂàÜÊûê„ÄÅË≥áÊñôÈ©óË≠â

### Êü•Ë©¢Ê®°ÂºèÁµ±Ë®à (query_pattern_summary_*.csv)
- **Áî®ÈÄî**: ÊêúÂ∞ãÊü•Ë©¢Ê®°ÂºèÊïàÊûúÂàÜÊûê
- **Ê¨Ñ‰Ωç**: 10 ÂÄãÊ¨Ñ‰ΩçÔºåÂåÖÂê´Ê®°Âºè‰ΩøÁî®Ê¨°Êï∏„ÄÅÂìÅË≥™Ë©ïÂàÜ„ÄÅÂàÜÈ°û
- **ÈÅ©Áî®**: Á≥ªÁµ±ÂÑ™Âåñ„ÄÅÊêúÂ∞ãÁ≠ñÁï•ÊîπÈÄ≤

### ËßÄÂØüÂêçÂñÆÁµ±Ë®à (watchlist_summary_*.csv)
- **Áî®ÈÄî**: ËßÄÂØüÂêçÂñÆÂÖ¨Âè∏ËôïÁêÜÁãÄÊÖãÂàÜÊûê
- **Ê¨Ñ‰Ωç**: 12 ÂÄãÊ¨Ñ‰ΩçÔºåÂåÖÂê´ËôïÁêÜÁãÄÊÖã„ÄÅÂìÅË≥™Ë©ïÂàÜ„ÄÅÈóúÈçµÂ≠óÂàÜÊûê
- **ÈÅ©Áî®**: Ë¶ÜËìãÁéáÁõ£Êéß„ÄÅÂÑ™ÂÖàËôïÁêÜË¶èÂäÉ

### È©óË≠âÊëòË¶Å (validation_summary_*.csv)
- **Áî®ÈÄî**: Êï¥È´îËôïÁêÜÁãÄÊÖãÂíåÁµ±Ë®àÊëòË¶Å
- **Ê¨Ñ‰Ωç**: 5 ÂÄãÊ¨Ñ‰ΩçÔºåÂåÖÂê´Áµ±Ë®àÈ†ÖÁõÆ„ÄÅÊï∏ÂÄº„ÄÅË™™Êòé
- **ÈÅ©Áî®**: Á≥ªÁµ±ÂÅ•Â∫∑Â∫¶Áõ£Êéß„ÄÅËôïÁêÜÂìÅË≥™Ë©ï‰º∞

## üí° ‰ΩøÁî®Âª∫Ë≠∞

### Excel ÂàÜÊûê
1. ‰ΩøÁî® Excel ÁöÑÊ®ûÁ¥êÂàÜÊûêË°®ÂäüËÉΩÈÄ≤Ë°åÊ∑±Â∫¶ÂàÜÊûê
2. Âª∫Á´ãÂúñË°®Ë¶ñË¶∫ÂåñÂëàÁèæË≥áÊñô
3. Ë®≠ÂÆöÊ¢ù‰ª∂Ê†ºÂºèÁ™ÅÂá∫ÈóúÈçµË≥áË®ä

### Ëá™ÂãïÂåñËôïÁêÜ
1. ÂèØ‰ª•ÂØ´Á®ãÂºèÂÆöÊúüËôïÁêÜ `*_latest.csv` Ê™îÊ°à
2. Âª∫Á´ãÁõ£ÊéßÂÑÄË°®ÊùøËÆÄÂèñÈÄô‰∫õ CSV
3. Ë®≠ÂÆöË≠¶Â†±Á≥ªÁµ±Áõ£ÊéßÂìÅË≥™Ë©ïÂàÜËÆäÂåñ

### Ë≥áÊñôÊï¥Âêà
1. ‰ΩøÁî® SQL Ë≥áÊñôÂ∫´ÂåØÂÖ•ÈÄô‰∫õ CSV ÈÄ≤Ë°åË§áÈõúÊü•Ë©¢
2. ÁµêÂêàÂÖ∂‰ªñË≥áÊñôÊ∫êÈÄ≤Ë°å‰∫§ÂèâÂàÜÊûê
3. Âª∫Á´ãÊ≠∑Âè≤Ë≥áÊñôË∂®Âã¢ÂàÜÊûê

## ‚ö†Ô∏è Ê≥®ÊÑè‰∫ãÈ†Ö

### Ê™îÊ°àÁ∑®Á¢º
- ÊâÄÊúâ CSV Ê™îÊ°à‰ΩøÁî® UTF-8-BOM Á∑®Á¢º
- Excel ÈñãÂïüÊôÇ‰∏≠ÊñáÊáâÊ≠£Â∏∏È°ØÁ§∫
- Â¶ÇÊúâ‰∫ÇÁ¢ºÔºåË´ãÁ¢∫Ë™çÁ∑®Á¢ºË®≠ÂÆö

### Ë≥áÊñôÊ†ºÂºè
- Êï∏ÂÄºÊ¨Ñ‰ΩçÂ∑≤Á∂ìÊ†ºÂºèÂåñÔºåÂèØÁõ¥Êé•Áî®ÊñºË®àÁÆó
- Êó•ÊúüÊ†ºÂºèÁÇ∫ YYYY-MM-DD
- ËÇ°Á•®‰ª£ËôüÁÇ∫Á¥îÊï∏Â≠óÊ†ºÂºè

### Êõ¥Êñ∞È†ªÁéá
- ÊôÇÈñìÊà≥ÁâàÊú¨Ê™îÊ°à‰øùÁïôÊ≠∑Âè≤Ë®òÈåÑ
- `*_latest.csv` Ê™îÊ°àÁ∏ΩÊòØÊúÄÊñ∞ÁâàÊú¨
- Âª∫Ë≠∞ÂÆöÊúüÂÇô‰ªΩÈáçË¶ÅÁöÑÊôÇÈñìÊà≥ÁâàÊú¨

---
FactSet Pipeline v3.6.1 - CSV Only Mode
ÈÅøÂÖç Google Sheets API ÈôêÂà∂ÔºåÊèê‰æõÁ©©ÂÆöÂèØÈù†ÁöÑËº∏Âá∫ÊñπÊ°à
"""
        
        # ÂÑ≤Â≠ò‰ΩøÁî®ÊåáÂçó
        guide_path = os.path.join(self.validation_settings['csv_output_dir'], f'generation_guide_{timestamp}.md')
        guide_latest = os.path.join(self.validation_settings['csv_output_dir'], 'generation_guide_latest.md')
        
        with open(guide_path, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        with open(guide_latest, 'w', encoding='utf-8') as f:
            f.write(guide_content)

    def _handle_validation_summary_v361_safe(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                                            watchlist_df: pd.DataFrame = None):
        """üîß ÂÆâÂÖ®ÁâàÊú¨ÁöÑÈ©óË≠âÊëòË¶ÅËôïÁêÜ"""
        try:
            # 1. ÁîüÊàêÈ©óË≠âÊëòË¶ÅÊï∏Êìö
            validation_data = self._generate_validation_summary_data_v361(portfolio_df, detailed_df, watchlist_df)
            
            # 2. ÁîüÊàê CSV Ê™îÊ°àÔºàÁ∏ΩÊòØÂü∑Ë°åÔºâ
            csv_file = self._save_validation_summary_csv(validation_data)
            if csv_file:
                print(f"üìä È©óË≠âÊëòË¶Å CSV Â∑≤ÁîüÊàê: {os.path.basename(csv_file)}")
            
            # 3. ÂòóË©¶‰∏äÂÇ≥Âà∞ Google SheetsÔºàÂèØÈÅ∏ÔºåÊúâ API ÈôêÂà∂‰øùË≠∑Ôºâ
            if self.validation_settings.get('upload_validation_to_sheets', False):
                try:
                    if self._check_api_availability():
                        self._upload_validation_summary_simple(validation_data)
                        print("üìä È©óË≠âÊëòË¶ÅÂ∑≤‰∏äÂÇ≥Âà∞ Google Sheets")
                    else:
                        print("‚ö†Ô∏è API ÈôêÂà∂ÔºåË∑≥ÈÅé Google Sheets È©óË≠âÊëòË¶Å‰∏äÂÇ≥")
                except Exception as e:
                    print(f"‚ö†Ô∏è Google Sheets È©óË≠âÊëòË¶Å‰∏äÂÇ≥Â§±Êïó: {e}")
                    print("üí° ‰ΩÜ CSV Ê™îÊ°àÂ∑≤ÁîüÊàêÔºåÂèØÊâãÂãï‰∏äÂÇ≥")
            
        except Exception as e:
            print(f"‚ö†Ô∏è È©óË≠âÊëòË¶ÅËôïÁêÜÂ§±Êïó: {e}")

    # ‰øùÊåÅÂÖ∂‰ªñÂéüÊúâÊñπÊ≥ï‰∏çËÆä...
    def _validate_before_upload_v361(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                                    watchlist_df: pd.DataFrame = None) -> Dict[str, Any]:
        """‰∏äÂÇ≥ÂâçÈ©óË≠âÊ™¢Êü•"""
        validation_result = {
            'safe_to_upload': True,
            'reason': '',
            'summary': {},
            'issues': [],
            'severity': 'info'
        }
        
        if portfolio_df.empty:
            validation_result['safe_to_upload'] = False
            validation_result['reason'] = 'ÊäïË≥áÁµÑÂêàÊëòË¶ÅÁÇ∫Á©∫'
            validation_result['severity'] = 'critical'
            return validation_result
        
        if detailed_df.empty:
            validation_result['safe_to_upload'] = False
            validation_result['reason'] = 'Ë©≥Á¥∞Â†±ÂëäÁÇ∫Á©∫'
            validation_result['severity'] = 'critical'
            return validation_result
        
        # È©óË≠âÁãÄÊÖãÂàÜÊûê
        validation_issues = []
        critical_issues = 0
        warning_issues = 0
        validation_disabled_count = 0
        
        if 'È©óË≠âÁãÄÊÖã' in detailed_df.columns:
            for idx, row in detailed_df.iterrows():
                validation_status = str(row.get('È©óË≠âÁãÄÊÖã', ''))
                company_name = row.get('ÂêçÁ®±', 'Unknown')
                company_code = row.get('‰ª£Ëôü', 'Unknown')
                
                if 'üö´' in validation_status or '‚ùå' in validation_status:
                    critical_issues += 1
                    validation_issues.append({
                        'company': f"{company_name}({company_code})",
                        'type': 'critical',
                        'status': validation_status
                    })
                elif '‚ö†Ô∏è' in validation_status:
                    if 'È©óË≠âÂÅúÁî®' in validation_status:
                        validation_disabled_count += 1
                    else:
                        warning_issues += 1
                    validation_issues.append({
                        'company': f"{company_name}({company_code})",
                        'type': 'warning',
                        'status': validation_status
                    })
        
        total_companies = len(detailed_df)
        
        # ËßÄÂØüÂêçÂñÆÁõ∏ÈóúÁµ±Ë®à
        watchlist_summary = {
            'watchlist_provided': watchlist_df is not None and not watchlist_df.empty,
            'watchlist_companies': 0,
            'coverage_rate': 0.0
        }
        
        if watchlist_df is not None and not watchlist_df.empty:
            watchlist_companies = len(watchlist_df)
            processed_companies = len([idx for idx, row in watchlist_df.iterrows() 
                                     if row.get('ËôïÁêÜÁãÄÊÖã', '') == '‚úÖ Â∑≤ËôïÁêÜ'])
            
            watchlist_summary.update({
                'watchlist_companies': watchlist_companies,
                'processed_companies': processed_companies,
                'coverage_rate': (processed_companies / watchlist_companies) * 100 if watchlist_companies > 0 else 0
            })
        
        validation_result['summary'] = {
            'total_companies': total_companies,
            'critical_issues': critical_issues,
            'warning_issues': warning_issues,
            'validation_disabled': validation_disabled_count,
            'validation_issues': len(validation_issues),
            'watchlist_summary': watchlist_summary
        }
        
        validation_result['issues'] = validation_issues
        
        if self.validation_settings.get('enhanced_validation', False):
            if critical_issues > 0:
                validation_result['safe_to_upload'] = False
                validation_result['severity'] = 'critical'
                validation_result['reason'] = f'ÁôºÁèæ {critical_issues} ÂÄãÈóúÈçµÈ©óË≠âÂïèÈ°å'
            elif warning_issues > total_companies * 0.5:
                validation_result['safe_to_upload'] = False
                validation_result['severity'] = 'warning'
                validation_result['reason'] = f'Ë≠¶ÂëäÂïèÈ°åÈÅéÂ§ö: {warning_issues}/{total_companies}'
            else:
                validation_result['safe_to_upload'] = True
                status_parts = []
                if validation_disabled_count > 0:
                    status_parts.append(f'{validation_disabled_count} ÂÄãÈ©óË≠âÂÅúÁî®')
                if warning_issues > 0:
                    status_parts.append(f'{warning_issues} ÂÄãË≠¶Âëä')
                if watchlist_summary['watchlist_provided']:
                    status_parts.append(f"ËßÄÂØüÂêçÂñÆË¶ÜËìãÁéá {watchlist_summary['coverage_rate']:.1f}%")
                
                if status_parts:
                    validation_result['reason'] = f'ÁôºÁèæ {", ".join(status_parts)}ÔºåÂ∞áÁπºÁ∫å‰∏äÂÇ≥'
                    validation_result['severity'] = 'info'
        
        return validation_result

    def _mark_problematic_data_v361(self, df: pd.DataFrame) -> pd.DataFrame:
        """Ê®ôË®òÂïèÈ°åË≥áÊñô"""
        df_marked = df.copy()
        
        if 'È©óË≠âÁãÄÊÖã' in df_marked.columns and 'ÂêçÁ®±' in df_marked.columns:
            for idx, row in df_marked.iterrows():
                validation_status = str(row.get('È©óË≠âÁãÄÊÖã', ''))
                company_name = str(row.get('ÂêçÁ®±', ''))
                
                if 'üö´' in validation_status:
                    df_marked.at[idx, 'ÂêçÁ®±'] = f"üö´ {company_name}"
                elif '‚ùå' in validation_status:
                    df_marked.at[idx, 'ÂêçÁ®±'] = f"‚ùå {company_name}"
                elif 'üìù' in validation_status:
                    df_marked.at[idx, 'ÂêçÁ®±'] = f"üìù {company_name}"
                elif 'üîÑ' in validation_status:
                    df_marked.at[idx, 'ÂêçÁ®±'] = f"üîÑ {company_name}"
                elif '‚ö†Ô∏è È©óË≠âÂÅúÁî®' in validation_status:
                    df_marked.at[idx, 'ÂêçÁ®±'] = f"‚ö†Ô∏è {company_name}"
                elif '‚ö†Ô∏è' in validation_status:
                    df_marked.at[idx, 'ÂêçÁ®±'] = f"‚ö†Ô∏è {company_name}"
        
        return df_marked

    def _generate_validation_summary_data_v361(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                                             watchlist_df: pd.DataFrame = None) -> pd.DataFrame:
        """ÁîüÊàêÈ©óË≠âÊëòË¶ÅÊï∏Êìö"""
        summary_rows = []
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Âü∫Êú¨Áµ±Ë®à
        summary_rows.append({
            'È†ÖÁõÆ': 'Á∏ΩÂÖ¨Âè∏Êï∏',
            'Êï∏ÂÄº': len(portfolio_df),
            'Ë™™Êòé': 'ÊäïË≥áÁµÑÂêà‰∏≠ÁöÑÂÖ¨Âè∏Á∏ΩÊï∏',
            'Ë©≥Á¥∞Ë≥áË®ä': f'Ë©≥Á¥∞Ë®òÈåÑ: {len(detailed_df)}',
            'Êõ¥Êñ∞ÊôÇÈñì': current_time
        })
        
        # ËßÄÂØüÂêçÂñÆÁµ±Ë®à
        if watchlist_df is not None and not watchlist_df.empty:
            total_watchlist = len(watchlist_df)
            processed_count = len([idx for idx, row in watchlist_df.iterrows() 
                                 if row.get('ËôïÁêÜÁãÄÊÖã', '') == '‚úÖ Â∑≤ËôïÁêÜ'])
            not_found_count = len([idx for idx, row in watchlist_df.iterrows() 
                                 if row.get('ËôïÁêÜÁãÄÊÖã', '') == '‚ùå Êú™ÊâæÂà∞'])
            coverage_rate = (processed_count / total_watchlist) * 100 if total_watchlist > 0 else 0
            
            summary_rows.extend([
                {
                    'È†ÖÁõÆ': 'ËßÄÂØüÂêçÂñÆÁ∏ΩÊï∏',
                    'Êï∏ÂÄº': total_watchlist,
                    'Ë™™Êòé': 'ËßÄÂØüÂêçÂñÆ‰∏≠ÁöÑÂÖ¨Âè∏Á∏ΩÊï∏',
                    'Ë©≥Á¥∞Ë≥áË®ä': f'ÈÄôÊòØËôïÁêÜÁöÑÂü∫Ê∫ñÊ∏ÖÂñÆ',
                    'Êõ¥Êñ∞ÊôÇÈñì': current_time
                },
                {
                    'È†ÖÁõÆ': 'ËßÄÂØüÂêçÂñÆÂ∑≤ËôïÁêÜ',
                    'Êï∏ÂÄº': processed_count,
                    'Ë™™Êòé': 'ËßÄÂØüÂêçÂñÆ‰∏≠Â∑≤ÊàêÂäüËôïÁêÜÁöÑÂÖ¨Âè∏Êï∏',
                    'Ë©≥Á¥∞Ë≥áË®ä': f'Ë¶ÜËìãÁéá: {coverage_rate:.1f}%',
                    'Êõ¥Êñ∞ÊôÇÈñì': current_time
                },
                {
                    'È†ÖÁõÆ': 'ËßÄÂØüÂêçÂñÆÊú™ÊâæÂà∞',
                    'Êï∏ÂÄº': not_found_count,
                    'Ë™™Êòé': 'ËßÄÂØüÂêçÂñÆ‰∏≠Êú™ÊâæÂà∞MDÊ™îÊ°àÁöÑÂÖ¨Âè∏Êï∏',
                    'Ë©≥Á¥∞Ë≥áË®ä': f'ÈúÄË¶ÅÂä†Âº∑ÊêúÂ∞ãÁöÑÂÖ¨Âè∏',
                    'Êõ¥Êñ∞ÊôÇÈñì': current_time
                }
            ])
        
        return pd.DataFrame(summary_rows)

    def _save_validation_summary_csv(self, validation_df: pd.DataFrame) -> str:
        """ÂÑ≤Â≠òÈ©óË≠âÊëòË¶ÅÁÇ∫ CSV Ê™îÊ°à"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            csv_filename = f'validation_summary_{timestamp}.csv'
            csv_path = os.path.join(self.validation_settings['csv_output_dir'], csv_filename)
            
            # ÂÑ≤Â≠ò CSV
            validation_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            
            # ÂêåÊôÇÂÑ≤Â≠òÊúÄÊñ∞ÁâàÊú¨
            latest_csv_path = os.path.join(self.validation_settings['csv_output_dir'], 'validation_summary_latest.csv')
            validation_df.to_csv(latest_csv_path, index=False, encoding='utf-8-sig')
            
            return csv_path
            
        except Exception as e:
            print(f"‚ùå ÂÑ≤Â≠òÈ©óË≠âÊëòË¶Å CSV Â§±Êïó: {e}")
            return ""

    def _upload_validation_summary_simple(self, validation_df: pd.DataFrame):
        """Á∞°ÂåñÁâàÈ©óË≠âÊëòË¶Å‰∏äÂÇ≥"""
        try:
            # ÂòóË©¶ÊâæÂà∞ÊàñÂª∫Á´ãÈ©óË≠âÊëòË¶ÅÂ∑•‰ΩúË°®
            try:
                validation_worksheet = self.spreadsheet.worksheet(self.worksheet_names['validation'])
            except gspread.WorksheetNotFound:
                print("üìä Âª∫Á´ãÈ©óË≠âÊëòË¶ÅÂ∑•‰ΩúË°®...")
                validation_worksheet = self.spreadsheet.add_worksheet(title=self.worksheet_names['validation'], rows=200, cols=10)
            
            # Ê∏ÖÁ©∫ÁèæÊúâÂÖßÂÆπ
            validation_worksheet.clear()
            time.sleep(self.api_settings['rate_limit_delay'])
            
            # Ê∫ñÂÇôÊï∏Êìö
            headers = validation_df.columns.tolist()
            data = validation_df.values.tolist()
            
            # Á¢∫‰øùÊâÄÊúâÊï∏ÊìöÈÉΩÊòØÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÔºåÈÅøÂÖçÊ†ºÂºèÂïèÈ°å
            clean_data = []
            for row in data:
                clean_row = []
                for cell in row:
                    if pd.isna(cell):
                        clean_row.append('')
                    else:
                        clean_row.append(str(cell))
                clean_data.append(clean_row)
            
            # ‰∏äÂÇ≥Ê®ôÈ°å
            validation_worksheet.update('A1', [headers])
            time.sleep(self.api_settings['rate_limit_delay'])
            
            # ‰∏äÂÇ≥Êï∏Êìö
            if clean_data:
                validation_worksheet.update('A2', clean_data)
                time.sleep(self.api_settings['rate_limit_delay'])
            
            # Âè™Ë®≠ÂÆöÊúÄÂü∫Êú¨ÁöÑÊ®ôÈ°åÊ†ºÂºè
            try:
                validation_worksheet.format('A1:E1', {
                    'textFormat': {'bold': True}
                })
            except:
                pass
            
        except Exception as e:
            raise Exception(f"Á∞°Âåñ‰∏äÂÇ≥Â§±Êïó: {e}")

    # ÂÖ∂‰ªñËºîÂä©ÊñπÊ≥ï
    def _clean_stock_code(self, code):
        """Ê∏ÖÁêÜËÇ°Á•®‰ª£ËôüÊ†ºÂºè"""
        if pd.isna(code) or code is None:
            return ''
        
        code_str = str(code).strip()
        
        if code_str.startswith("'"):
            code_str = code_str[1:]
        
        if code_str.isdigit() and len(code_str) == 4:
            return int(code_str)
        
        if '-TW' in code_str:
            parts = code_str.split('-TW')
            if len(parts) == 2 and parts[0].isdigit() and len(parts[0]) == 4:
                return f"{int(parts[0])}-TW"
        
        return code_str

    def _format_numeric_value(self, value):
        """Ê†ºÂºèÂåñÊï∏ÂÄºÔºåËôïÁêÜ NaN ÂíåÁâπÊÆäÂÄº"""
        if pd.isna(value) or value is None:
            return ''
        
        if isinstance(value, (int, float)):
            if math.isnan(value) or math.isinf(value):
                return ''
            if isinstance(value, float):
                if value.is_integer():
                    return str(int(value))
                else:
                    return f"{value:.2f}"
            else:
                return str(value)
        
        return str(value)

    def _ensure_json_compatible(self, value):
        """Á¢∫‰øùÂÄºËàá JSON Áõ∏ÂÆπ"""
        if pd.isna(value) or value is None:
            return ''
        
        if isinstance(value, (int, float)):
            if math.isnan(value) or math.isinf(value):
                return ''
            return str(value)
        
        str_value = str(value)
        if str_value.startswith("'"):
            str_value = str_value[1:]
        
        return str_value if str_value != '' else ''

    def _setup_connection(self) -> bool:
        """Ë®≠ÂÆö Google Sheets ÈÄ£Á∑ö"""
        try:
            if not self.sheet_id:
                print("‚ùå Êú™Ë®≠ÂÆö GOOGLE_SHEET_ID Áí∞Â¢ÉËÆäÊï∏")
                return False
            
            credentials_json = os.getenv('GOOGLE_SHEETS_CREDENTIALS')
            if not credentials_json:
                print("‚ùå Êú™Ë®≠ÂÆö GOOGLE_SHEETS_CREDENTIALS Áí∞Â¢ÉËÆäÊï∏")
                return False
            
            credentials_info = json.loads(credentials_json)
            
            scopes = [
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/drive'
            ]
            
            credentials = Credentials.from_service_account_info(
                credentials_info, scopes=scopes
            )
            
            self.client = gspread.authorize(credentials)
            self.spreadsheet = self.client.open_by_key(self.sheet_id)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Google Sheets ÈÄ£Á∑öË®≠ÂÆöÂ§±Êïó: {e}")
            return False

    def _upload_portfolio_summary(self, portfolio_df: pd.DataFrame) -> bool:
        """‰∏äÂÇ≥ÊäïË≥áÁµÑÂêàÊëòË¶Å"""
        try:
            try:
                portfolio_worksheet = self.spreadsheet.worksheet(self.worksheet_names['portfolio'])
            except gspread.WorksheetNotFound:
                print("üìä Âª∫Á´ãÊäïË≥áÁµÑÂêàÊëòË¶ÅÂ∑•‰ΩúË°®...")
                portfolio_worksheet = self.spreadsheet.add_worksheet(title=self.worksheet_names['portfolio'], rows=1000, cols=20)
            
            portfolio_worksheet.clear()
            time.sleep(self.api_settings['rate_limit_delay'])
            
            portfolio_df_clean = portfolio_df.copy()
            portfolio_df_clean = portfolio_df_clean.fillna('')
            
            if '‰ª£Ëôü' in portfolio_df_clean.columns:
                portfolio_df_clean['‰ª£Ëôü'] = portfolio_df_clean['‰ª£Ëôü'].apply(self._clean_stock_code)
            
            if 'ËÇ°Á•®‰ª£Ëôü' in portfolio_df_clean.columns:
                portfolio_df_clean['ËÇ°Á•®‰ª£Ëôü'] = portfolio_df_clean['ËÇ°Á•®‰ª£Ëôü'].apply(self._clean_stock_code)
            
            numeric_columns = ['ÂàÜÊûêÂ∏´Êï∏Èáè', 'ÁõÆÊ®ôÂÉπ', '2025EPSÂπ≥ÂùáÂÄº', '2026EPSÂπ≥ÂùáÂÄº', '2027EPSÂπ≥ÂùáÂÄº', 'ÂìÅË≥™Ë©ïÂàÜ']
            for col in numeric_columns:
                if col in portfolio_df_clean.columns:
                    portfolio_df_clean[col] = portfolio_df_clean[col].apply(self._format_numeric_value)
            
            headers = portfolio_df_clean.columns.tolist()
            data = portfolio_df_clean.values.tolist()
            
            data = [[self._ensure_json_compatible(cell) for cell in row] for row in data]
            
            portfolio_worksheet.update('A1', [headers])
            time.sleep(self.api_settings['rate_limit_delay'])
            
            if data:
                portfolio_worksheet.update('A2', data)
                time.sleep(self.api_settings['rate_limit_delay'])
            
            return True
            
        except Exception as e:
            print(f"‚ùå ÊäïË≥áÁµÑÂêàÊëòË¶Å‰∏äÂÇ≥Â§±Êïó: {e}")
            return False

    def _upload_detailed_report(self, detailed_df: pd.DataFrame) -> bool:
        """‰∏äÂÇ≥Ë©≥Á¥∞Â†±Âëä"""
        try:
            try:
                detailed_worksheet = self.spreadsheet.worksheet(self.worksheet_names['detailed'])
            except gspread.WorksheetNotFound:
                print("üìä Âª∫Á´ãË©≥Á¥∞Â†±ÂëäÂ∑•‰ΩúË°®...")
                detailed_worksheet = self.spreadsheet.add_worksheet(title=self.worksheet_names['detailed'], rows=2000, cols=25)
            
            detailed_worksheet.clear()
            time.sleep(self.api_settings['rate_limit_delay'])
            
            detailed_df_clean = detailed_df.copy()
            detailed_df_clean = detailed_df_clean.fillna('')
            
            if '‰ª£Ëôü' in detailed_df_clean.columns:
                detailed_df_clean['‰ª£Ëôü'] = detailed_df_clean['‰ª£Ëôü'].apply(self._clean_stock_code)
            
            if 'ËÇ°Á•®‰ª£Ëôü' in detailed_df_clean.columns:
                detailed_df_clean['ËÇ°Á•®‰ª£Ëôü'] = detailed_df_clean['ËÇ°Á•®‰ª£Ëôü'].apply(self._clean_stock_code)
            
            numeric_columns = [
                'ÂàÜÊûêÂ∏´Êï∏Èáè', 'ÁõÆÊ®ôÂÉπ', 'ÂìÅË≥™Ë©ïÂàÜ',
                '2025EPSÊúÄÈ´òÂÄº', '2025EPSÊúÄ‰ΩéÂÄº', '2025EPSÂπ≥ÂùáÂÄº',
                '2026EPSÊúÄÈ´òÂÄº', '2026EPSÊúÄ‰ΩéÂÄº', '2026EPSÂπ≥ÂùáÂÄº',
                '2027EPSÊúÄÈ´òÂÄº', '2027EPSÊúÄ‰ΩéÂÄº', '2027EPSÂπ≥ÂùáÂÄº'
            ]
            for col in numeric_columns:
                if col in detailed_df_clean.columns:
                    detailed_df_clean[col] = detailed_df_clean[col].apply(self._format_numeric_value)
            
            headers = detailed_df_clean.columns.tolist()
            data = detailed_df_clean.values.tolist()
            
            data = [[self._ensure_json_compatible(cell) for cell in row] for row in data]
            
            detailed_worksheet.update('A1', [headers])
            time.sleep(self.api_settings['rate_limit_delay'])
            
            if data:
                # ÂàÜÊâπ‰∏äÂÇ≥Â§ßÈáèË≥áÊñô
                batch_size = self.api_settings['batch_size']
                for i in range(0, len(data), batch_size):
                    batch_data = data[i:i + batch_size]
                    start_row = i + 2
                    range_name = f'A{start_row}'
                    
                    detailed_worksheet.update(range_name, batch_data)
                    time.sleep(self.api_settings['rate_limit_delay'])
                    
                    if i + batch_size < len(data):
                        print(f"   Â∑≤‰∏äÂÇ≥ {i + batch_size}/{len(data)} Ë°å...")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Ë©≥Á¥∞Â†±Âëä‰∏äÂÇ≥Â§±Êïó: {e}")
            return False

    def _upload_keyword_summary(self, keyword_df: pd.DataFrame) -> bool:
        """‰∏äÂÇ≥ÈóúÈçµÂ≠óÁµ±Ë®àÂ†±Âëä"""
        try:
            try:
                worksheet = self.spreadsheet.worksheet(self.worksheet_names['keywords'])
            except gspread.WorksheetNotFound:
                print("üìä Âª∫Á´ãÈóúÈçµÂ≠óÂ∑•‰ΩúË°®...")
                worksheet = self.spreadsheet.add_worksheet(
                    title=self.worksheet_names['keywords'], 
                    rows=1000, 
                    cols=12
                )
            
            worksheet.clear()
            time.sleep(self.api_settings['rate_limit_delay'])
            
            keyword_df_clean = keyword_df.copy()
            keyword_df_clean = keyword_df_clean.fillna('')
            
            numeric_columns = ['‰ΩøÁî®Ê¨°Êï∏', 'Âπ≥ÂùáÂìÅË≥™Ë©ïÂàÜ', 'ÊúÄÈ´òÂìÅË≥™Ë©ïÂàÜ', 'ÊúÄ‰ΩéÂìÅË≥™Ë©ïÂàÜ', 'Áõ∏ÈóúÂÖ¨Âè∏Êï∏Èáè']
            for col in numeric_columns:
                if col in keyword_df_clean.columns:
                    keyword_df_clean[col] = keyword_df_clean[col].apply(self._format_numeric_value)
            
            headers = keyword_df_clean.columns.tolist()
            data = keyword_df_clean.values.tolist()
            
            data = [[self._ensure_json_compatible(cell) for cell in row] for row in data]
            
            worksheet.update('A1', [headers])
            time.sleep(self.api_settings['rate_limit_delay'])
            
            if data:
                worksheet.update('A2', data)
                time.sleep(self.api_settings['rate_limit_delay'])
            
            # Ë®≠ÂÆöÂü∫Êú¨Ê†ºÂºè
            try:
                worksheet.format('A1:J1', {
                    'backgroundColor': {'red': 0.2, 'green': 0.6, 'blue': 0.9},
                    'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}}
                })
                time.sleep(self.api_settings['rate_limit_delay'])
            except:
                pass
            
            return True
            
        except Exception as e:
            print(f"‚ùå ÈóúÈçµÂ≠óÂ†±Âëä‰∏äÂÇ≥Â§±Êïó: {e}")
            return False

    def test_connection(self) -> bool:
        """Ê∏¨Ë©¶ Google Sheets ÈÄ£Á∑ö"""
        try:
            if self._setup_connection():
                spreadsheet_info = self.spreadsheet.title
                print(f"‚úÖ Google Sheets ÈÄ£Á∑öÊàêÂäü: {spreadsheet_info}")
                return True
            else:
                print("‚ùå Google Sheets ÈÄ£Á∑öÂ§±Êïó")
                return False
        except Exception as e:
            print(f"‚ùå Google Sheets ÈÄ£Á∑öÊ∏¨Ë©¶Â§±Êïó: {e}")
            return False

    # üÜï ÂÖ¨Áî®ÊñπÊ≥ïÔºöÂè™ÁîüÊàê CSVÔºå‰∏ç‰∏äÂÇ≥
    def generate_csv_only(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, 
                         keyword_df: pd.DataFrame = None, watchlist_df: pd.DataFrame = None) -> bool:
        """üÜï ÂÖ¨Áî®ÊñπÊ≥ïÔºöÂè™ÁîüÊàê CSV Ê™îÊ°àÔºå‰∏ç‰∏äÂÇ≥Âà∞ Google Sheets"""
        return self._csv_only_mode(portfolio_df, detailed_df, keyword_df, watchlist_df)


# Ê∏¨Ë©¶ÂäüËÉΩ
if __name__ == "__main__":
    uploader = SheetsUploader()
    
    print("=== üîß ‰øÆÂæ©Áâà Sheets Uploader v3.6.1 Ê∏¨Ë©¶ ===")
    
    # Ê∏¨Ë©¶Ë≥áÊñô
    import pandas as pd
    
    test_portfolio = pd.DataFrame([
        {'‰ª£Ëôü': '2330', 'ÂêçÁ®±': 'Âè∞Á©çÈõª', 'ÂìÅË≥™Ë©ïÂàÜ': 10.0, 'ÁãÄÊÖã': 'üü¢ ÂÆåÊï¥'},
        {'‰ª£Ëôü': '6462', 'ÂêçÁ®±': 'Á•ûÁõæ', 'ÂìÅË≥™Ë©ïÂàÜ': 7.0, 'ÁãÄÊÖã': 'üü° ËâØÂ•Ω'}
    ])
    
    test_detailed = pd.DataFrame([
        {'‰ª£Ëôü': '2330', 'ÂêçÁ®±': 'Âè∞Á©çÈõª', 'ÂìÅË≥™Ë©ïÂàÜ': 10.0, 'È©óË≠âÁãÄÊÖã': '‚úÖ ÈÄöÈÅé'},
        {'‰ª£Ëôü': '6462', 'ÂêçÁ®±': 'Á•ûÁõæ', 'ÂìÅË≥™Ë©ïÂàÜ': 7.0, 'È©óË≠âÁãÄÊÖã': '‚ö†Ô∏è È©óË≠âÂÅúÁî®'}
    ])
    
    test_watchlist = pd.DataFrame([
        {
            'ÂÖ¨Âè∏‰ª£Ëôü': '2330',
            'ÂÖ¨Âè∏ÂêçÁ®±': 'Âè∞Á©çÈõª',
            'MDÊ™îÊ°àÊï∏Èáè': 2,
            'ËôïÁêÜÁãÄÊÖã': '‚úÖ Â∑≤ËôïÁêÜ',
            'Âπ≥ÂùáÂìÅË≥™Ë©ïÂàÜ': 9.2,
            'ÊúÄÈ´òÂìÅË≥™Ë©ïÂàÜ': 10.0,
            'ÊêúÂ∞ãÈóúÈçµÂ≠óÊï∏Èáè': 4,
            '‰∏ªË¶ÅÈóúÈçµÂ≠ó': 'Âè∞Á©çÈõª, factset, eps',
            'ÈóúÈçµÂ≠óÂπ≥ÂùáÂìÅË≥™': 8.5,
            'ÊúÄÊñ∞Ê™îÊ°àÊó•Êúü': '2025-06-24',
            'È©óË≠âÁãÄÊÖã': '‚úÖ È©óË≠âÈÄöÈÅé'
        }
    ])
    
    print("Ê∏¨Ë©¶ 1: CSV-only Ê®°Âºè")
    success = uploader.generate_csv_only(test_portfolio, test_detailed, None, test_watchlist)
    if success:
        print("   ‚úÖ CSV-only Ê®°ÂºèÊ∏¨Ë©¶ÊàêÂäü")
    else:
        print("   ‚ùå CSV-only Ê®°ÂºèÊ∏¨Ë©¶Â§±Êïó")
    
    print("\nÊ∏¨Ë©¶ 2: ‰∏äÂÇ≥ÂâçÈ©óË≠â")
    validation_result = uploader._validate_before_upload_v361(test_portfolio, test_detailed, test_watchlist)
    print(f"   È©óË≠âÁµêÊûú: {validation_result['safe_to_upload']}")
    print(f"   È©óË≠âÊëòË¶Å: {validation_result['summary']}")
    
    print("\nÊ∏¨Ë©¶ 3: API ÂèØÁî®ÊÄßÊ™¢Êü•")
    api_available = uploader._check_api_availability()
    print(f"   API ÂèØÁî®: {api_available}")
    
    print(f"\nüéâ ‰øÆÂæ©Áâà Sheets Uploader v3.6.1 Ê∏¨Ë©¶ÂÆåÊàê!")
    print(f"‚úÖ ‰øÆÂæ© columnWidth API ÈåØË™§")
    print(f"‚úÖ Â¢ûÂä† API ÈôêÂà∂‰øùË≠∑Ê©üÂà∂")
    print(f"‚úÖ ÊîØÊè¥ CSV-only Ê®°Âºè")
    print(f"‚úÖ Â¢ûÂº∑ÈåØË™§ËôïÁêÜÂíåÈáçË©¶Ê©üÂà∂")
    print(f"‚úÖ Ëá™Âãï fallback Âà∞ CSV Ê®°Âºè")
    
    print(f"\nüí° ‰ΩøÁî®Âª∫Ë≠∞:")
    print(f"   Â∞çÊñºÂ§ßÈáèË≥áÊñôÊàñ API ÈôêÂà∂ÊÉÖÊ≥ÅÔºå‰ΩøÁî® csv_only=True")
    print(f"   Á≥ªÁµ±ÊúÉËá™ÂãïÊ™¢Ê∏¨ API ÂïèÈ°å‰∏¶ÂàáÊèõÂà∞ CSV Ê®°Âºè")
    print(f"   ÊâÄÊúâ CSV Ê™îÊ°àÈÉΩÊúâÂÆåÊï¥ÁöÑ‰ΩøÁî®ÊåáÂçó")