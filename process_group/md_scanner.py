#!/usr/bin/env python3
"""
MD Scanner - FactSet Pipeline v3.6.1 (Refined)
å°ˆé–€æƒæå’Œç®¡ç† data/md/ æª”æ¡ˆå¤¾ä¸­çš„ MD æª”æ¡ˆ
å®Œå…¨ç¨ç«‹ï¼Œæ”¯æ´è§€å¯Ÿåå–®çµ±è¨ˆåˆ†æ

æª”æ¡ˆåç¨±: process_group/md_scanner.py
åŠŸèƒ½:
- æƒææ‰€æœ‰ MD æª”æ¡ˆ
- æ‰¾å‡ºæœ€è¿‘çš„æª”æ¡ˆ  
- ä¾å…¬å¸ä»£è™Ÿå°‹æ‰¾æª”æ¡ˆ
- æå–æª”æ¡ˆè³‡è¨Š
- æ”¯æ´è§€å¯Ÿåå–®è¦†è“‹çµ±è¨ˆ
- å¢å¼·éŒ¯èª¤è™•ç†å’Œæ—¥èªŒ
"""

import os
import glob
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

class MDScanner:
    """
    MD æª”æ¡ˆæƒæå™¨ v3.6.1 (Refined) - è™•ç†ç¾¤çµ„çš„æª”æ¡ˆç³»çµ±ä»‹é¢
    è² è²¬æƒæ data/md/ ç›®éŒ„ä¸­çš„æ‰€æœ‰ MD æª”æ¡ˆï¼Œæ”¯æ´è§€å¯Ÿåå–®çµ±è¨ˆ
    """

    def __init__(self, md_dir="data/md"):
        self.md_dir = md_dir
        self.version = "3.6.1"
        self._ensure_md_directory()
        
        # æª”æ¡ˆåç¨±é©—è­‰æ¨¡å¼
        self.filename_pattern = re.compile(r'^(\d{4})_([^_]+)_([^_]+)_([^_]+)_?.*\.md$')
        
        # çµ±è¨ˆè³‡æ–™å¿«å–
        self._stats_cache = {}
        self._cache_timestamp = None
        self._cache_duration = 300  # 5åˆ†é˜å¿«å–
    
    def scan_all_md_files(self) -> List[str]:
        """
        æƒææ‰€æœ‰ MD æª”æ¡ˆ
        è¿”å›: æŒ‰æ™‚é–“æ’åºçš„æª”æ¡ˆè·¯å¾‘æ¸…å–® (æœ€æ–°çš„åœ¨å‰)
        """
        try:
            pattern = os.path.join(self.md_dir, "*.md")
            md_files = glob.glob(pattern)
            
            # éæ¿¾æœ‰æ•ˆçš„ MD æª”æ¡ˆ
            valid_files = []
            for file_path in md_files:
                if self._is_valid_md_file(file_path):
                    valid_files.append(file_path)
                else:
                    print(f"âš ï¸ è·³éç„¡æ•ˆæª”æ¡ˆ: {os.path.basename(file_path)}")
            
            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº (æœ€æ–°çš„åœ¨å‰)
            valid_files.sort(key=self._get_file_mtime, reverse=True)
            
            return valid_files
            
        except Exception as e:
            print(f"âŒ æƒæ MD æª”æ¡ˆå¤±æ•—: {e}")
            return []
    
    def scan_recent_files(self, hours=24) -> List[str]:
        """
        æƒææœ€è¿‘ N å°æ™‚çš„ MD æª”æ¡ˆ
        åƒæ•¸: hours - å°æ™‚æ•¸ (é è¨­ 24 å°æ™‚)
        è¿”å›: æœ€è¿‘æª”æ¡ˆæ¸…å–®
        """
        try:
            all_files = self.scan_all_md_files()
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            recent_files = []
            for file_path in all_files:
                file_time = self._get_file_datetime(file_path)
                if file_time and file_time > cutoff_time:
                    recent_files.append(file_path)
            
            return recent_files
            
        except Exception as e:
            print(f"âŒ æƒææœ€è¿‘æª”æ¡ˆå¤±æ•—: {e}")
            return []
    
    def find_company_files(self, company_code: str) -> List[str]:
        """
        å°‹æ‰¾ç‰¹å®šå…¬å¸çš„æ‰€æœ‰ MD æª”æ¡ˆ
        åƒæ•¸: company_code - å…¬å¸ä»£è™Ÿ (å¦‚ "2330")
        è¿”å›: è©²å…¬å¸çš„æª”æ¡ˆæ¸…å–® (æŒ‰æ™‚é–“æ’åºï¼Œæœ€æ–°åœ¨å‰)
        """
        try:
            # æ¸…ç†å…¬å¸ä»£è™Ÿ
            clean_code = str(company_code).strip()
            if not self._is_valid_company_code(clean_code):
                print(f"âš ï¸ ç„¡æ•ˆçš„å…¬å¸ä»£è™Ÿæ ¼å¼: {company_code}")
                return []
            
            # æª”æ¡ˆåç¨±æ ¼å¼: {company_code}_{company_name}_{source}_{hash}_{timestamp}.md
            pattern = os.path.join(self.md_dir, f"{clean_code}_*.md")
            company_files = glob.glob(pattern)
            
            # é©—è­‰æª”æ¡ˆåç¨±æ ¼å¼æ­£ç¢º
            validated_files = []
            for file_path in company_files:
                if self._is_valid_md_filename(file_path, clean_code):
                    validated_files.append(file_path)
                else:
                    print(f"âš ï¸ æª”æ¡ˆæ ¼å¼ä¸ç¬¦: {os.path.basename(file_path)}")
            
            # æŒ‰æ™‚é–“æ’åº
            validated_files.sort(key=self._get_file_mtime, reverse=True)
            
            return validated_files
            
        except Exception as e:
            print(f"âŒ å°‹æ‰¾å…¬å¸æª”æ¡ˆå¤±æ•— ({company_code}): {e}")
            return []
    
    def get_latest_file_per_company(self) -> Dict[str, str]:
        """
        å–å¾—æ¯å®¶å…¬å¸çš„æœ€æ–° MD æª”æ¡ˆ
        è¿”å›: {company_code: latest_file_path} å­—å…¸
        """
        try:
            all_files = self.scan_all_md_files()
            company_latest = {}
            
            for file_path in all_files:
                company_code = self._extract_company_code(file_path)
                if company_code:
                    # å¦‚æœæ˜¯è©²å…¬å¸ç¬¬ä¸€å€‹æª”æ¡ˆï¼Œæˆ–è€…æ¯”ç¾æœ‰æª”æ¡ˆæ›´æ–°
                    if (company_code not in company_latest or 
                        self._get_file_mtime(file_path) > self._get_file_mtime(company_latest[company_code])):
                        company_latest[company_code] = file_path
            
            return company_latest
            
        except Exception as e:
            print(f"âŒ å–å¾—æœ€æ–°æª”æ¡ˆå¤±æ•—: {e}")
            return {}
    
    def get_file_info(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        å–å¾— MD æª”æ¡ˆçš„è©³ç´°è³‡è¨Š
        åƒæ•¸: file_path - æª”æ¡ˆè·¯å¾‘
        è¿”å›: æª”æ¡ˆè³‡è¨Šå­—å…¸
        """
        try:
            if not os.path.exists(file_path):
                return None
            
            filename = os.path.basename(file_path)
            
            # è§£ææª”æ¡ˆåç¨±: ä»£è™Ÿ_åç¨±_ä¾†æº_hash_æ™‚é–“.md
            # ä¾‹å¦‚: 2330_å°ç©é›»_factset_abc123_0626_1030.md
            name_parts = filename.replace('.md', '').split('_')
            
            info = {
                'file_path': file_path,
                'filename': filename,
                'file_size': os.path.getsize(file_path),
                'file_mtime': self._get_file_datetime(file_path),
                'company_code': name_parts[0] if len(name_parts) >= 1 else 'Unknown',
                'company_name': name_parts[1] if len(name_parts) >= 2 else 'Unknown',
                'data_source': name_parts[2] if len(name_parts) >= 3 else 'Unknown',
                'file_hash': name_parts[3] if len(name_parts) >= 4 else 'Unknown',
                'timestamp_str': name_parts[4] if len(name_parts) >= 5 else 'Unknown',
                'valid_format': self._is_valid_md_filename(file_path),
                'size_mb': round(os.path.getsize(file_path) / (1024 * 1024), 2)
            }
            
            # å˜—è©¦è§£ææ™‚é–“æˆ³è¨˜
            if len(name_parts) >= 5:
                try:
                    # æ™‚é–“æ ¼å¼: MMDD_HHMM (å¦‚ 0626_1030)
                    month_day = name_parts[4]
                    hour_min = name_parts[5] if len(name_parts) >= 6 else '0000'
                    
                    if len(month_day) == 4 and len(hour_min) == 4:
                        month = int(month_day[:2])
                        day = int(month_day[2:])
                        hour = int(hour_min[:2])
                        minute = int(hour_min[2:])
                        
                        # å‡è¨­æ˜¯ç•¶å¹´
                        current_year = datetime.now().year
                        parsed_time = datetime(current_year, month, day, hour, minute)
                        info['parsed_timestamp'] = parsed_time
                except (ValueError, IndexError):
                    info['parsed_timestamp'] = None
            
            return info
            
        except Exception as e:
            print(f"âŒ å–å¾—æª”æ¡ˆè³‡è¨Šå¤±æ•— ({file_path}): {e}")
            return None
    
    def count_files_by_company(self) -> Dict[str, int]:
        """
        çµ±è¨ˆæ¯å®¶å…¬å¸çš„æª”æ¡ˆæ•¸é‡
        è¿”å›: {company_code: file_count} å­—å…¸
        """
        try:
            all_files = self.scan_all_md_files()
            company_counts = {}
            
            for file_path in all_files:
                company_code = self._extract_company_code(file_path)
                if company_code:
                    company_counts[company_code] = company_counts.get(company_code, 0) + 1
            
            return company_counts
            
        except Exception as e:
            print(f"âŒ çµ±è¨ˆå…¬å¸æª”æ¡ˆæ•¸é‡å¤±æ•—: {e}")
            return {}
    
    def get_watchlist_coverage_stats(self, watchlist_codes: List[str]) -> Dict[str, Any]:
        """
        ğŸ†• v3.6.1 è¨ˆç®—è§€å¯Ÿåå–®è¦†è“‹çµ±è¨ˆ
        åƒæ•¸: watchlist_codes - è§€å¯Ÿåå–®å…¬å¸ä»£è™Ÿæ¸…å–®
        è¿”å›: è¦†è“‹çµ±è¨ˆè³‡è¨Š
        """
        try:
            all_files = self.scan_all_md_files()
            processed_codes = set()
            
            # æ”¶é›†å·²è™•ç†çš„å…¬å¸ä»£è™Ÿ
            for file_path in all_files:
                company_code = self._extract_company_code(file_path)
                if company_code:
                    processed_codes.add(company_code)
            
            # è¨ˆç®—è¦†è“‹çµ±è¨ˆ
            total_watchlist = len(watchlist_codes)
            covered_companies = len([code for code in watchlist_codes if code in processed_codes])
            missing_companies = [code for code in watchlist_codes if code not in processed_codes]
            
            coverage_rate = (covered_companies / total_watchlist) * 100 if total_watchlist > 0 else 0
            
            # æŒ‰å…¬å¸ä»£è™Ÿç¯„åœåˆ†æè¦†è“‹æƒ…æ³
            coverage_by_range = self._analyze_coverage_by_range(watchlist_codes, processed_codes)
            
            return {
                'total_watchlist_companies': total_watchlist,
                'companies_with_files': covered_companies,
                'missing_companies': missing_companies,
                'missing_count': len(missing_companies),
                'coverage_rate': round(coverage_rate, 1),
                'coverage_by_range': coverage_by_range,
                'analysis_timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ è§€å¯Ÿåå–®è¦†è“‹çµ±è¨ˆå¤±æ•—: {e}")
            return {
                'total_watchlist_companies': 0,
                'companies_with_files': 0,
                'coverage_rate': 0.0,
                'error': str(e)
            }
    
    def get_stats(self, force_refresh=False) -> Dict[str, Any]:
        """
        å–å¾— MD æª”æ¡ˆçµ±è¨ˆè³‡è¨Š (å¸¶å¿«å–)
        è¿”å›: çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        try:
            # æª¢æŸ¥å¿«å–
            if not force_refresh and self._is_cache_valid():
                return self._stats_cache
            
            all_files = self.scan_all_md_files()
            recent_files = self.scan_recent_files(24)
            company_counts = self.count_files_by_company()
            
            # è¨ˆç®—æª”æ¡ˆå¤§å°
            total_size = 0
            file_sizes = []
            for f in all_files:
                if os.path.exists(f):
                    size = os.path.getsize(f)
                    total_size += size
                    file_sizes.append(size)
            
            # è¨ˆç®—æ™‚é–“ç¯„åœ
            oldest_file = min(all_files, key=self._get_file_mtime) if all_files else None
            newest_file = max(all_files, key=self._get_file_mtime) if all_files else None
            
            # æª”æ¡ˆå¤§å°çµ±è¨ˆ
            size_stats = {}
            if file_sizes:
                size_stats = {
                    'total_size_mb': round(total_size / (1024 * 1024), 2),
                    'average_size_kb': round(sum(file_sizes) / len(file_sizes) / 1024, 2),
                    'largest_file_mb': round(max(file_sizes) / (1024 * 1024), 2),
                    'smallest_file_kb': round(min(file_sizes) / 1024, 2)
                }
            
            # æ•¸æ“šå“è³ªçµ±è¨ˆ
            quality_stats = self._analyze_file_quality(all_files)
            
            stats = {
                'version': self.version,
                'scan_timestamp': datetime.now().isoformat(),
                'total_files': len(all_files),
                'recent_files_24h': len(recent_files),
                'unique_companies': len(company_counts),
                'companies_with_files': company_counts,
                'oldest_file': oldest_file,
                'newest_file': newest_file,
                'file_size_stats': size_stats,
                'quality_stats': quality_stats,
                'top_companies_by_files': self._get_top_companies(company_counts, 10)
            }
            
            # æ›´æ–°å¿«å–
            self._stats_cache = stats
            self._cache_timestamp = datetime.now()
            
            return stats
            
        except Exception as e:
            print(f"âŒ å–å¾—çµ±è¨ˆè³‡è¨Šå¤±æ•—: {e}")
            return {
                'version': self.version,
                'error': str(e),
                'total_files': 0,
                'unique_companies': 0
            }
    
    # ç§æœ‰æ–¹æ³•
    
    def _ensure_md_directory(self):
        """ç¢ºä¿ MD ç›®éŒ„å­˜åœ¨"""
        try:
            Path(self.md_dir).mkdir(parents=True, exist_ok=True)
        except Exception as e:
            print(f"âŒ å»ºç«‹ MD ç›®éŒ„å¤±æ•—: {e}")
    
    def _get_file_mtime(self, file_path: str) -> float:
        """å–å¾—æª”æ¡ˆä¿®æ”¹æ™‚é–“ (timestamp)"""
        try:
            return os.path.getmtime(file_path)
        except OSError:
            return 0
    
    def _get_file_datetime(self, file_path: str) -> Optional[datetime]:
        """å–å¾—æª”æ¡ˆä¿®æ”¹æ™‚é–“ (datetime ç‰©ä»¶)"""
        try:
            timestamp = os.path.getmtime(file_path)
            return datetime.fromtimestamp(timestamp)
        except OSError:
            return None
    
    def _extract_company_code(self, file_path: str) -> Optional[str]:
        """å¾æª”æ¡ˆè·¯å¾‘æå–å…¬å¸ä»£è™Ÿ"""
        try:
            filename = os.path.basename(file_path)
            
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…
            match = self.filename_pattern.match(filename)
            if match:
                company_code = match.group(1)
                if self._is_valid_company_code(company_code):
                    return company_code
            
            # å›é€€åˆ°åˆ†å‰²æ–¹æ³•
            parts = filename.replace('.md', '').split('_')
            if len(parts) >= 1:
                company_code = parts[0]
                if self._is_valid_company_code(company_code):
                    return company_code
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ æå–å…¬å¸ä»£è™Ÿå¤±æ•— ({file_path}): {e}")
            return None
    
    def _is_valid_company_code(self, code: str) -> bool:
        """é©—è­‰å…¬å¸ä»£è™Ÿæ ¼å¼"""
        try:
            if not code or not isinstance(code, str):
                return False
            
            clean_code = code.strip()
            
            # å¿…é ˆæ˜¯4ä½æ•¸å­—
            if not (clean_code.isdigit() and len(clean_code) == 4):
                return False
            
            # æª¢æŸ¥æ•¸å­—ç¯„åœ (å°è‚¡ä»£è™Ÿç¯„åœ)
            code_num = int(clean_code)
            return 1000 <= code_num <= 9999
            
        except (ValueError, TypeError):
            return False
    
    def _is_valid_md_file(self, file_path: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ MD æª”æ¡ˆ"""
        try:
            if not file_path.endswith('.md'):
                return False
            
            if not os.path.exists(file_path):
                return False
            
            # æª¢æŸ¥æª”æ¡ˆå¤§å°
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                return False
            
            # æª¢æŸ¥æª”æ¡ˆåç¨±æ ¼å¼
            return self._is_valid_md_filename(file_path)
            
        except Exception:
            return False
    
    def _is_valid_md_filename(self, file_path: str, expected_company_code: str = None) -> bool:
        """
        é©—è­‰ MD æª”æ¡ˆåç¨±æ ¼å¼æ˜¯å¦æ­£ç¢º
        é æœŸæ ¼å¼: {company_code}_{company_name}_{source}_{hash}_{timestamp}.md
        """
        try:
            filename = os.path.basename(file_path)
            
            if not filename.endswith('.md'):
                return False
            
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼é©—è­‰
            match = self.filename_pattern.match(filename)
            if not match:
                return False
            
            company_code = match.group(1)
            
            # é©—è­‰å…¬å¸ä»£è™Ÿæ ¼å¼
            if not self._is_valid_company_code(company_code):
                return False
            
            # å¦‚æœæŒ‡å®šäº†ç‰¹å®šå…¬å¸ä»£è™Ÿï¼Œè¦å®Œå…¨åŒ¹é…
            if expected_company_code and company_code != expected_company_code:
                return False
            
            return True
            
        except Exception:
            return False
    
    def _analyze_coverage_by_range(self, watchlist_codes: List[str], processed_codes: set) -> Dict[str, Dict]:
        """åˆ†æä¸åŒä»£è™Ÿç¯„åœçš„è¦†è“‹æƒ…æ³"""
        ranges = {
            '1000-2999': {'total': 0, 'covered': 0},
            '3000-5999': {'total': 0, 'covered': 0},
            '6000-8999': {'total': 0, 'covered': 0},
            '9000+': {'total': 0, 'covered': 0}
        }
        
        for code in watchlist_codes:
            try:
                code_num = int(code)
                range_key = None
                
                if 1000 <= code_num <= 2999:
                    range_key = '1000-2999'
                elif 3000 <= code_num <= 5999:
                    range_key = '3000-5999'
                elif 6000 <= code_num <= 8999:
                    range_key = '6000-8999'
                else:
                    range_key = '9000+'
                
                if range_key:
                    ranges[range_key]['total'] += 1
                    if code in processed_codes:
                        ranges[range_key]['covered'] += 1
                        
            except ValueError:
                continue
        
        # è¨ˆç®—è¦†è“‹ç‡
        for range_key, stats in ranges.items():
            if stats['total'] > 0:
                stats['coverage_rate'] = round((stats['covered'] / stats['total']) * 100, 1)
            else:
                stats['coverage_rate'] = 0.0
        
        return ranges
    
    def _analyze_file_quality(self, file_paths: List[str]) -> Dict[str, Any]:
        """åˆ†ææª”æ¡ˆå“è³ªçµ±è¨ˆ"""
        try:
            quality_stats = {
                'valid_format_files': 0,
                'invalid_format_files': 0,
                'empty_files': 0,
                'large_files': 0,  # > 50KB
                'very_large_files': 0,  # > 500KB
                'recent_files': 0,  # æœ€è¿‘7å¤©
                'old_files': 0  # è¶…é30å¤©
            }
            
            cutoff_recent = datetime.now() - timedelta(days=7)
            cutoff_old = datetime.now() - timedelta(days=30)
            
            for file_path in file_paths:
                try:
                    # æ ¼å¼æª¢æŸ¥
                    if self._is_valid_md_filename(file_path):
                        quality_stats['valid_format_files'] += 1
                    else:
                        quality_stats['invalid_format_files'] += 1
                    
                    # å¤§å°æª¢æŸ¥
                    file_size = os.path.getsize(file_path)
                    if file_size == 0:
                        quality_stats['empty_files'] += 1
                    elif file_size > 500 * 1024:  # 500KB
                        quality_stats['very_large_files'] += 1
                    elif file_size > 50 * 1024:  # 50KB
                        quality_stats['large_files'] += 1
                    
                    # æ™‚é–“æª¢æŸ¥
                    file_time = self._get_file_datetime(file_path)
                    if file_time:
                        if file_time > cutoff_recent:
                            quality_stats['recent_files'] += 1
                        elif file_time < cutoff_old:
                            quality_stats['old_files'] += 1
                            
                except Exception as e:
                    print(f"âš ï¸ åˆ†ææª”æ¡ˆå“è³ªå¤±æ•— ({file_path}): {e}")
                    continue
            
            return quality_stats
            
        except Exception as e:
            print(f"âŒ æª”æ¡ˆå“è³ªåˆ†æå¤±æ•—: {e}")
            return {}
    
    def _get_top_companies(self, company_counts: Dict[str, int], top_n: int) -> List[Tuple[str, int]]:
        """å–å¾—æª”æ¡ˆæ•¸é‡æœ€å¤šçš„å‰ N å®¶å…¬å¸"""
        try:
            sorted_companies = sorted(company_counts.items(), key=lambda x: x[1], reverse=True)
            return sorted_companies[:top_n]
        except Exception:
            return []
    
    def _is_cache_valid(self) -> bool:
        """æª¢æŸ¥å¿«å–æ˜¯å¦æœ‰æ•ˆ"""
        if not self._cache_timestamp or not self._stats_cache:
            return False
        
        cache_age = (datetime.now() - self._cache_timestamp).total_seconds()
        return cache_age < self._cache_duration


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    # å»ºç«‹ MD æƒæå™¨
    scanner = MDScanner()
    
    print(f"=== MD æª”æ¡ˆæƒæå™¨æ¸¬è©¦ v{scanner.version} ===")
    
    # æƒææ‰€æœ‰æª”æ¡ˆ
    all_files = scanner.scan_all_md_files()
    print(f"\næ‰¾åˆ° {len(all_files)} å€‹ MD æª”æ¡ˆ:")
    for file_path in all_files[:5]:  # åªé¡¯ç¤ºå‰ 5 å€‹
        info = scanner.get_file_info(file_path)
        if info:
            print(f"  {info['company_code']} - {info['company_name']} ({info['filename']}) - {info['size_mb']}MB")
    
    # æƒææœ€è¿‘æª”æ¡ˆ
    recent_files = scanner.scan_recent_files(24)
    print(f"\næœ€è¿‘ 24 å°æ™‚å…§çš„æª”æ¡ˆ: {len(recent_files)} å€‹")
    
    # å°‹æ‰¾ç‰¹å®šå…¬å¸
    company_code = "2330"
    company_files = scanner.find_company_files(company_code)
    print(f"\nå…¬å¸ {company_code} çš„æª”æ¡ˆ: {len(company_files)} å€‹")
    
    # æ¯å®¶å…¬å¸æœ€æ–°æª”æ¡ˆ
    latest_per_company = scanner.get_latest_file_per_company()
    print(f"\næ¯å®¶å…¬å¸æœ€æ–°æª”æ¡ˆ: {len(latest_per_company)} å®¶å…¬å¸")
    
    # ğŸ†• è§€å¯Ÿåå–®è¦†è“‹æ¸¬è©¦
    test_watchlist = ['2330', '2317', '6462', '2454', '1234']  # åŒ…å«å¯èƒ½ä¸å­˜åœ¨çš„å…¬å¸
    coverage_stats = scanner.get_watchlist_coverage_stats(test_watchlist)
    print(f"\nğŸ†• è§€å¯Ÿåå–®è¦†è“‹çµ±è¨ˆ:")
    print(f"   ç¸½è§€å¯Ÿåå–®: {coverage_stats['total_watchlist_companies']}")
    print(f"   æœ‰æª”æ¡ˆå…¬å¸: {coverage_stats['companies_with_files']}")
    print(f"   è¦†è“‹ç‡: {coverage_stats['coverage_rate']}%")
    print(f"   ç¼ºå¤±å…¬å¸: {coverage_stats['missing_companies']}")
    
    # çµ±è¨ˆè³‡è¨Š
    stats = scanner.get_stats()
    print(f"\n=== çµ±è¨ˆè³‡è¨Š v{stats['version']} ===")
    print(f"ç¸½æª”æ¡ˆæ•¸: {stats['total_files']}")
    print(f"æœ€è¿‘ 24h: {stats['recent_files_24h']}")
    print(f"å…¬å¸æ•¸é‡: {stats['unique_companies']}")
    
    if 'file_size_stats' in stats:
        size_stats = stats['file_size_stats']
        print(f"ç¸½å¤§å°: {size_stats.get('total_size_mb', 0)} MB")
        print(f"å¹³å‡å¤§å°: {size_stats.get('average_size_kb', 0)} KB")
    
    if 'quality_stats' in stats:
        quality_stats = stats['quality_stats']
        print(f"æœ‰æ•ˆæ ¼å¼æª”æ¡ˆ: {quality_stats.get('valid_format_files', 0)}")
        print(f"ç„¡æ•ˆæ ¼å¼æª”æ¡ˆ: {quality_stats.get('invalid_format_files', 0)}")
    
    # æŒ‰å…¬å¸æª”æ¡ˆæ•¸é‡æ’åº
    if 'top_companies_by_files' in stats:
        top_companies = stats['top_companies_by_files']
        print(f"\næª”æ¡ˆæœ€å¤šçš„å‰ 5 å®¶å…¬å¸:")
        for company, count in top_companies[:5]:
            print(f"  {company}: {count} å€‹æª”æ¡ˆ")
    
    print(f"\nâœ… v{scanner.version} MD æƒæå™¨æ¸¬è©¦å®Œæˆï¼")
    print(f"ğŸ†• æ–°åŠŸèƒ½: è§€å¯Ÿåå–®è¦†è“‹çµ±è¨ˆã€å¢å¼·æª”æ¡ˆå“è³ªåˆ†æã€æ™ºèƒ½å¿«å–")