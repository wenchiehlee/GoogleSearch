#!/usr/bin/env python3
"""
MD Parser - FactSet Pipeline v3.5.1
Fixed validation against è§€å¯Ÿåå–®.csv with stricter checks
"""

import os
import re
import yaml
import pandas as pd
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
import statistics

class MDParser:
    def __init__(self):
        """åˆå§‹åŒ– MD è§£æå™¨ - v3.5.1 ä¿®æ­£è§€å¯Ÿåå–®é©—è­‰"""
        
        # åŸæœ‰çš„æ¨¡å¼ä¿æŒä¸è®Š
        self.date_patterns = [
            r'\*\s*(\d{4})-(\d{1,2})-(\d{1,2})\s+\d{1,2}:\d{1,2}',
            r'\*\s*æ›´æ–°[ï¼š:]\s*(\d{4})-(\d{1,2})-(\d{1,2})\s+\d{1,2}:\d{1,2}',
            r'æ›´æ–°[ï¼š:]\s*(\d{4})-(\d{1,2})-(\d{1,2})\s+\d{1,2}:\d{1,2}',
            r'é‰…äº¨ç¶²æ–°èä¸­å¿ƒ\s*\n\s*\n\s*(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[é€±å‘¨]?[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]?\s*[ä¸Šä¸‹]åˆ\s*\d{1,2}:\d{1,2}',
            r'é‰…äº¨ç¶²æ–°èä¸­å¿ƒ\s*\n\s*\n\s*(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',
            r'é‰…äº¨ç¶²æ–°èä¸­å¿ƒ[\s\n]+(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[é€±å‘¨]?[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]?',
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[é€±å‘¨]?[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]?\s*[ä¸Šä¸‹]åˆ\s*\d{1,2}:\d{1,2}',
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥[é€±å‘¨]?[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]?',
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥',
            r'(\d{4})-(\d{1,2})-(\d{1,2})\s+\d{1,2}:\d{1,2}:\d{1,2}',
            r'(\d{4})-(\d{1,2})-(\d{1,2})\s+\d{1,2}:\d{1,2}',
            r'(\d{4})-(\d{1,2})-(\d{1,2})',
            r'(\d{4})/(\d{1,2})/(\d{1,2})',
        ]
        
        self.eps_patterns = [
            r'(\d{4})å¹´[^|]*\|\s*([0-9]+\.?[0-9]*)',
            r'(\d{4})\s*å¹´\s*[:ï¼š]?\s*([0-9]+\.?[0-9]*)',
            r'(\d{4})\s*eps\s*[é ä¼°é æ¸¬ä¼°ç®—]*\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
            r'eps\s*(\d{4})\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
            r'å¹³å‡å€¼[^|]*(\d{4})[^|]*\|\s*([0-9]+\.?[0-9]*)',
            r'ä¸­ä½æ•¸[^|]*(\d{4})[^|]*\|\s*([0-9]+\.?[0-9]*)',
        ]
        
        self.target_price_patterns = [
            r'ç›®æ¨™åƒ¹\s*[:ï¼šç‚º]\s*([0-9]+\.?[0-9]*)\s*å…ƒ',
            r'é ä¼°ç›®æ¨™åƒ¹\s*[:ï¼šç‚º]\s*([0-9]+\.?[0-9]*)\s*å…ƒ',
            r'target\s*price\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
        ]
        
        self.analyst_patterns = [
            r'å…±\s*(\d+)\s*ä½åˆ†æå¸«',
            r'(\d+)\s*ä½åˆ†æå¸«',
            r'(\d+)\s*analysts?',
        ]

        # ğŸ”§ è¼‰å…¥è§€å¯Ÿåå–®ä¸¦é€²è¡Œåš´æ ¼é©—è­‰
        self.watch_list_mapping = self._load_watch_list_mapping_strict()
        self.validation_enabled = len(self.watch_list_mapping) > 0

    def _load_watch_list_mapping_strict(self) -> Dict[str, str]:
        """ğŸ”§ v3.5.1 åš´æ ¼è¼‰å…¥è§€å¯Ÿåå–®ä¸¦é©—è­‰"""
        mapping = {}
        
        possible_paths = [
            'è§€å¯Ÿåå–®.csv',
            '../è§€å¯Ÿåå–®.csv',
            '../../è§€å¯Ÿåå–®.csv',
            'data/è§€å¯Ÿåå–®.csv',
            '../data/è§€å¯Ÿåå–®.csv'
        ]
        
        for csv_path in possible_paths:
            if os.path.exists(csv_path):
                try:
                    print(f"ğŸ” å˜—è©¦è¼‰å…¥è§€å¯Ÿåå–®: {csv_path}")
                    
                    # ğŸ”§ ä½¿ç”¨å¤šç¨®ç·¨ç¢¼å˜—è©¦è®€å–
                    encodings = ['utf-8', 'utf-8-sig', 'big5', 'gbk', 'cp950']
                    df = None
                    
                    for encoding in encodings:
                        try:
                            df = pd.read_csv(csv_path, header=None, names=['code', 'name'], encoding=encoding)
                            print(f"âœ… æˆåŠŸä½¿ç”¨ {encoding} ç·¨ç¢¼è®€å–")
                            break
                        except UnicodeDecodeError:
                            continue
                    
                    if df is None:
                        print(f"âŒ ç„¡æ³•ä½¿ç”¨ä»»ä½•ç·¨ç¢¼è®€å– {csv_path}")
                        continue
                    
                    # ğŸ”§ åš´æ ¼é©—è­‰å’Œæ¸…ç†æ•¸æ“š
                    valid_count = 0
                    invalid_count = 0
                    duplicate_count = 0
                    
                    for idx, row in df.iterrows():
                        try:
                            # æå–ä¸¦æ¸…ç†ä»£è™Ÿå’Œåç¨±
                            code = str(row['code']).strip()
                            name = str(row['name']).strip()
                            
                            # ğŸ”§ åš´æ ¼é©—è­‰å…¬å¸ä»£è™Ÿæ ¼å¼
                            if not self._is_valid_company_code(code):
                                print(f"âš ï¸ ç„¡æ•ˆå…¬å¸ä»£è™Ÿæ ¼å¼: '{code}' (ç¬¬{idx+1}è¡Œ)")
                                invalid_count += 1
                                continue
                            
                            # ğŸ”§ é©—è­‰å…¬å¸åç¨±
                            if not self._is_valid_company_name(name):
                                print(f"âš ï¸ ç„¡æ•ˆå…¬å¸åç¨±: '{name}' (ä»£è™Ÿ: {code}, ç¬¬{idx+1}è¡Œ)")
                                invalid_count += 1
                                continue
                            
                            # ğŸ”§ æª¢æŸ¥é‡è¤‡ä»£è™Ÿ
                            if code in mapping:
                                print(f"âš ï¸ é‡è¤‡å…¬å¸ä»£è™Ÿ: {code} - åŸæœ‰: {mapping[code]}, æ–°çš„: {name}")
                                duplicate_count += 1
                                continue
                            
                            # æ·»åŠ åˆ°æ˜ å°„
                            mapping[code] = name
                            valid_count += 1
                            
                        except Exception as e:
                            print(f"âŒ è™•ç†ç¬¬{idx+1}è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                            invalid_count += 1
                            continue
                    
                    # ğŸ”§ é©—è­‰è¼‰å…¥çµæœ
                    total_rows = len(df)
                    if valid_count == 0:
                        print(f"âŒ è§€å¯Ÿåå–®ç„¡æœ‰æ•ˆæ•¸æ“š: {csv_path}")
                        continue
                    
                    print(f"ğŸ“Š è§€å¯Ÿåå–®è¼‰å…¥çµ±è¨ˆ:")
                    print(f"   æª”æ¡ˆ: {csv_path}")
                    print(f"   ç¸½è¡Œæ•¸: {total_rows}")
                    print(f"   æœ‰æ•ˆæ•¸æ“š: {valid_count}")
                    print(f"   ç„¡æ•ˆæ•¸æ“š: {invalid_count}")
                    print(f"   é‡è¤‡æ•¸æ“š: {duplicate_count}")
                    print(f"   æˆåŠŸç‡: {valid_count/total_rows*100:.1f}%")
                    
                    # ğŸ”§ é¡å¤–é©—è­‰ï¼šæª¢æŸ¥æ˜¯å¦æœ‰å·²çŸ¥çš„æ¸¬è©¦å…¬å¸
                    self._validate_watch_list_content(mapping)
                    
                    return mapping
                    
                except Exception as e:
                    print(f"âŒ è®€å–è§€å¯Ÿåå–®å¤±æ•— {csv_path}: {e}")
                    continue
        
        # ğŸ”§ å¦‚æœè§€å¯Ÿåå–®è¼‰å…¥å¤±æ•—ï¼Œè¿”å›ç©ºå­—å…¸ä½†ä¸åœæ­¢ç³»çµ±
        print("âŒ æ‰€æœ‰è§€å¯Ÿåå–®è¼‰å…¥å˜—è©¦å‡å¤±æ•—")
        print("âš ï¸ ç³»çµ±å°‡åœ¨ç„¡é©—è­‰æ¨¡å¼ä¸‹é‹è¡Œ")
        return {}

    def _is_valid_company_code(self, code: str) -> bool:
        """ğŸ”§ v3.5.1 åš´æ ¼é©—è­‰å…¬å¸ä»£è™Ÿæ ¼å¼"""
        if not code or code in ['nan', 'NaN', 'null', 'None', '']:
            return False
        
        # ç§»é™¤å¯èƒ½çš„å¼•è™Ÿå’Œç©ºç™½
        clean_code = code.strip().strip('\'"')
        
        # æª¢æŸ¥æ˜¯å¦ç‚º4ä½æ•¸å­—
        if not (clean_code.isdigit() and len(clean_code) == 4):
            return False
        
        # æª¢æŸ¥æ•¸å­—ç¯„åœï¼ˆå°è‚¡ä»£è™Ÿç¯„åœï¼‰
        code_num = int(clean_code)
        if not (1000 <= code_num <= 9999):
            return False
        
        return True

    def _is_valid_company_name(self, name: str) -> bool:
        """ğŸ”§ v3.5.1 åš´æ ¼é©—è­‰å…¬å¸åç¨±"""
        if not name or name in ['nan', 'NaN', 'null', 'None', '']:
            return False
        
        # ç§»é™¤ç©ºç™½å­—ç¬¦
        clean_name = name.strip()
        
        # æª¢æŸ¥é•·åº¦
        if len(clean_name) < 2 or len(clean_name) > 20:
            return False
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç„¡æ•ˆå­—ç¬¦ï¼ˆéæ–¼åš´æ ¼çš„æª¢æŸ¥å¯èƒ½éœ€è¦èª¿æ•´ï¼‰
        invalid_chars = ['|', '\t', '\n', '\r']
        if any(char in clean_name for char in invalid_chars):
            return False
        
        return True

    def _validate_watch_list_content(self, mapping: Dict[str, str]):
        """ğŸ”§ v3.5.1 é©—è­‰è§€å¯Ÿåå–®å…§å®¹çš„åˆç†æ€§"""
        if not mapping:
            return
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¸¸è¦‹çš„æ¸¬è©¦å…¬å¸
        test_companies = {
            '2330': 'å°ç©é›»',
            '2317': 'é´»æµ·',
            '2454': 'è¯ç™¼ç§‘'
        }
        
        found_test_companies = 0
        for code, expected_name in test_companies.items():
            if code in mapping:
                actual_name = mapping[code]
                if actual_name == expected_name:
                    found_test_companies += 1
                    print(f"âœ… æ‰¾åˆ°æ¸¬è©¦å…¬å¸: {code} - {actual_name}")
                else:
                    print(f"âš ï¸ æ¸¬è©¦å…¬å¸åç¨±ä¸ç¬¦: {code} - æœŸæœ›:{expected_name}, å¯¦éš›:{actual_name}")
        
        if found_test_companies == 0:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å·²çŸ¥æ¸¬è©¦å…¬å¸ï¼Œè«‹æª¢æŸ¥è§€å¯Ÿåå–®å…§å®¹")

    def parse_md_file(self, file_path: str) -> Dict[str, Any]:
        """è§£æ MD æª”æ¡ˆä¸¦é€²è¡Œåš´æ ¼é©—è­‰"""
        try:
            # è®€å–æª”æ¡ˆå…§å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŸºæœ¬æª”æ¡ˆè³‡è¨Š
            file_info = self._extract_file_info(file_path)
            company_code = file_info.get('company_code', '')
            company_name = file_info.get('company_name', '')
            
            # ğŸ”§ æ ¸å¿ƒé©—è­‰ï¼šå°ç…§è§€å¯Ÿåå–® (åš´æ ¼æ¨¡å¼)
            validation_result = self._validate_against_watch_list_strict(company_code, company_name)
            
            # è§£æ YAML front matter
            yaml_data = self._extract_yaml_frontmatter(content)
            
            # åŸæœ‰åŠŸèƒ½ï¼šæ—¥æœŸæå–
            content_date = self._extract_content_date_bulletproof(content)
            extraction_status = "content_extraction" if content_date else "no_date_found"
            
            # åŸæœ‰åŠŸèƒ½ï¼šEPS ç­‰è³‡æ–™æå–
            eps_data = self._extract_eps_data(content)
            eps_stats = self._calculate_eps_statistics(eps_data)
            target_price = self._extract_target_price(content)
            analyst_count = self._extract_analyst_count(content)
            data_richness = self._calculate_data_richness(eps_stats, target_price, analyst_count)
            
            # çµ„åˆçµæœ
            result = {
                # åŸºæœ¬è³‡è¨Š
                'filename': os.path.basename(file_path),
                'company_code': company_code,
                'company_name': company_name,
                'data_source': file_info.get('data_source', ''),
                'file_mtime': datetime.fromtimestamp(os.path.getmtime(file_path)),
                
                # æ—¥æœŸè³‡è¨Š
                'content_date': content_date,
                'extracted_date': yaml_data.get('extracted_date'),
                'filename_date': file_info.get('parsed_timestamp'),
                
                # EPS è³‡æ–™
                **eps_stats,
                
                # å…¶ä»–è²¡å‹™è³‡æ–™
                'target_price': target_price,
                'analyst_count': analyst_count,
                
                # è³‡æ–™ç‹€æ…‹
                'has_eps_data': len(eps_data) > 0,
                'has_target_price': target_price is not None,
                'has_analyst_info': analyst_count > 0,
                'data_richness_score': data_richness,
                
                # YAML è³‡æ–™
                'yaml_data': yaml_data,
                
                # ğŸ”§ åš´æ ¼é©—è­‰çµæœ
                'validation_result': validation_result,
                'content_validation_passed': validation_result['overall_status'] == 'valid',
                'validation_warnings': validation_result.get('warnings', []),
                'validation_errors': validation_result.get('errors', []),
                'validation_enabled': self.validation_enabled,
                
                # åŸå§‹å…§å®¹
                'content': content,
                'content_length': len(content),
                'parsed_at': datetime.now(),
                
                # èª¿è©¦è³‡è¨Š
                'date_extraction_method': extraction_status,
                'debug_info': self._get_debug_info(content, content_date)
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ è§£ææª”æ¡ˆå¤±æ•— {file_path}: {e}")
            return self._create_empty_result(file_path, str(e))

    def _validate_against_watch_list_strict(self, company_code: str, company_name: str) -> Dict[str, Any]:
        """ğŸ”§ v3.5.1 åš´æ ¼å°ç…§è§€å¯Ÿåå–®é€²è¡Œé©—è­‰"""
        
        validation_result = {
            'overall_status': 'valid',
            'warnings': [],
            'errors': [],
            'confidence_score': 10.0,
            'validation_method': 'strict'
        }
        
        # ğŸ”§ å¦‚æœè§€å¯Ÿåå–®æœªè¼‰å…¥ï¼Œè¨˜éŒ„ä½†ä¸é˜»æ­¢è™•ç†
        if not self.validation_enabled:
            validation_result['warnings'].append("è§€å¯Ÿåå–®æœªè¼‰å…¥ï¼Œè·³éé©—è­‰")
            validation_result['confidence_score'] = 5.0
            validation_result['validation_method'] = 'disabled'
            print(f"âš ï¸ è§€å¯Ÿåå–®é©—è­‰å·²åœç”¨: {company_code} - {company_name}")
            return validation_result
        
        # ğŸ”§ åš´æ ¼æª¢æŸ¥è¼¸å…¥åƒæ•¸
        if not company_code or not company_name:
            validation_result['overall_status'] = 'error'
            validation_result['confidence_score'] = 0.0
            error_msg = f"å…¬å¸ä»£è™Ÿæˆ–åç¨±ç‚ºç©º: ä»£è™Ÿ='{company_code}', åç¨±='{company_name}'"
            validation_result['errors'].append(error_msg)
            print(f"âŒ åƒæ•¸éŒ¯èª¤: {error_msg}")
            return validation_result
        
        # ğŸ”§ æ¸…ç†è¼¸å…¥æ•¸æ“š
        clean_code = str(company_code).strip().strip('\'"')
        clean_name = str(company_name).strip()
        
        # ğŸ”§ æª¢æŸ¥ 1: å…¬å¸ä»£è™Ÿæ ¼å¼é©—è­‰
        if not self._is_valid_company_code(clean_code):
            validation_result['overall_status'] = 'error'
            validation_result['confidence_score'] = 0.0
            error_msg = f"å…¬å¸ä»£è™Ÿæ ¼å¼ç„¡æ•ˆ: '{clean_code}'"
            validation_result['errors'].append(error_msg)
            print(f"âŒ ä»£è™Ÿæ ¼å¼ç„¡æ•ˆ: {clean_code}")
            return validation_result
        
        # ğŸ”§ æª¢æŸ¥ 2: å…¬å¸ä»£è™Ÿæ˜¯å¦åœ¨è§€å¯Ÿåå–®ä¸­
        if clean_code not in self.watch_list_mapping:
            validation_result['overall_status'] = 'error'
            validation_result['confidence_score'] = 0.0
            error_msg = f"ä»£è™Ÿ{clean_code}ä¸åœ¨è§€å¯Ÿåå–®ä¸­ï¼Œä¸å…è¨±è™•ç†"
            validation_result['errors'].append(error_msg)
            print(f"âŒ ä¸åœ¨è§€å¯Ÿåå–®: {clean_code}")
            
            # ğŸ”§ é¡å¤–ä¿¡æ¯ï¼šæä¾›ç›¸ä¼¼çš„ä»£è™Ÿå»ºè­°
            similar_codes = self._find_similar_codes(clean_code)
            if similar_codes:
                error_msg += f" (ç›¸ä¼¼ä»£è™Ÿ: {', '.join(similar_codes[:3])})"
                validation_result['errors'][-1] = error_msg
            
            return validation_result
        
        # ğŸ”§ æª¢æŸ¥ 3: å…¬å¸åç¨±æ˜¯å¦èˆ‡è§€å¯Ÿåå–®ä¸€è‡´ (åš´æ ¼æ¯”è¼ƒ)
        correct_name = self.watch_list_mapping[clean_code]
        
        # ğŸ”§ å¤šå±¤æ¬¡åç¨±æ¯”è¼ƒ
        name_match = self._compare_company_names(clean_name, correct_name)
        
        if not name_match['is_match']:
            validation_result['overall_status'] = 'error'
            validation_result['confidence_score'] = 0.0
            error_msg = f"å…¬å¸åç¨±ä¸ç¬¦è§€å¯Ÿåå–®ï¼šæª”æ¡ˆç‚º{clean_name}({clean_code})ï¼Œè§€å¯Ÿåå–®é¡¯ç¤ºæ‡‰ç‚º{correct_name}({clean_code})"
            validation_result['errors'].append(error_msg)
            
            # ğŸ”§ é¡å¤–ä¿¡æ¯ï¼šè©³ç´°çš„ä¸åŒ¹é…åˆ†æ
            if name_match['details']:
                validation_result['errors'].append(f"è©³ç´°æ¯”è¼ƒ: {name_match['details']}")
            
            print(f"âŒ åç¨±ä¸ç¬¦: {clean_code}")
            print(f"   æª”æ¡ˆåç¨±: '{clean_name}'")
            print(f"   è§€å¯Ÿåå–®: '{correct_name}'")
            print(f"   æ¯”è¼ƒè©³æƒ…: {name_match['details']}")
            
            return validation_result
        
        # ğŸ”§ æª¢æŸ¥é€šé
        validation_result['confidence_score'] = name_match['confidence_score']
        if name_match['confidence_score'] < 10.0:
            validation_result['warnings'].append(f"åç¨±åŒ¹é…åº¦: {name_match['confidence_score']}/10")
        
        print(f"âœ… é©—è­‰é€šé: {clean_code} - {clean_name} (ä¿¡å¿ƒåº¦: {name_match['confidence_score']})")
        return validation_result

    def _find_similar_codes(self, target_code: str) -> List[str]:
        """ğŸ”§ å°‹æ‰¾ç›¸ä¼¼çš„å…¬å¸ä»£è™Ÿ"""
        if not self.watch_list_mapping:
            return []
        
        similar_codes = []
        target_num = None
        
        try:
            target_num = int(target_code)
        except ValueError:
            return similar_codes
        
        for code in self.watch_list_mapping.keys():
            try:
                code_num = int(code)
                # å°‹æ‰¾æ•¸å€¼ç›¸è¿‘çš„ä»£è™Ÿ
                if abs(code_num - target_num) <= 10:
                    similar_codes.append(code)
            except ValueError:
                continue
        
        return sorted(similar_codes)

    def _compare_company_names(self, name1: str, name2: str) -> Dict[str, Any]:
        """ğŸ”§ v3.5.1 å¤šå±¤æ¬¡å…¬å¸åç¨±æ¯”è¼ƒ"""
        comparison_result = {
            'is_match': False,
            'confidence_score': 0.0,
            'details': ''
        }
        
        # å±¤æ¬¡ 1: å®Œå…¨åŒ¹é…
        if name1 == name2:
            comparison_result['is_match'] = True
            comparison_result['confidence_score'] = 10.0
            comparison_result['details'] = 'å®Œå…¨åŒ¹é…'
            return comparison_result
        
        # å±¤æ¬¡ 2: ç§»é™¤ç©ºç™½å¾ŒåŒ¹é…
        clean_name1 = re.sub(r'\s+', '', name1)
        clean_name2 = re.sub(r'\s+', '', name2)
        
        if clean_name1 == clean_name2:
            comparison_result['is_match'] = True
            comparison_result['confidence_score'] = 9.5
            comparison_result['details'] = 'ç§»é™¤ç©ºç™½å¾ŒåŒ¹é…'
            return comparison_result
        
        # å±¤æ¬¡ 3: ç§»é™¤å¸¸è¦‹å¾Œç¶´è©å¾ŒåŒ¹é…
        suffixes = ['è‚¡ä»½æœ‰é™å…¬å¸', 'æœ‰é™å…¬å¸', 'å…¬å¸', 'é›†åœ˜', 'æ§è‚¡', 'Corporation', 'Corp', 'Inc', 'Ltd', 'Group']
        
        def remove_suffixes(name):
            for suffix in suffixes:
                if name.endswith(suffix):
                    name = name[:-len(suffix)].strip()
            return name
        
        core_name1 = remove_suffixes(clean_name1)
        core_name2 = remove_suffixes(clean_name2)
        
        if core_name1 == core_name2:
            comparison_result['is_match'] = True
            comparison_result['confidence_score'] = 9.0
            comparison_result['details'] = 'ç§»é™¤å¾Œç¶´è©å¾ŒåŒ¹é…'
            return comparison_result
        
        # å±¤æ¬¡ 4: æ¨¡ç³ŠåŒ¹é… (å­—ç¬¦åŒ…å«é—œä¿‚)
        if core_name1 in core_name2 or core_name2 in core_name1:
            comparison_result['is_match'] = True
            comparison_result['confidence_score'] = 7.0
            comparison_result['details'] = f'éƒ¨åˆ†åŒ…å«åŒ¹é…: "{core_name1}" vs "{core_name2}"'
            return comparison_result
        
        # ä¸åŒ¹é…
        comparison_result['details'] = f'å®Œå…¨ä¸åŒ¹é…: "{name1}" vs "{name2}"'
        return comparison_result

    # åŸæœ‰æ–¹æ³•ä¿æŒä¸è®Š (é™¤äº†å°‘é‡èª¿æ•´)
    def _extract_content_date_bulletproof(self, content: str) -> Optional[str]:
        """çµ•å°é˜²å½ˆçš„æ—¥æœŸæå– - æ’é™¤ YAML frontmatter"""
        actual_content = self._get_content_without_yaml(content)
        found_dates = []
        
        for i, pattern in enumerate(self.date_patterns):
            matches = re.findall(pattern, actual_content, re.MULTILINE | re.DOTALL)
            
            if matches:
                for match in matches:
                    try:
                        if len(match) >= 3:
                            year, month, day = match[0], match[1], match[2]
                            
                            if self._validate_date(year, month, day):
                                date_str = f"{year}/{int(month)}/{int(day)}"
                                confidence = self._calculate_date_confidence(pattern, match, actual_content, i)
                                
                                found_dates.append({
                                    'date': date_str,
                                    'pattern_index': i,
                                    'pattern': pattern,
                                    'confidence': confidence,
                                    'match': match
                                })
                                
                    except (ValueError, IndexError) as e:
                        continue
        
        if found_dates:
            found_dates.sort(key=lambda x: x['confidence'], reverse=True)
            best_date = found_dates[0]
            return best_date['date']
        
        return None

    def _get_content_without_yaml(self, content: str) -> str:
        """ç§»é™¤ YAML frontmatterï¼Œåªè¿”å›å¯¦éš›å…§å®¹"""
        try:
            if content.startswith('---'):
                end_pos = content.find('---', 3)
                if end_pos != -1:
                    actual_content = content[end_pos + 3:].strip()
                    return actual_content
        except Exception as e:
            pass
        return content

    def _validate_date(self, year: str, month: str, day: str) -> bool:
        """é©—è­‰æ—¥æœŸçš„åˆç†æ€§"""
        try:
            y, m, d = int(year), int(month), int(day)
            if not (2020 <= y <= 2030):
                return False
            if not (1 <= m <= 12):
                return False
            if not (1 <= d <= 31):
                return False
            datetime(y, m, d)
            return True
        except (ValueError, TypeError):
            return False

    def _calculate_date_confidence(self, pattern: str, match: tuple, content: str, pattern_index: int) -> float:
        """è¨ˆç®—æ—¥æœŸåŒ¹é…çš„å¯ä¿¡åº¦"""
        confidence = 5.0
        
        if pattern_index == 0:
            confidence += 6.0
        elif pattern_index == 1:
            confidence += 5.5
        elif pattern_index == 2:
            confidence += 5.0
        elif pattern_index <= 6:
            confidence += 4.0
        elif 'cmoney' in content.lower() or 'CMoney' in content:
            confidence += 2.5
        elif 'é‰…äº¨ç¶²' in pattern:
            confidence += 2.0
        elif 'å¹´' in pattern and 'æœˆ' in pattern:
            confidence += 1.5
        elif '-' in pattern:
            confidence += 1.0
        
        match_text = ''.join(match)
        position = content.find(match_text)
        if position != -1:
            if position < len(content) * 0.1:
                confidence += 2.0
            elif position < len(content) * 0.3:
                confidence += 1.0
        
        try:
            year = int(match[0])
            current_year = datetime.now().year
            if year == current_year:
                confidence += 1.5
            elif year == current_year - 1:
                confidence += 1.0
        except:
            pass
        
        return confidence

    def _get_debug_info(self, content: str, extracted_date: Optional[str]) -> Dict[str, Any]:
        """ç”Ÿæˆèª¿è©¦è³‡è¨Š"""
        return {
            'content_preview': content[:200] + "..." if len(content) > 200 else content,
            'extracted_date': extracted_date,
            'yaml_detected': content.startswith('---'),
            'content_length': len(content),
            'watch_list_loaded': self.validation_enabled,
            'watch_list_size': len(self.watch_list_mapping)
        }

    def _extract_file_info(self, file_path: str) -> Dict[str, Any]:
        """å¾æª”æ¡ˆè·¯å¾‘æå–åŸºæœ¬è³‡è¨Š"""
        filename = os.path.basename(file_path)
        name_without_ext = filename.replace('.md', '')
        parts = name_without_ext.split('_')
        
        result = {
            'company_code': None,
            'company_name': None,
            'data_source': None,
            'timestamp': None,
            'parsed_timestamp': None
        }
        
        if len(parts) >= 2:
            if parts[0].isdigit() and len(parts[0]) == 4:
                result['company_code'] = parts[0]
            
            if len(parts) > 1:
                result['company_name'] = parts[1]
            
            if len(parts) > 2:
                result['data_source'] = parts[2]
        
        return result

    def _extract_yaml_frontmatter(self, content: str) -> Dict[str, Any]:
        """æå– YAML front matter"""
        try:
            if content.startswith('---'):
                end_pos = content.find('---', 3)
                if end_pos != -1:
                    yaml_content = content[3:end_pos].strip()
                    return yaml.safe_load(yaml_content) or {}
        except:
            pass
        return {}

    def _extract_eps_data(self, content: str) -> Dict[str, List[float]]:
        """æå– EPS è³‡æ–™"""
        eps_data = {'2025': [], '2026': [], '2027': []}
        
        eps_data.update(self._extract_eps_from_table(content))
        
        for pattern in self.eps_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                try:
                    year = match[0]
                    value = float(match[1])
                    
                    if year in eps_data and 0 < value < 1000:
                        eps_data[year].append(value)
                except (ValueError, IndexError):
                    continue
        
        for year in eps_data:
            eps_data[year] = list(set(eps_data[year]))
        
        return eps_data

    def _extract_eps_from_table(self, content: str) -> Dict[str, List[float]]:
        """å¾è¡¨æ ¼ä¸­æå– EPS è³‡æ–™"""
        eps_data = {'2025': [], '2026': [], '2027': []}
        
        table_patterns = [
            r'\|\s*(æœ€é«˜å€¼|æœ€ä½å€¼|å¹³å‡å€¼|ä¸­ä½æ•¸)[^|]*\|\s*([0-9]+\.?[0-9]*)[^|]*\|\s*([0-9]+\.?[0-9]*)\s*\|\s*([0-9]+\.?[0-9]*)',
        ]
        
        for pattern in table_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                try:
                    years = ['2025', '2026', '2027']
                    for i, year in enumerate(years):
                        if i + 1 < len(match):
                            value_str = match[i + 1].strip()
                            value_str = re.sub(r'\([^)]*\)', '', value_str)
                            value = float(value_str)
                            if 0 < value < 1000:
                                eps_data[year].append(value)
                except (ValueError, IndexError):
                    continue
        
        return eps_data

    def _extract_target_price(self, content: str) -> Optional[float]:
        """æå–ç›®æ¨™åƒ¹æ ¼"""
        for pattern in self.target_price_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                try:
                    price = float(matches[0])
                    if 0 < price < 10000:
                        return price
                except ValueError:
                    continue
        return None

    def _extract_analyst_count(self, content: str) -> int:
        """æå–åˆ†æå¸«æ•¸é‡"""
        for pattern in self.analyst_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                try:
                    count = int(matches[0])
                    if 0 < count < 1000:
                        return count
                except ValueError:
                    continue
        return 0

    def _calculate_eps_statistics(self, eps_data: Dict[str, List[float]]) -> Dict[str, Any]:
        """è¨ˆç®— EPS çµ±è¨ˆè³‡æ–™"""
        result = {}
        
        for year in ['2025', '2026', '2027']:
            values = eps_data.get(year, [])
            
            if values:
                result[f'eps_{year}_high'] = max(values)
                result[f'eps_{year}_low'] = min(values)
                result[f'eps_{year}_avg'] = round(statistics.mean(values), 2)
            else:
                result[f'eps_{year}_high'] = None
                result[f'eps_{year}_low'] = None
                result[f'eps_{year}_avg'] = None
        
        return result

    def _calculate_data_richness(self, eps_stats: Dict, target_price: Optional[float], analyst_count: int) -> float:
        """è¨ˆç®—è³‡æ–™è±å¯Œåº¦åˆ†æ•¸ (0-10)"""
        score = 0
        
        eps_years = ['2025', '2026', '2027']
        eps_available = sum(1 for year in eps_years if eps_stats.get(f'eps_{year}_avg') is not None)
        score += (eps_available / len(eps_years)) * 6
        
        if target_price is not None:
            score += 2
        
        if analyst_count > 0:
            if analyst_count >= 20:
                score += 2
            elif analyst_count >= 10:
                score += 1.5
            elif analyst_count >= 5:
                score += 1
            else:
                score += 0.5
        
        return round(min(score, 10), 2)

    def _create_empty_result(self, file_path: str, error_msg: str) -> Dict[str, Any]:
        """å»ºç«‹ç©ºçš„è§£æçµæœ"""
        file_info = self._extract_file_info(file_path)
        
        return {
            'filename': os.path.basename(file_path),
            'company_code': file_info.get('company_code'),
            'company_name': file_info.get('company_name'),
            'data_source': file_info.get('data_source'),
            'file_mtime': datetime.fromtimestamp(os.path.getmtime(file_path)) if os.path.exists(file_path) else None,
            'content_date': None,
            'eps_2025_high': None, 'eps_2025_low': None, 'eps_2025_avg': None,
            'eps_2026_high': None, 'eps_2026_low': None, 'eps_2026_avg': None,
            'eps_2027_high': None, 'eps_2027_low': None, 'eps_2027_avg': None,
            'target_price': None,
            'analyst_count': 0,
            'has_eps_data': False,
            'has_target_price': False,
            'has_analyst_info': False,
            'data_richness_score': 0.0,
            'yaml_data': {},
            'content': '',
            'content_length': 0,
            'parsed_at': datetime.now(),
            'error': error_msg,
            'date_extraction_method': 'error',
            'validation_result': {'overall_status': 'error', 'errors': [error_msg]},
            'content_validation_passed': False,
            'validation_warnings': [],
            'validation_errors': [error_msg],
            'validation_enabled': self.validation_enabled
        }


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    parser = MDParser()
    
    print("=== MD Parser v3.5.1 æ¸¬è©¦ (ä¿®æ­£è§€å¯Ÿåå–®é©—è­‰) ===")
    print(f"ğŸ“‹ è§€å¯Ÿåå–®è¼‰å…¥: {len(parser.watch_list_mapping)} å®¶å…¬å¸")
    print(f"ğŸ”§ é©—è­‰åŠŸèƒ½: {'å•Ÿç”¨' if parser.validation_enabled else 'åœç”¨'}")
    
    if parser.validation_enabled:
        # æ¸¬è©¦é©—è­‰é‚è¼¯
        test_cases = [
            ('6462', 'ase'),      # éŒ¯èª¤åç¨±
            ('6811', 'fubon'),    # éŒ¯èª¤åç¨±  
            ('9999', 'ä¸å­˜åœ¨'),    # ä¸å­˜åœ¨çš„ä»£è™Ÿ
            ('abc', 'test'),      # ç„¡æ•ˆæ ¼å¼
            ('2330', 'å°ç©é›»')     # æ­£å¸¸å…¬å¸ (å¦‚æœåœ¨è§€å¯Ÿåå–®ä¸­)
        ]
        
        print(f"\nğŸ§ª é©—è­‰æ¸¬è©¦:")
        for code, name in test_cases:
            result = parser._validate_against_watch_list_strict(code, name)
            status = result['overall_status']
            errors = len(result.get('errors', []))
            confidence = result.get('confidence_score', 0)
            print(f"  {code} ({name}): {status} - ä¿¡å¿ƒåº¦:{confidence} - éŒ¯èª¤:{errors}")
            
            if errors > 0:
                for error in result.get('errors', [])[:1]:  # åªé¡¯ç¤ºç¬¬ä¸€å€‹éŒ¯èª¤
                    print(f"    âŒ {error}")
    else:
        print("âš ï¸ è§€å¯Ÿåå–®é©—è­‰å·²åœç”¨")
    
    print(f"\nâœ… v3.5.1 ä¿®æ­£ç‰ˆè§€å¯Ÿåå–®é©—è­‰ç³»çµ±å·²å•Ÿå‹•ï¼")
    print(f"ğŸ”§ ä¸»è¦ä¿®æ­£: åš´æ ¼åç¨±æ¯”è¼ƒã€æ ¼å¼é©—è­‰ã€éŒ¯èª¤è™•ç†")