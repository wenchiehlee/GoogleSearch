#!/usr/bin/env python3
"""
Quality Analyzer - FactSet Pipeline v3.5.1
Forces quality score = 0 for all validation failures
"""

import re
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple

class QualityAnalyzer:
    """å“è³ªåˆ†æå™¨ - å¼·åˆ¶é©—è­‰å¤±æ•—è©•åˆ†ç‚º 0"""
    
    # å“è³ªç¯„åœå®šç¾©
    QUALITY_RANGES = {
        'complete': (9.0, 10.0),      # ğŸŸ¢ å®Œæ•´ (9.0-10.0)
        'good': (8.0, 8.99),          # ğŸŸ¡ è‰¯å¥½ (8.0-8.99)
        'partial': (3.0, 7.99),       # ğŸŸ  éƒ¨åˆ† (3.0-7.99)
        'insufficient': (0.0, 2.99)   # ğŸ”´ ä¸è¶³ (0.0-2.99)
    }
    
    # å“è³ªç‹€æ…‹æŒ‡æ¨™
    QUALITY_INDICATORS = {
        'complete': 'ğŸŸ¢ å®Œæ•´',
        'good': 'ğŸŸ¡ è‰¯å¥½',
        'partial': 'ğŸŸ  éƒ¨åˆ†',
        'insufficient': 'ğŸ”´ ä¸è¶³'
    }
    
    # è©•åˆ†æ¬Šé‡
    QUALITY_WEIGHTS = {
        'data_completeness': 0.30,    # è³‡æ–™å®Œæ•´æ€§ 30%
        'analyst_coverage': 0.20,     # åˆ†æå¸«è¦†è“‹ 20%
        'data_freshness': 0.15,       # è³‡æ–™æ–°é®®åº¦ 15%
        'content_quality': 0.15,      # å…§å®¹å“è³ª 15%
        'data_consistency': 0.05,     # è³‡æ–™ä¸€è‡´æ€§ 5%
        'content_validation': 0.15    # å…§å®¹é©—è­‰ 15%
    }
    
    def __init__(self):
        """åˆå§‹åŒ–å“è³ªåˆ†æå™¨"""
        self.financial_keywords = [
            'eps', 'æ¯è‚¡ç›ˆé¤˜', 'ç‡Ÿæ”¶', 'ç‡Ÿæ¥­æ”¶å…¥', 'æ·¨åˆ©', 'ç²åˆ©',
            'ç›®æ¨™åƒ¹', 'è©•ç­‰', 'åˆ†æå¸«', 'é ä¼°', 'é æ¸¬', 'factset',
            'revenue', 'earnings', 'profit', 'target', 'analyst'
        ]

    def analyze(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸»è¦åˆ†ææ–¹æ³• - æª¢æŸ¥é©—è­‰å¤±æ•—ä¸¦å¼·åˆ¶ 0 åˆ†"""
        try:
            company_code = parsed_data.get('company_code', '')
            company_name = parsed_data.get('company_name', '')
            
            # æª¢æŸ¥é©—è­‰çµæœ
            validation_result = parsed_data.get('validation_result', {})
            validation_status = validation_result.get('overall_status', 'valid')
            validation_passed = parsed_data.get('content_validation_passed', True)
            
            # å¦‚æœé©—è­‰å¤±æ•—ï¼Œç›´æ¥è¿”å› 0 åˆ†
            if not validation_passed or validation_status == 'error':
                validation_errors = parsed_data.get('validation_errors', [])
                main_error = str(validation_errors[0]) if validation_errors else "é©—è­‰å¤±æ•—"
                
                print(f"âŒ é©—è­‰å¤±æ•—å¼·åˆ¶ 0 åˆ†: {company_code} ({company_name}) - {main_error[:50]}...")
                return self._create_zero_score_analysis(company_code, company_name, main_error)
            
            # æ­£å¸¸çš„å“è³ªåˆ†æé‚è¼¯
            completeness_analysis = self._analyze_data_completeness(parsed_data)
            coverage_analysis = self._analyze_analyst_coverage(parsed_data)
            freshness_analysis = self._analyze_data_freshness(parsed_data)
            content_analysis = self._analyze_content_quality(parsed_data)
            consistency_analysis = self._analyze_data_consistency(parsed_data)
            validation_analysis = self._analyze_content_validation(parsed_data)
            
            # CRITICAL: ç›´æ¥ä½¿ç”¨ MD æª”æ¡ˆçš„ quality_scoreï¼Œä¸é‡æ–°è¨ˆç®—
            # å“è³ªè©•åˆ†æ‡‰è©²åªå¾ MD æª”æ¡ˆè®€å–ï¼Œä¿æŒèˆ‡ Search Group ä¸€è‡´
            md_quality_score = parsed_data.get('quality_score', 0)
            if md_quality_score > 0:
                final_quality_score = round(md_quality_score, 1)
            else:
                # Fallback: å¦‚æœ MD æª”æ¡ˆç¼ºå°‘ quality_scoreï¼Œä½¿ç”¨é è¨­å€¼ 0
                final_quality_score = 0.0
            
            # ç¢ºå®šå“è³ªé¡åˆ¥å’Œç‹€æ…‹
            quality_category = self._determine_quality_category_fixed(final_quality_score)
            quality_status = self.QUALITY_INDICATORS[quality_category]
            
            # ç”Ÿæˆæ‘˜è¦æŒ‡æ¨™
            summary_metrics = self._generate_summary_metrics(parsed_data)
            
            return {
                'quality_score': final_quality_score,
                'quality_status': quality_status,
                'quality_category': quality_category,
                'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                
                'detailed_analysis': {
                    'data_completeness': completeness_analysis,
                    'analyst_coverage': coverage_analysis,
                    'data_freshness': freshness_analysis,
                    'content_quality': content_analysis,
                    'data_consistency': consistency_analysis,
                    'content_validation': validation_analysis
                },
                
                'summary_metrics': summary_metrics,
                
                'validation_summary': {
                    'validation_passed': validation_passed,
                    'validation_warnings': parsed_data.get('validation_warnings', []),
                    'validation_errors': parsed_data.get('validation_errors', []),
                    'has_validation_issues': len(parsed_data.get('validation_errors', [])) > 0
                },
                
                'score_adjustment': {
                    'base_score': round(final_quality_score, 1),  # ä½¿ç”¨ MD æª”æ¡ˆçš„å“è³ªè©•åˆ†
                    'final_score': final_quality_score,
                    'adjustment_reason': "æ­£å¸¸è©•åˆ†ï¼Œç„¡èª¿æ•´"
                }
            }
            
        except Exception as e:
            print(f"âŒ å“è³ªåˆ†æå¤±æ•—: {e}")
            return self._create_empty_analysis(str(e))

    def _create_zero_score_analysis(self, company_code: str, company_name: str, error_msg: str) -> Dict[str, Any]:
        """å»ºç«‹å¼·åˆ¶ 0 åˆ†çš„å“è³ªåˆ†æçµæœ"""
        return {
            'quality_score': 0.0,
            'quality_status': 'âŒ é©—è­‰å¤±æ•—',
            'quality_category': 'insufficient',
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            
            'detailed_analysis': {
                'validation_failure': {
                    'score': 0.0,
                    'details': [f"âŒ é©—è­‰å¤±æ•—: {error_msg}"],
                    'metrics': {
                        'validation_failure': True,
                        'company_code': company_code,
                        'company_name': company_name
                    }
                }
            },
            
            'summary_metrics': {
                'content_validation_passed': False,
                'validation_error_count': 1,
                'validation_failure': True,
                'eps_data_available': False,
                'target_price_available': False,
                'analyst_count': 0,
                'content_length': 0,
                'financial_keywords_found': 0
            },
            
            'validation_summary': {
                'validation_passed': False,
                'validation_errors': [error_msg],
                'validation_warnings': [],
                'has_validation_issues': True
            },
            
            'score_adjustment': {
                'base_score': 0.0,
                'final_score': 0.0,
                'adjustment_reason': f"é©—è­‰å¤±æ•—å¼·åˆ¶ 0 åˆ†: {error_msg[:50]}..."
            }
        }

    def _analyze_content_validation(self, data: Dict) -> Dict:
        """åˆ†æå…§å®¹é©—è­‰çµæœ (15% æ¬Šé‡)"""
        score = 8.0  # é è¨­é«˜åˆ†ï¼Œæœ‰å•é¡Œæ‰æ‰£åˆ†
        details = []
        metrics = {}
        
        validation_result = data.get('validation_result', {})
        validation_status = validation_result.get('overall_status', 'unknown')
        validation_confidence = validation_result.get('confidence_score', 10.0)
        validation_errors = data.get('validation_errors', [])
        validation_warnings = data.get('validation_warnings', [])
        
        # æ ¹æ“šé©—è­‰ç‹€æ…‹è©•åˆ†
        if validation_status == 'valid':
            score = 10.0
            details.append("âœ… å…§å®¹é©—è­‰é€šé")
        elif validation_status == 'warning':
            score = 6.0
            details.append(f"ğŸŸ¡ å…§å®¹é©—è­‰æœ‰è­¦å‘Š ({len(validation_warnings)} é …)")
        elif validation_status == 'error':
            score = 0.0  # é©—è­‰éŒ¯èª¤ç›´æ¥ 0 åˆ†
            details.append(f"âŒ å…§å®¹é©—è­‰å¤±æ•— ({len(validation_errors)} é …éŒ¯èª¤)")
        else:
            score = 5.0
            details.append("âš ï¸ å…§å®¹é©—è­‰ç‹€æ…‹æœªçŸ¥")
        
        # æª¢æŸ¥å…·é«”çš„é©—è­‰å•é¡Œ
        for error in validation_errors:
            if any(keyword in str(error) for keyword in ['å…¬å¸åç¨±ä¸ç¬¦', 'ä¸åœ¨è§€å¯Ÿåå–®']):
                score = 0.0  # é—œéµå•é¡Œç›´æ¥ 0 åˆ†
                details.append("âŒ ç™¼ç¾é—œéµé©—è­‰å•é¡Œ")
                break
        
        # è¨˜éŒ„é©—è­‰æŒ‡æ¨™
        metrics.update({
            'validation_status': validation_status,
            'validation_confidence': validation_confidence,
            'error_count': len(validation_errors),
            'warning_count': len(validation_warnings),
            'has_validation_failure': score == 0.0
        })
        
        return {
            'score': round(max(0, min(score, 10)), 2),
            'details': details,
            'metrics': metrics
        }

    def _determine_quality_category_fixed(self, score: float) -> str:
        """ç¢ºå®šå“è³ªé¡åˆ¥"""
        for category, (min_score, max_score) in self.QUALITY_RANGES.items():
            if min_score <= score <= max_score:
                return category
        
        if score >= 9.0:
            return 'complete'
        elif score >= 8.0:
            return 'good'
        elif score >= 3.0:
            return 'partial'
        else:
            return 'insufficient'

    def _analyze_data_completeness(self, data: Dict) -> Dict:
        """åˆ†æè³‡æ–™å®Œæ•´æ€§ (30% æ¬Šé‡)"""
        score = 0
        details = []
        metrics = {}
        
        # EPS è³‡æ–™å®Œæ•´æ€§ (40% of this dimension)
        eps_years = ['2025', '2026', '2027']
        eps_available = 0
        
        for year in eps_years:
            if data.get(f'eps_{year}_avg') is not None:
                eps_available += 1
        
        eps_completeness = eps_available / len(eps_years)
        score += eps_completeness * 4.0
        
        if eps_available == 3:
            details.append("âœ… EPS é æ¸¬å®Œæ•´ (2025-2027)")
        elif eps_available == 2:
            details.append("ğŸŸ¡ EPS é æ¸¬éƒ¨åˆ†å®Œæ•´")
        elif eps_available == 1:
            details.append("ğŸŸ  EPS é æ¸¬è³‡æ–™æœ‰é™")
        else:
            details.append("âŒ ç¼ºå°‘ EPS é æ¸¬è³‡æ–™")
        
        metrics['eps_years_available'] = eps_available
        
        # ç›®æ¨™åƒ¹æ ¼ (30% of this dimension)
        if data.get('target_price') is not None:
            score += 3.0
            details.append("âœ… ç›®æ¨™åƒ¹æ ¼è³‡è¨Šå®Œæ•´")
            metrics['has_target_price'] = True
        else:
            details.append("âŒ ç¼ºå°‘ç›®æ¨™åƒ¹æ ¼")
            metrics['has_target_price'] = False
        
        # åˆ†æå¸«æ•¸é‡ (20% of this dimension)
        analyst_count = data.get('analyst_count', 0)
        if analyst_count >= 10:
            score += 2.0
            details.append(f"âœ… åˆ†æå¸«è¦†è“‹å……è¶³ ({analyst_count}ä½)")
        elif analyst_count >= 5:
            score += 1.5
            details.append(f"ğŸŸ¡ åˆ†æå¸«è¦†è“‹ä¸€èˆ¬ ({analyst_count}ä½)")
        elif analyst_count > 0:
            score += 1.0
            details.append(f"ğŸŸ  åˆ†æå¸«è¦†è“‹æœ‰é™ ({analyst_count}ä½)")
        else:
            details.append("âŒ ç¼ºå°‘åˆ†æå¸«è³‡è¨Š")
        
        metrics['analyst_count'] = analyst_count
        
        # åŸºæœ¬è³‡è¨Š (10% of this dimension)
        basic_info_score = 0
        if data.get('company_code'):
            basic_info_score += 0.5
        if data.get('company_name'):
            basic_info_score += 0.5
        
        score += basic_info_score * 1.0
        
        if basic_info_score == 1.0:
            details.append("âœ… åŸºæœ¬å…¬å¸è³‡è¨Šå®Œæ•´")
        else:
            details.append("ğŸŸ  åŸºæœ¬å…¬å¸è³‡è¨Šä¸å®Œæ•´")
        
        metrics['basic_info_complete'] = basic_info_score == 1.0
        
        return {
            'score': round(min(score, 10), 2),
            'details': details,
            'metrics': metrics
        }

    def _analyze_analyst_coverage(self, data: Dict) -> Dict:
        """åˆ†æåˆ†æå¸«è¦†è“‹åº¦ (20% æ¬Šé‡)"""
        score = 0
        details = []
        metrics = {}
        
        analyst_count = data.get('analyst_count', 0)
        
        # åˆ†æå¸«æ•¸é‡è©•åˆ† (70% of this dimension)
        if analyst_count >= 30:
            score += 7.0
            details.append(f"ğŸŒŸ å„ªç§€çš„åˆ†æå¸«è¦†è“‹ ({analyst_count}ä½)")
        elif analyst_count >= 20:
            score += 6.0
            details.append(f"âœ… è‰¯å¥½çš„åˆ†æå¸«è¦†è“‹ ({analyst_count}ä½)")
        elif analyst_count >= 15:
            score += 5.0
            details.append(f"ğŸŸ¡ é©ä¸­çš„åˆ†æå¸«è¦†è“‹ ({analyst_count}ä½)")
        elif analyst_count >= 10:
            score += 4.0
            details.append(f"ğŸŸ  åŸºæœ¬çš„åˆ†æå¸«è¦†è“‹ ({analyst_count}ä½)")
        elif analyst_count >= 5:
            score += 2.5
            details.append(f"ğŸ”´ æœ‰é™çš„åˆ†æå¸«è¦†è“‹ ({analyst_count}ä½)")
        elif analyst_count > 0:
            score += 1.0
            details.append(f"âš ï¸ æ¥µå°‘çš„åˆ†æå¸«è¦†è“‹ ({analyst_count}ä½)")
        else:
            details.append("âŒ ç„¡åˆ†æå¸«è¦†è“‹è³‡è¨Š")
        
        metrics['analyst_count'] = analyst_count
        
        # è³‡æ–™ä¾†æºå“è³ª (30% of this dimension)
        data_source = data.get('data_source', '').lower()
        if 'factset' in data_source:
            score += 3.0
            details.append("âœ… é«˜å“è³ªè³‡æ–™ä¾†æº (FactSet)")
            metrics['data_source_quality'] = 'high'
        elif any(source in data_source for source in ['bloomberg', 'refinitiv', 'reuters']):
            score += 2.5
            details.append("ğŸŸ¡ ä¸­ç­‰å“è³ªè³‡æ–™ä¾†æº")
            metrics['data_source_quality'] = 'medium'
        elif data_source:
            score += 1.5
            details.append("ğŸŸ  ä¸€èˆ¬è³‡æ–™ä¾†æº")
            metrics['data_source_quality'] = 'basic'
        else:
            details.append("âŒ æœªçŸ¥è³‡æ–™ä¾†æº")
            metrics['data_source_quality'] = 'unknown'
        
        return {
            'score': round(min(score, 10), 2),
            'details': details,
            'metrics': metrics
        }

    def _analyze_data_freshness(self, data: Dict) -> Dict:
        """åˆ†æè³‡æ–™æ–°é®®åº¦ (15% æ¬Šé‡)"""
        score = 0
        details = []
        metrics = {}
        
        # å–å¾—å…§å®¹æ—¥æœŸæˆ–æª”æ¡ˆä¿®æ”¹æ™‚é–“
        content_date = data.get('content_date')
        file_mtime = data.get('file_mtime')
        
        reference_date = content_date or file_mtime
        
        if reference_date:
            if isinstance(reference_date, str):
                try:
                    # è™•ç†ä¸åŒçš„æ—¥æœŸæ ¼å¼
                    if '/' in reference_date:
                        # 2025/6/6 æ ¼å¼
                        date_parts = reference_date.split('/')
                        if len(date_parts) == 3:
                            year, month, day = date_parts
                            reference_date = datetime(int(year), int(month), int(day))
                    else:
                        reference_date = datetime.fromisoformat(reference_date.replace('Z', '+00:00'))
                except:
                    reference_date = None
            
            if reference_date:
                now = datetime.now()
                if reference_date.tzinfo is None:
                    reference_date = reference_date.replace(tzinfo=None)
                    now = now.replace(tzinfo=None)
                
                age_days = (now - reference_date).days
                
                # è³‡æ–™æ–°é®®åº¦è©•åˆ†
                if age_days <= 7:
                    score += 8
                    details.append(f"âœ… è³‡æ–™éå¸¸æ–°é®® ({age_days} å¤©)")
                elif age_days <= 30:
                    score += 7
                    details.append(f"âœ… è³‡æ–™æ–°é®® ({age_days} å¤©)")
                elif age_days <= 90:
                    score += 5
                    details.append(f"ğŸŸ¡ è³‡æ–™è¼ƒæ–° ({age_days} å¤©)")
                elif age_days <= 180:
                    score += 3
                    details.append(f"ğŸŸ  è³‡æ–™è¼ƒèˆŠ ({age_days} å¤©)")
                else:
                    score += 1
                    details.append(f"ğŸ”´ è³‡æ–™éèˆŠ ({age_days} å¤©)")
                
                metrics['age_days'] = age_days
        else:
            score += 2
            details.append("âš ï¸ ç„¡æ³•ç¢ºå®šè³‡æ–™æ™‚é–“")
        
        return {
            'score': round(min(score, 10), 2),
            'details': details,
            'metrics': metrics
        }

    def _analyze_content_quality(self, data: Dict) -> Dict:
        """åˆ†æå…§å®¹å“è³ª (15% æ¬Šé‡)"""
        score = 0
        details = []
        metrics = {}
        
        content = str(data.get('content', ''))
        content_length = len(content)
        
        # å…§å®¹é•·åº¦è©•åˆ†
        if content_length >= 5000:
            score += 4
            details.append(f"âœ… å…§å®¹è±å¯Œ ({content_length} å­—å…ƒ)")
        elif content_length >= 2000:
            score += 3
            details.append(f"ğŸŸ¡ å…§å®¹é©ä¸­ ({content_length} å­—å…ƒ)")
        elif content_length >= 500:
            score += 2
            details.append(f"ğŸŸ  å…§å®¹è¼ƒå°‘ ({content_length} å­—å…ƒ)")
        else:
            score += 1
            details.append(f"ğŸ”´ å…§å®¹éå°‘ ({content_length} å­—å…ƒ)")
        
        # è²¡å‹™é—œéµå­—æª¢æŸ¥
        keyword_count = sum(1 for keyword in self.financial_keywords if keyword in content.lower())
        
        if keyword_count >= 8:
            score += 4
            details.append(f"âœ… è²¡å‹™é—œéµå­—è±å¯Œ ({keyword_count})")
        elif keyword_count >= 5:
            score += 3
            details.append(f"ğŸŸ¡ è²¡å‹™é—œéµå­—ä¸€èˆ¬ ({keyword_count})")
        elif keyword_count >= 2:
            score += 2
            details.append(f"ğŸŸ  è²¡å‹™é—œéµå­—è¼ƒå°‘ ({keyword_count})")
        else:
            score += 1
            details.append(f"ğŸ”´ è²¡å‹™é—œéµå­—ç¨€å°‘ ({keyword_count})")
        
        metrics['content_length'] = content_length
        metrics['keyword_count'] = keyword_count
        
        return {
            'score': round(min(score, 10), 2),
            'details': details,
            'metrics': metrics
        }

    def _analyze_data_consistency(self, data: Dict) -> Dict:
        """åˆ†æè³‡æ–™ä¸€è‡´æ€§ (5% æ¬Šé‡)"""
        score = 8  # é è¨­é«˜åˆ†ï¼Œæœ‰å•é¡Œæ‰æ‰£åˆ†
        details = []
        issues = []
        
        # æª¢æŸ¥ EPS è¶¨å‹¢ä¸€è‡´æ€§
        eps_2025 = data.get('eps_2025_avg')
        eps_2026 = data.get('eps_2026_avg')
        eps_2027 = data.get('eps_2027_avg')
        
        if eps_2025 and eps_2026 and eps_2027:
            # æª¢æŸ¥ç•°å¸¸çš„ EPS è®ŠåŒ–
            if abs(eps_2026 - eps_2025) > eps_2025 * 2:
                score -= 2
                issues.append("EPS 2025-2026 è®ŠåŒ–ç•°å¸¸")
            
            if abs(eps_2027 - eps_2026) > eps_2026 * 2:
                score -= 2
                issues.append("EPS 2026-2027 è®ŠåŒ–ç•°å¸¸")
        
        # æª¢æŸ¥å…¬å¸è³‡è¨Šä¸€è‡´æ€§
        company_code = data.get('company_code', '')
        if company_code and not (company_code.isdigit() and len(company_code) == 4):
            score -= 1
            issues.append("å…¬å¸ä»£è™Ÿæ ¼å¼ç•°å¸¸")
        
        # æª¢æŸ¥ç›®æ¨™åƒ¹æ ¼åˆç†æ€§
        target_price = data.get('target_price')
        if target_price and (target_price <= 0 or target_price > 10000):
            score -= 1
            issues.append("ç›®æ¨™åƒ¹æ ¼æ•¸å€¼ç•°å¸¸")
        
        if issues:
            details.append(f"âŒ ç™¼ç¾ {len(issues)} å€‹ä¸€è‡´æ€§å•é¡Œ")
            details.extend([f"  - {issue}" for issue in issues])
        else:
            details.append("âœ… è³‡æ–™ä¸€è‡´æ€§è‰¯å¥½")
        
        return {
            'score': max(0, min(10, score)),
            'details': details,
            'metrics': {'consistency_issues': issues}
        }

    def _generate_summary_metrics(self, data: Dict) -> Dict:
        """ç”Ÿæˆæ‘˜è¦æŒ‡æ¨™"""
        return {
            'eps_data_available': any(data.get(f'eps_{year}_avg') is not None for year in ['2025', '2026', '2027']),
            'target_price_available': data.get('target_price') is not None,
            'analyst_count': data.get('analyst_count', 0),
            'content_length': len(str(data.get('content', ''))),
            'financial_keywords_found': sum(1 for keyword in self.financial_keywords if keyword in str(data.get('content', '')).lower()),
            'content_validation_passed': data.get('content_validation_passed', True),
            'validation_error_count': len(data.get('validation_errors', [])),
            'validation_warning_count': len(data.get('validation_warnings', []))
        }

    def _create_empty_analysis(self, error_msg: str) -> Dict:
        """å»ºç«‹ç©ºçš„åˆ†æçµæœ"""
        return {
            'quality_score': 0,
            'quality_status': 'ğŸ”´ ä¸è¶³',
            'quality_category': 'insufficient',
            'error': error_msg,
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'validation_summary': {
                'validation_passed': False,
                'validation_errors': [error_msg],
                'has_validation_issues': True
            }
        }


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    analyzer = QualityAnalyzer()
    
    print("=== å“è³ªåˆ†æå™¨æ¸¬è©¦ (è§€å¯Ÿåå–®é©—è­‰) ===")
    
    # æ¸¬è©¦å·²çŸ¥å•é¡Œå…¬å¸
    test_cases = [
        # é©—è­‰å¤±æ•—
        {
            'company_code': '6462',
            'company_name': 'ase',
            'validation_errors': ['å…¬å¸åç¨±ä¸ç¬¦è§€å¯Ÿåå–®'],
            'content_validation_passed': False
        },
        # ä¸åœ¨è§€å¯Ÿåå–®
        {
            'company_code': '1122',
            'company_name': 'å¨å‰›',
            'validation_errors': ['ä¸åœ¨è§€å¯Ÿåå–®ä¸­'],
            'content_validation_passed': False
        },
        # æ­£å¸¸å…¬å¸
        {
            'company_code': '2330',
            'company_name': 'å°ç©é›»',
            'validation_errors': [],
            'content_validation_passed': True,
            'analyst_count': 42,
            'target_price': 650.5,
            'eps_2025_avg': 46.0
        }
    ]
    
    for i, test_data in enumerate(test_cases, 1):
        print(f"\næ¸¬è©¦ {i}: {test_data['company_code']} ({test_data['company_name']})")
        result = analyzer.analyze(test_data)
        score = result['quality_score']
        status = result['quality_status']
        print(f"   å“è³ªè©•åˆ†: {score} {status}")
        
        if test_data['company_code'] in ['6462', '1122']:
            expected = "0.0 âŒ é©—è­‰å¤±æ•—"
            actual = f"{score} {status}"
            print(f"   é æœŸ: {expected}")
            print(f"   å¯¦éš›: {actual}")
            print(f"   çµæœ: {'âœ… æ­£ç¢º' if score == 0.0 else 'âŒ éŒ¯èª¤'}")
    
    print(f"\nâœ… å“è³ªåˆ†æå™¨å·²å•Ÿå‹•ï¼")
    print(f"âŒ æ‰€æœ‰é©—è­‰å¤±æ•—çš„å…¬å¸å°‡è¢«å¼·åˆ¶è¨­å®šç‚º 0 åˆ†")