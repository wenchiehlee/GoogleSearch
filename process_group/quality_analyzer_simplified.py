#!/usr/bin/env python3
"""
Simplified Quality Analyzer - FactSet Pipeline v3.8.0
UPDATED: Added Revenue scoring + Strict validation for EPS and Revenue
- EPS Validation: High >= Median AND Average >= Low (else score = 0)
- Revenue Validation: High >= Average AND Median >= Low (else score = 0)
- Date freshness has ZERO weight (0%) AND 0-5 years old = all equally valid (10.0)
"""

from datetime import datetime
from typing import Dict, Any

class QualityAnalyzerSimplified:
    """ç°¡åŒ–å“è³ªåˆ†æå™¨ v3.8.0 - åŒ…å«ç‡Ÿæ”¶è©•åˆ†èˆ‡åš´æ ¼é©—è­‰"""

    # å“è³ªç¯„åœå®šç¾©
    QUALITY_RANGES = {
        'complete': (9.0, 10.0),      # ğŸŸ¢ å®Œæ•´ (9.0-10.0)
        'good': (8.0, 8.99),          # ğŸŸ¡ è‰¯å¥½ (8.0-8.99)
        'partial': (3.0, 7.99),       # ğŸŸ  éƒ¨åˆ† (3.0-7.99)
        'insufficient': (0.0, 2.99)   # ğŸ”´ ä¸è¶³ (0.0-2.99)
    }

    # å“è³ªç‹€æ…‹æŒ‡æ¨™
    QUALITY_INDICATORS = {
        'complete': 'ğŸŸ¢ å®Œæ•´',
        'good': 'ğŸŸ¡ è‰¯å¥½',
        'partial': 'ğŸŸ  éƒ¨åˆ†',
        'insufficient': 'ğŸ”´ ä¸è¶³'
    }

    # æ›´æ–°è©•åˆ†æ¬Šé‡ (ç¸½å’Œ = 100%)
    WEIGHTS = {
        'eps_quality': 0.35,        # EPS è³‡æ–™å“è³ª 35% (é™ä½)
        'revenue_quality': 0.25,    # ç‡Ÿæ”¶è³‡æ–™å“è³ª 25% (æ–°å¢)
        'analyst_coverage': 0.30,   # åˆ†æå¸«è¦†è“‹ 30% (é™ä½)
        'data_freshness': 0.00,     # è³‡æ–™æ–°é®®åº¦ 0% (å®Œå…¨ç§»é™¤æ—¥æœŸå½±éŸ¿)
        'target_consistency': 0.10  # ç›®æ¨™åƒ¹èˆ‡ä¸€è‡´æ€§ 10% (ä¿æŒ)
    }

    def __init__(self):
        """åˆå§‹åŒ–ç°¡åŒ–å“è³ªåˆ†æå™¨ v3.8.0"""
        pass

    def analyze(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†ææ–¹æ³• v3.8.0 - åŒ…å«ç‡Ÿæ”¶è©•åˆ†

        æ¬„ä½:
        1. MDæ—¥æœŸ (content_date)
        2. åˆ†æå¸«æ•¸é‡ (analyst_count)
        3. ç›®æ¨™åƒ¹ (target_price)
        4-12. EPSæ¬„ä½ (eps_2025/2026/2027_high/low/avg/median)
        13-21. ç‡Ÿæ”¶æ¬„ä½ (revenue_2025/2026/2027_high/low/avg/median)
        """
        try:
            company_code = parsed_data.get('company_code', '')
            company_name = parsed_data.get('company_name', '')

            # è¨ˆç®—äº”å€‹çµ„ä»¶åˆ†æ•¸
            eps_score = self._calculate_eps_quality(parsed_data)
            revenue_score = self._calculate_revenue_quality(parsed_data)
            analyst_score = self._calculate_analyst_coverage(parsed_data)
            freshness_score = self._calculate_data_freshness(parsed_data)
            target_score = self._calculate_target_consistency(parsed_data)

            # åŠ æ¬Šç¸½åˆ†
            final_score = (
                eps_score * self.WEIGHTS['eps_quality'] +
                revenue_score * self.WEIGHTS['revenue_quality'] +
                analyst_score * self.WEIGHTS['analyst_coverage'] +
                freshness_score * self.WEIGHTS['data_freshness'] +
                target_score * self.WEIGHTS['target_consistency']
            )

            # å››æ¨äº”å…¥åˆ°ä¸€ä½å°æ•¸
            final_score = round(final_score, 1)

            # ç¢ºå®šå“è³ªé¡åˆ¥
            quality_category = self._determine_quality_category(final_score)
            quality_status = self.QUALITY_INDICATORS[quality_category]

            return {
                'quality_score': final_score,
                'quality_status': quality_status,
                'quality_category': quality_category,
                'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),

                'component_scores': {
                    'eps_quality': round(eps_score, 2),
                    'revenue_quality': round(revenue_score, 2),
                    'analyst_coverage': round(analyst_score, 2),
                    'data_freshness': round(freshness_score, 2),
                    'target_consistency': round(target_score, 2)
                },

                'weighted_contributions': {
                    'eps_quality': round(eps_score * self.WEIGHTS['eps_quality'], 2),
                    'revenue_quality': round(revenue_score * self.WEIGHTS['revenue_quality'], 2),
                    'analyst_coverage': round(analyst_score * self.WEIGHTS['analyst_coverage'], 2),
                    'data_freshness': round(freshness_score * self.WEIGHTS['data_freshness'], 2),
                    'target_consistency': round(target_score * self.WEIGHTS['target_consistency'], 2)
                },

                'summary_metrics': {
                    'eps_years_available': sum(1 for year in ['2026', '2027', '2028']
                                              if parsed_data.get(f'eps_{year}_avg') is not None),
                    'revenue_years_available': sum(1 for year in ['2026', '2027', '2028']
                                                  if parsed_data.get(f'revenue_{year}_avg') is not None),
                    'analyst_count': parsed_data.get('analyst_count', 0),
                    'has_target_price': parsed_data.get('target_price') is not None,
                    'content_age_days': self._get_age_days(parsed_data.get('content_date'))
                }
            }

        except Exception as e:
            print(f"âŒ ç°¡åŒ–å“è³ªåˆ†æå¤±æ•—: {e}")
            return self._create_empty_analysis(str(e))

    def _calculate_eps_quality(self, data: Dict) -> float:
        """
        è¨ˆç®— EPS è³‡æ–™å“è³ªåˆ†æ•¸ (0-10) - v3.8.0 åš´æ ¼é©—è­‰

        åš´æ ¼é©—è­‰è¦å‰‡:
        - High >= Median (ä¸­ä½æ•¸)
        - Average >= Low
        - ä»»ä¸€å¹´ä¸ç¬¦åˆ â†’ æ•´é«” EPS score = 0

        çµ„æˆ:
        - è¦†è“‹ç‡ (50%): æœ‰å¹¾å¹´çš„ EPS è³‡æ–™
        - å“è³ª (50%): EPS ç¯„åœæ˜¯å¦æœ‰æ•ˆ
        """
        eps_years = ['2026', '2027', '2028']

        # å…ˆé€²è¡Œåš´æ ¼é©—è­‰
        for year in eps_years:
            high = data.get(f'eps_{year}_high')
            low = data.get(f'eps_{year}_low')
            avg = data.get(f'eps_{year}_avg')
            median = data.get(f'eps_{year}_median')

            # å¦‚æœè©²å¹´æœ‰ä»»ä½• EPS è³‡æ–™ï¼Œå°±å¿…é ˆå…¨éƒ¨ç¬¦åˆé©—è­‰è¦å‰‡
            if any([high is not None, low is not None, avg is not None, median is not None]):
                # æª¢æŸ¥æ˜¯å¦æœ‰å®Œæ•´è³‡æ–™
                if not all([high is not None, low is not None, avg is not None, median is not None]):
                    # è³‡æ–™ä¸å®Œæ•´ï¼Œä½†ä¸ç®—é©—è­‰å¤±æ•—ï¼Œç¹¼çºŒ
                    continue

                # åš´æ ¼é©—è­‰: High >= Median AND Average >= Low
                if not (high >= median and avg >= low):
                    print(f"âŒ EPS {year} é©—è­‰å¤±æ•—: High({high}) < Median({median}) or Avg({avg}) < Low({low})")
                    return 0.0  # é©—è­‰å¤±æ•—ï¼Œç›´æ¥è¿”å› 0 åˆ†

        # é€šéé©—è­‰å¾Œï¼Œé€²è¡Œæ­£å¸¸è©•åˆ†
        score = 0.0

        # 1. è¦†è“‹ç‡è©•åˆ† (æœ€é«˜5åˆ†)
        eps_available = sum(1 for year in eps_years
                           if data.get(f'eps_{year}_avg') is not None)

        coverage_score = (eps_available / 3) * 5.0
        score += coverage_score

        # 2. ç¯„åœå“è³ªè©•åˆ† (æœ€é«˜5åˆ†)
        quality_score = 0.0

        for year in eps_years:
            high = data.get(f'eps_{year}_high')
            low = data.get(f'eps_{year}_low')
            avg = data.get(f'eps_{year}_avg')

            if all([high is not None, low is not None, avg is not None]):
                # æª¢æŸ¥: Low â‰¤ Avg â‰¤ High
                if low <= avg <= high:
                    quality_score += 1.0

                    # çå‹µ: ç¯„åœç·Šå¯† (High/Low < 2.0)
                    if low > 0 and (high / low) < 2.0:
                        quality_score += 0.67

        quality_score = min(quality_score, 5.0)
        score += quality_score

        return min(score, 10.0)

    def _calculate_revenue_quality(self, data: Dict) -> float:
        """
        è¨ˆç®—ç‡Ÿæ”¶è³‡æ–™å“è³ªåˆ†æ•¸ (0-10) - v3.8.0 æ–°å¢

        åš´æ ¼é©—è­‰è¦å‰‡:
        - High >= Average
        - Median (ä¸­ä½æ•¸) >= Low
        - ä»»ä¸€å¹´ä¸ç¬¦åˆ â†’ æ•´é«”ç‡Ÿæ”¶ score = 0

        çµ„æˆ:
        - è¦†è“‹ç‡ (50%): æœ‰å¹¾å¹´çš„ç‡Ÿæ”¶è³‡æ–™
        - å“è³ª (50%): ç‡Ÿæ”¶ç¯„åœæ˜¯å¦æœ‰æ•ˆ
        """
        revenue_years = ['2026', '2027', '2028']

        # å…ˆé€²è¡Œåš´æ ¼é©—è­‰
        for year in revenue_years:
            high = data.get(f'revenue_{year}_high')
            low = data.get(f'revenue_{year}_low')
            avg = data.get(f'revenue_{year}_avg')
            median = data.get(f'revenue_{year}_median')

            # å¦‚æœè©²å¹´æœ‰ä»»ä½•ç‡Ÿæ”¶è³‡æ–™ï¼Œå°±å¿…é ˆå…¨éƒ¨ç¬¦åˆé©—è­‰è¦å‰‡
            if any([high is not None, low is not None, avg is not None, median is not None]):
                # æª¢æŸ¥æ˜¯å¦æœ‰å®Œæ•´è³‡æ–™
                if not all([high is not None, low is not None, avg is not None, median is not None]):
                    # è³‡æ–™ä¸å®Œæ•´ï¼Œä½†ä¸ç®—é©—è­‰å¤±æ•—ï¼Œç¹¼çºŒ
                    continue

                # åš´æ ¼é©—è­‰: High >= Average AND Median >= Low
                if not (high >= avg and median >= low):
                    print(f"âŒ ç‡Ÿæ”¶ {year} é©—è­‰å¤±æ•—: High({high}) < Avg({avg}) or Median({median}) < Low({low})")
                    return 0.0  # é©—è­‰å¤±æ•—ï¼Œç›´æ¥è¿”å› 0 åˆ†

        # é€šéé©—è­‰å¾Œï¼Œé€²è¡Œæ­£å¸¸è©•åˆ†
        score = 0.0

        # 1. è¦†è“‹ç‡è©•åˆ† (æœ€é«˜5åˆ†)
        revenue_available = sum(1 for year in revenue_years
                               if data.get(f'revenue_{year}_avg') is not None)

        coverage_score = (revenue_available / 3) * 5.0
        score += coverage_score

        # 2. ç¯„åœå“è³ªè©•åˆ† (æœ€é«˜5åˆ†)
        quality_score = 0.0

        for year in revenue_years:
            high = data.get(f'revenue_{year}_high')
            low = data.get(f'revenue_{year}_low')
            avg = data.get(f'revenue_{year}_avg')

            if all([high is not None, low is not None, avg is not None]):
                # æª¢æŸ¥: Low â‰¤ Avg â‰¤ High
                if low <= avg <= high:
                    quality_score += 1.0

                    # çå‹µ: ç¯„åœç·Šå¯† (High/Low < 2.0)
                    if low > 0 and (high / low) < 2.0:
                        quality_score += 0.67

        quality_score = min(quality_score, 5.0)
        score += quality_score

        return min(score, 10.0)

    def _calculate_analyst_coverage(self, data: Dict) -> float:
        """
        è¨ˆç®—åˆ†æå¸«è¦†è“‹åˆ†æ•¸ (0-10)

        åƒ…åŸºæ–¼åˆ†æå¸«æ•¸é‡
        """
        analyst_count = data.get('analyst_count', 0)

        if analyst_count >= 30:
            return 10.0  # å„ªç§€
        elif analyst_count >= 20:
            return 9.0   # å¾ˆå¥½
        elif analyst_count >= 15:
            return 8.0   # è‰¯å¥½
        elif analyst_count >= 10:
            return 6.5   # ä¸­ç­‰
        elif analyst_count >= 5:
            return 4.0   # æœ‰é™
        elif analyst_count >= 1:
            return 2.0   # æ¥µå°‘
        else:
            return 0.0   # ç„¡

    def _calculate_data_freshness(self, data: Dict) -> float:
        """
        è¨ˆç®—è³‡æ–™æ–°é®®åº¦åˆ†æ•¸ (0-10)

        åŸºæ–¼ MDæ—¥æœŸ çš„å¹´é½¡
        æ¬Šé‡è¨­ç‚º 0% - æ—¥æœŸå°å“è³ªåˆ†æ•¸å®Œå…¨ç„¡å½±éŸ¿
        ä¿ç•™æ­¤å‡½æ•¸åƒ…ç”¨æ–¼å ±å‘Šé¡¯ç¤ºï¼Œä¸å½±éŸ¿æœ€çµ‚è©•åˆ†

        æ›´æ–°: æ‰€æœ‰æ—¥æœŸéƒ½è¦–ç‚ºåŒç­‰æœ‰æ•ˆ (10.0åˆ†) - ç„¡å¹´é½¡é™åˆ¶
        """
        content_date = data.get('content_date')

        if not content_date:
            return 0.0

        age_days = self._get_age_days(content_date)

        if age_days is None:
            return 0.0

        # æ‰€æœ‰æœ‰æ•ˆæ—¥æœŸéƒ½çµ¦äºˆæ»¿åˆ† - å®Œå…¨ç„¡å¹´é½¡æ­§è¦–
        return 10.0

    def _calculate_target_consistency(self, data: Dict) -> float:
        """
        è¨ˆç®—ç›®æ¨™åƒ¹èˆ‡ä¸€è‡´æ€§åˆ†æ•¸ (0-10)

        çµ„æˆ:
        - ç›®æ¨™åƒ¹å­˜åœ¨ (60%): 6åˆ†
        - EPS ä¸€è‡´æ€§ (40%): 4åˆ†
        """
        score = 0.0

        # 1. ç›®æ¨™åƒ¹ (6åˆ†)
        target_price = data.get('target_price')
        if target_price is not None and target_price > 0:
            score += 6.0

        # 2. EPS è¶¨å‹¢ä¸€è‡´æ€§ (4åˆ†)
        eps_2026 = data.get('eps_2026_avg')
        eps_2027 = data.get('eps_2027_avg')
        eps_2028 = data.get('eps_2028_avg')

        consistency_score = 4.0

        # æª¢æŸ¥ç•°å¸¸è®ŠåŒ– (>1000% YoY)
        if eps_2026 and eps_2027 and eps_2026 > 0:
            if abs(eps_2027 - eps_2026) > eps_2026 * 10:
                consistency_score -= 2.0

        if eps_2027 and eps_2028 and eps_2027 > 0:
            if abs(eps_2028 - eps_2027) > eps_2027 * 10:
                consistency_score -= 2.0

        score += max(0, consistency_score)

        return min(score, 10.0)

    def _get_age_days(self, content_date) -> int:
        """è¨ˆç®—æ—¥æœŸå¹´é½¡ï¼ˆå¤©æ•¸ï¼‰"""
        if not content_date:
            return None

        try:
            # è§£ææ—¥æœŸæ ¼å¼
            if isinstance(content_date, str):
                if '/' in content_date:
                    # æ ¼å¼: "2025/10/24"
                    parts = content_date.split('/')
                    year, month, day = int(parts[0]), int(parts[1]), int(parts[2])
                elif '-' in content_date:
                    # æ ¼å¼: "2025-10-24"
                    parts = content_date.split('-')
                    year, month, day = int(parts[0]), int(parts[1]), int(parts[2])
                else:
                    return None

                date_obj = datetime(year, month, day)
            elif isinstance(content_date, datetime):
                date_obj = content_date
            else:
                return None

            # è¨ˆç®—å¹´é½¡
            now = datetime.now()
            age_days = (now - date_obj).days

            return age_days

        except Exception as e:
            print(f"âš ï¸ æ—¥æœŸè§£æå¤±æ•—: {e}")
            return None

    def _determine_quality_category(self, score: float) -> str:
        """ç¢ºå®šå“è³ªé¡åˆ¥"""
        for category, (min_score, max_score) in self.QUALITY_RANGES.items():
            if min_score <= score <= max_score:
                return category

        # å‚™ç”¨åˆ†é¡
        if score >= 9.0:
            return 'complete'
        elif score >= 8.0:
            return 'good'
        elif score >= 3.0:
            return 'partial'
        else:
            return 'insufficient'

    def _create_empty_analysis(self, error_msg: str) -> Dict:
        """å»ºç«‹ç©ºçš„åˆ†æçµæœ"""
        return {
            'quality_score': 0.0,
            'quality_status': 'ğŸ”´ ä¸è¶³',
            'quality_category': 'insufficient',
            'error': error_msg,
            'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'component_scores': {
                'eps_quality': 0.0,
                'revenue_quality': 0.0,
                'analyst_coverage': 0.0,
                'data_freshness': 0.0,
                'target_consistency': 0.0
            }
        }


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    analyzer = QualityAnalyzerSimplified()

    print("=== ç°¡åŒ–å“è³ªåˆ†æå™¨æ¸¬è©¦ v3.8.0 ===")
    print(f"æ¬Šé‡é…ç½®: {analyzer.WEIGHTS}")
    print()

    # æ¸¬è©¦æ¡ˆä¾‹1: å®Œç¾è³‡æ–™ (åŒ…å«ç‡Ÿæ”¶)
    test_case_1 = {
        'company_code': '2330',
        'company_name': 'å°ç©é›»',
        'content_date': '2025/12/25',
        'analyst_count': 28,
        'target_price': 850.0,
        'eps_2025_high': 38.5,
        'eps_2025_low': 32.1,
        'eps_2025_avg': 35.2,
        'eps_2025_median': 35.0,
        'eps_2026_high': 46.2,
        'eps_2026_low': 39.5,
        'eps_2026_avg': 42.8,
        'eps_2026_median': 42.5,
        'eps_2027_high': 55.8,
        'eps_2027_low': 47.2,
        'eps_2027_avg': 51.3,
        'eps_2027_median': 51.0,
        'revenue_2025_high': 3500000,
        'revenue_2025_low': 3200000,
        'revenue_2025_avg': 3350000,
        'revenue_2025_median': 3340000,
        'revenue_2026_high': 3800000,
        'revenue_2026_low': 3400000,
        'revenue_2026_avg': 3600000,
        'revenue_2026_median': 3590000,
        'revenue_2027_high': 4200000,
        'revenue_2027_low': 3700000,
        'revenue_2027_avg': 3950000,
        'revenue_2027_median': 3940000
    }

    result = analyzer.analyze(test_case_1)
    print(f"æ¸¬è©¦æ¡ˆä¾‹1 (å®Œç¾è³‡æ–™ - EPS + ç‡Ÿæ”¶):")
    print(f"  å“è³ªåˆ†æ•¸: {result['quality_score']}")
    print(f"  å“è³ªç‹€æ…‹: {result['quality_status']}")
    print(f"  çµ„ä»¶åˆ†æ•¸: {result['component_scores']}")
    print(f"  åŠ æ¬Šè²¢ç»: {result['weighted_contributions']}")
    print()

    # æ¸¬è©¦æ¡ˆä¾‹2: EPS é©—è­‰å¤±æ•— (High < Median)
    test_case_2 = {
        'company_code': '2301',
        'company_name': 'å…‰å¯¶ç§‘',
        'content_date': '2025/10/24',
        'analyst_count': 13,
        'target_price': 168.0,
        'eps_2025_high': 6.0,  # High < Median (6.5) â†’ é©—è­‰å¤±æ•—
        'eps_2025_low': 5.97,
        'eps_2025_avg': 6.51,
        'eps_2025_median': 6.5,
        'revenue_2025_high': 150000,
        'revenue_2025_low': 140000,
        'revenue_2025_avg': 145000,
        'revenue_2025_median': 145000
    }

    result = analyzer.analyze(test_case_2)
    print(f"æ¸¬è©¦æ¡ˆä¾‹2 (EPSé©—è­‰å¤±æ•— - High < Median):")
    print(f"  å“è³ªåˆ†æ•¸: {result['quality_score']}")
    print(f"  å“è³ªç‹€æ…‹: {result['quality_status']}")
    print(f"  çµ„ä»¶åˆ†æ•¸: {result['component_scores']}")
    print(f"  é æœŸ: EPS score = 0.0")
    print()

    # æ¸¬è©¦æ¡ˆä¾‹3: ç‡Ÿæ”¶é©—è­‰å¤±æ•— (Median < Low)
    test_case_3 = {
        'company_code': '2454',
        'company_name': 'è¯ç™¼ç§‘',
        'content_date': '2025/11/15',
        'analyst_count': 25,
        'target_price': 1200.0,
        'eps_2025_high': 95.0,
        'eps_2025_low': 85.0,
        'eps_2025_avg': 90.0,
        'eps_2025_median': 90.0,
        'revenue_2025_high': 580000,
        'revenue_2025_low': 520000,
        'revenue_2025_avg': 550000,
        'revenue_2025_median': 500000  # Median < Low â†’ é©—è­‰å¤±æ•—
    }

    result = analyzer.analyze(test_case_3)
    print(f"æ¸¬è©¦æ¡ˆä¾‹3 (ç‡Ÿæ”¶é©—è­‰å¤±æ•— - Median < Low):")
    print(f"  å“è³ªåˆ†æ•¸: {result['quality_score']}")
    print(f"  å“è³ªç‹€æ…‹: {result['quality_status']}")
    print(f"  çµ„ä»¶åˆ†æ•¸: {result['component_scores']}")
    print(f"  é æœŸ: Revenue score = 0.0")
    print()

    print("âœ… ç°¡åŒ–å“è³ªåˆ†æå™¨ v3.8.0 æ¸¬è©¦å®Œæˆ")
    print(f"ğŸ¯ æ–°åŠŸèƒ½:")
    print(f"   âœ… ç‡Ÿæ”¶è©•åˆ† (25% æ¬Šé‡)")
    print(f"   âœ… EPS åš´æ ¼é©—è­‰: High >= Median, Avg >= Low")
    print(f"   âœ… ç‡Ÿæ”¶åš´æ ¼é©—è­‰: High >= Avg, Median >= Low")
