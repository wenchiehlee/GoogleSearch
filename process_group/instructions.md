# FactSet Pipeline v3.5.0 - Process Group å®Œæ•´å¯¦ä½œæŒ‡å—

## Version
{Process Group Instructions}=3.5.0

## ğŸ¯ Process Group æ¦‚è¿°

**ç›®æ¨™**: å°ˆé–€è™•ç† MD æª”æ¡ˆçš„ç¨ç«‹ç¾¤çµ„ï¼Œå®Œå…¨é€éæª”æ¡ˆç³»çµ±èˆ‡ Search Group é€šè¨Š

**è¼¸å…¥**: `data/md/*.md` æª”æ¡ˆ (ç”± Search Group ç”Ÿæˆ)
**è¼¸å‡º**: Google Sheets å ±å‘Š + CSV æª”æ¡ˆ

**v3.5.0 æ¶æ§‹ç‰¹é»**: 
- âœ… å®Œå…¨ç¨ç«‹æ–¼ Search Group
- âœ… é€éæª”æ¡ˆå¤¾ä»‹é¢é€šè¨Š (`data/md/`)
- âœ… æ¨¡çµ„åŒ–å°æª”æ¡ˆ (150-500 è¡Œ)
- âœ… å–®ä¸€è·è²¬è¨­è¨ˆ
- âœ… å‘ä¸‹ç›¸å®¹æ•´åˆ

## ğŸ“ Process Group æª”æ¡ˆçµæ§‹

```
process_group/                           # ğŸ“Š è™•ç†ç¾¤çµ„ç›®éŒ„
â”œâ”€â”€ md_scanner.py                       # 150 è¡Œ - æª”æ¡ˆç³»çµ±ä»‹é¢
â”œâ”€â”€ process_cli.py                      # 450 è¡Œ - å‘½ä»¤åˆ—ä»‹é¢
â”œâ”€â”€ md_parser.py                        # 500 è¡Œ - MD å…§å®¹è§£æ
â”œâ”€â”€ quality_analyzer.py                 # 500 è¡Œ - å“è³ªåˆ†æ
â”œâ”€â”€ report_generator.py                 # 500 è¡Œ - å ±å‘Šç”Ÿæˆ
â”œâ”€â”€ sheets_uploader.py                  # 400 è¡Œ - Google Sheets ä¸Šå‚³
â””â”€â”€ process_logger.py                   # 100 è¡Œ - æ—¥èªŒç³»çµ± (å¯é¸)
```

## ğŸ”§ æ ¸å¿ƒè¨­è¨ˆåŸå‰‡

### 1. æª”æ¡ˆå¤¾é€šè¨ŠåŸå‰‡
```python
# Process Group åªéœ€è¦çŸ¥é“é€™å€‹ç›®éŒ„
MD_FILES_DIR = "data/md"  # æˆ– "../data/md" (å–æ±ºæ–¼åŸ·è¡Œä½ç½®)

# ä¸éœ€è¦çŸ¥é“ Search Group å¦‚ä½•å»ºç«‹é€™äº›æª”æ¡ˆ
# ä¸éœ€è¦ JSON ä¸­ä»‹æ ¼å¼
# ä¸éœ€è¦è¤‡é›œçš„ API é€šè¨Š
```

### 2. å–®ä¸€è·è²¬åŸå‰‡
```python
# æ¯å€‹æª”æ¡ˆå°ˆæ³¨ä¸€å€‹åŠŸèƒ½
md_scanner.py      â†’ åªç®¡æƒæ MD æª”æ¡ˆ
md_parser.py       â†’ åªç®¡è§£æ MD å…§å®¹  
quality_analyzer.py â†’ åªç®¡å“è³ªè©•åˆ†
report_generator.py â†’ åªç®¡ç”Ÿæˆå ±å‘Š
sheets_uploader.py â†’ åªç®¡ä¸Šå‚³ Sheets
```

### 3. ç¨ç«‹æ€§åŸå‰‡
```python
# æ¯å€‹æ¨¡çµ„éƒ½å¯ä»¥ç¨ç«‹æ¸¬è©¦
python md_scanner.py     # æ¸¬è©¦æª”æ¡ˆæƒæ
python md_parser.py      # æ¸¬è©¦å…§å®¹è§£æ
python quality_analyzer.py # æ¸¬è©¦å“è³ªè©•åˆ†
```

## ğŸ“‹ æª”æ¡ˆå¯¦ä½œè¦æ ¼

### 1. MD Scanner (`md_scanner.py`) - 150 è¡Œ

#### è·è²¬
- æƒæ `data/md/` ç›®éŒ„ä¸­çš„æ‰€æœ‰ MD æª”æ¡ˆ
- æä¾›æª”æ¡ˆæ¸…å–®ã€æª”æ¡ˆè³‡è¨Šã€çµ±è¨ˆè³‡æ–™
- ä½œç‚º Process Group èˆ‡æª”æ¡ˆç³»çµ±çš„å”¯ä¸€ä»‹é¢

#### æ ¸å¿ƒé¡åˆ¥
```python
class MDScanner:
    def __init__(self, md_dir="../data/md"):
        self.md_dir = md_dir
        self._ensure_md_directory()
    
    # æ ¸å¿ƒæ–¹æ³•
    def scan_all_md_files(self) -> List[str]:
        """æƒææ‰€æœ‰ MD æª”æ¡ˆï¼ŒæŒ‰æ™‚é–“æ’åº"""
    
    def scan_recent_files(self, hours=24) -> List[str]:
        """æƒææœ€è¿‘ N å°æ™‚çš„æª”æ¡ˆ"""
    
    def find_company_files(self, company_code: str) -> List[str]:
        """å°‹æ‰¾ç‰¹å®šå…¬å¸çš„æª”æ¡ˆ"""
    
    def get_latest_file_per_company(self) -> Dict[str, str]:
        """å–å¾—æ¯å®¶å…¬å¸çš„æœ€æ–°æª”æ¡ˆ"""
    
    def get_file_info(self, file_path: str) -> Dict[str, Any]:
        """å–å¾—æª”æ¡ˆè©³ç´°è³‡è¨Š"""
    
    def get_stats(self) -> Dict[str, Any]:
        """å–å¾—çµ±è¨ˆè³‡è¨Š"""
```

#### æª”æ¡ˆåç¨±è§£æ
```python
# é æœŸçš„æª”æ¡ˆåç¨±æ ¼å¼
# {company_code}_{company_name}_{source}_{hash}_{timestamp}.md
# ä¾‹å¦‚: 2330_å°ç©é›»_factset_abc123_0626_1030.md

def _extract_company_code(self, file_path: str) -> str:
    """å¾æª”æ¡ˆåç¨±æå–å…¬å¸ä»£è™Ÿ"""
    filename = os.path.basename(file_path)
    parts = filename.replace('.md', '').split('_')
    return parts[0] if parts and parts[0].isdigit() and len(parts[0]) == 4 else None
```

#### çµ±è¨ˆåŠŸèƒ½
```python
def get_stats(self) -> Dict[str, Any]:
    """æä¾›å®Œæ•´çš„æª”æ¡ˆçµ±è¨ˆ"""
    return {
        'total_files': int,
        'recent_files_24h': int,
        'unique_companies': int,
        'total_size_mb': float,
        'companies_with_files': Dict[str, int],
        'oldest_file': str,
        'newest_file': str
    }
```

---

### 2. Process CLI (`process_cli.py`) - 450 è¡Œ

#### è·è²¬
- æä¾›å‘½ä»¤åˆ—ä»‹é¢
- å”èª¿å„æ¨¡çµ„çš„åŸ·è¡Œ
- è™•ç†éŒ¯èª¤å’Œæ—¥èªŒ
- æ”¯æ´å‘ä¸‹ç›¸å®¹æ€§

#### æ ¸å¿ƒé¡åˆ¥
```python
class ProcessCLI:
    def __init__(self):
        self.md_scanner = MDScanner()
        # å¯é¸æ¨¡çµ„ (graceful degradation)
        self.md_parser = None
        self.quality_analyzer = None  
        self.report_generator = None
        self.sheets_uploader = None
        self._init_optional_components()
    
    # ä¸»è¦å‘½ä»¤
    def process_all_md_files(self, upload_sheets=True, **kwargs):
        """è™•ç†æ‰€æœ‰ MD æª”æ¡ˆ"""
    
    def process_recent_md_files(self, hours=24, upload_sheets=True, **kwargs):
        """è™•ç†æœ€è¿‘çš„æª”æ¡ˆ"""
    
    def process_single_company(self, company_code: str, upload_sheets=True, **kwargs):
        """è™•ç†å–®ä¸€å…¬å¸"""
    
    def analyze_quality_only(self, **kwargs):
        """åªé€²è¡Œå“è³ªåˆ†æ"""
    
    def show_md_stats(self, **kwargs):
        """é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š"""
    
    def validate_setup(self, **kwargs):
        """é©—è­‰ç’°å¢ƒè¨­å®š"""
```

#### å‘½ä»¤åˆ—ä»‹é¢
```python
def main():
    parser = argparse.ArgumentParser(description='FactSet è™•ç†ç³»çµ± v3.5.0')
    parser.add_argument('command', choices=[
        'process',           # è™•ç†æ‰€æœ‰ MD æª”æ¡ˆ
        'process-recent',    # è™•ç†æœ€è¿‘çš„ MD æª”æ¡ˆ
        'process-single',    # è™•ç†å–®ä¸€å…¬å¸
        'analyze-quality',   # å“è³ªåˆ†æ
        'stats',            # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        'validate'          # é©—è­‰ç’°å¢ƒè¨­å®š
    ])
    parser.add_argument('--company', help='å…¬å¸ä»£è™Ÿ')
    parser.add_argument('--hours', type=int, default=24, help='å°æ™‚æ•¸')
    parser.add_argument('--no-upload', action='store_true', help='ä¸ä¸Šå‚³åˆ° Sheets')
```

#### éŒ¯èª¤è™•ç†
```python
def _init_optional_components(self):
    """åˆå§‹åŒ–å¯é¸çµ„ä»¶ï¼Œæ”¯æ´ graceful degradation"""
    try:
        self.md_parser = MDParser()
    except ImportError:
        pass
    
    # åŸºæœ¬åŠŸèƒ½ (åªç”¨ MDScanner) ç¸½æ˜¯å¯ç”¨
    # é€²éšåŠŸèƒ½ (å“è³ªåˆ†æã€å ±å‘Šç”Ÿæˆ) å¯é¸
```

---

### 3. MD Parser (`md_parser.py`) - 500 è¡Œ

#### è·è²¬
- è§£æ MD æª”æ¡ˆå…§å®¹
- æå– EPS é æ¸¬è³‡æ–™ (2025-2027)
- æå–ç›®æ¨™åƒ¹æ ¼å’Œåˆ†æå¸«æ•¸é‡
- è¨ˆç®—è³‡æ–™è±å¯Œåº¦

#### æ ¸å¿ƒé¡åˆ¥
```python
class MDParser:
    def __init__(self):
        # EPS æ­£å‰‡è¡¨é”å¼æ¨¡å¼
        self.eps_patterns = [
            r'(\d{4})\s*eps\s*[é ä¼°é æ¸¬ä¼°ç®—]*\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
            r'eps\s*(\d{4})\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
            # ... æ›´å¤šæ¨¡å¼
        ]
        
        # ç›®æ¨™åƒ¹æ ¼æ¨¡å¼
        self.target_price_patterns = [
            r'ç›®æ¨™åƒ¹\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
            r'target\s*price\s*[:ï¼š]\s*([0-9]+\.?[0-9]*)',
            # ... æ›´å¤šæ¨¡å¼
        ]
    
    def parse_md_file(self, file_path: str) -> Dict[str, Any]:
        """ä¸»è¦è§£ææ–¹æ³•"""
```

#### è§£æçµæœæ ¼å¼
```python
# parse_md_file è¿”å›æ ¼å¼
{
    # åŸºæœ¬è³‡è¨Š (å¾æª”æ¡ˆè·¯å¾‘)
    'filename': str,
    'company_code': str,
    'company_name': str,
    'data_source': str,
    'file_mtime': datetime,
    
    # EPS è³‡æ–™
    'eps_2025_high': float,
    'eps_2025_low': float,
    'eps_2025_avg': float,
    'eps_2026_high': float,
    'eps_2026_low': float,
    'eps_2026_avg': float,
    'eps_2027_high': float,
    'eps_2027_low': float,
    'eps_2027_avg': float,
    
    # å…¶ä»–è²¡å‹™è³‡æ–™
    'target_price': float,
    'analyst_count': int,
    
    # è³‡æ–™ç‹€æ…‹
    'has_eps_data': bool,
    'has_target_price': bool,
    'has_analyst_info': bool,
    'data_richness_score': float,
    
    # åŸå§‹å…§å®¹
    'content': str,
    'content_length': int,
    'parsed_at': datetime
}
```

#### æ ¸å¿ƒè§£ææ–¹æ³•
```python
def _extract_eps_data(self, content: str) -> Dict[str, List[float]]:
    """æå– EPS è³‡æ–™"""
    # è¿”å› {'2025': [46.0, 45.5], '2026': [52.3], ...}

def _extract_target_price(self, content: str) -> Optional[float]:
    """æå–ç›®æ¨™åƒ¹æ ¼"""
    
def _extract_analyst_count(self, content: str) -> int:
    """æå–åˆ†æå¸«æ•¸é‡"""

def _calculate_eps_statistics(self, eps_data: Dict) -> Dict[str, Any]:
    """è¨ˆç®— EPS çµ±è¨ˆ (é«˜ã€ä½ã€å¹³å‡)"""
```

---

### 4. Quality Analyzer (`quality_analyzer.py`) - 500 è¡Œ

#### è·è²¬
- å¯¦ä½œæ¨™æº–åŒ– 0-10 å“è³ªè©•åˆ†ç³»çµ±
- å¤šç¶­åº¦å“è³ªåˆ†æ
- ç”Ÿæˆå“è³ªç‹€æ…‹æŒ‡æ¨™

#### æ ¸å¿ƒé¡åˆ¥
```python
class QualityAnalyzer:
    # å“è³ªç¯„åœå®šç¾©
    QUALITY_RANGES = {
        'complete': (9, 10),      # ğŸŸ¢ å®Œæ•´
        'good': (8, 8),           # ğŸŸ¡ è‰¯å¥½
        'partial': (3, 7),        # ğŸŸ  éƒ¨åˆ†
        'insufficient': (0, 2)    # ğŸ”´ ä¸è¶³
    }
    
    # è©•åˆ†æ¬Šé‡
    QUALITY_WEIGHTS = {
        'data_completeness': 0.35,    # è³‡æ–™å®Œæ•´æ€§ 35%
        'analyst_coverage': 0.25,     # åˆ†æå¸«è¦†è“‹ 25%
        'data_freshness': 0.20,       # è³‡æ–™æ–°é®®åº¦ 20%
        'content_quality': 0.15,      # å…§å®¹å“è³ª 15%
        'data_consistency': 0.05      # è³‡æ–™ä¸€è‡´æ€§ 5%
    }
    
    def analyze(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸»è¦åˆ†ææ–¹æ³•"""
```

#### åˆ†æçµæœæ ¼å¼
```python
# analyze æ–¹æ³•è¿”å›æ ¼å¼
{
    'quality_score': float,      # 0-10 è©•åˆ†
    'quality_status': str,       # ğŸŸ¢ğŸŸ¡ğŸŸ ğŸ”´ æŒ‡æ¨™
    'quality_category': str,     # complete/good/partial/insufficient
    'analysis_timestamp': str,
    
    'detailed_analysis': {
        'data_completeness': {
            'score': float,
            'details': List[str],
            'metrics': Dict
        },
        'analyst_coverage': {...},
        'data_freshness': {...},
        'content_quality': {...},
        'data_consistency': {...}
    },
    
    'summary_metrics': {
        'eps_data_available': bool,
        'target_price_available': bool,
        'analyst_count': int,
        'content_length': int,
        'financial_keywords_found': int
    }
}
```

#### å„ç¶­åº¦åˆ†ææ–¹æ³•
```python
def _analyze_data_completeness(self, data: Dict) -> Dict:
    """åˆ†æè³‡æ–™å®Œæ•´æ€§ (35% æ¬Šé‡)"""
    # EPS è³‡æ–™å®Œæ•´æ€§ã€ç›®æ¨™åƒ¹æ ¼ã€åˆ†æå¸«æ•¸é‡ã€åŸºæœ¬è³‡è¨Š

def _analyze_analyst_coverage(self, data: Dict) -> Dict:
    """åˆ†æåˆ†æå¸«è¦†è“‹åº¦ (25% æ¬Šé‡)"""
    # åˆ†æå¸«æ•¸é‡ã€è³‡æ–™ä¾†æºå¤šæ¨£æ€§

def _analyze_data_freshness(self, data: Dict) -> Dict:
    """åˆ†æè³‡æ–™æ–°é®®åº¦ (20% æ¬Šé‡)"""
    # æª”æ¡ˆæ™‚é–“ã€å…§å®¹æ™‚æ•ˆæ€§

def _analyze_content_quality(self, data: Dict) -> Dict:
    """åˆ†æå…§å®¹å“è³ª (15% æ¬Šé‡)"""
    # å…§å®¹é•·åº¦ã€é—œéµå­—è¦†è“‹ã€ä¾†æºå“è³ª

def _analyze_data_consistency(self, data: Dict) -> Dict:
    """åˆ†æè³‡æ–™ä¸€è‡´æ€§ (5% æ¬Šé‡)"""
    # EPS è¶¨å‹¢ã€å…¬å¸è³‡è¨Šã€ç›®æ¨™åƒ¹æ ¼åˆç†æ€§
```

---

### 5. Report Generator (`report_generator.py`) - 500 è¡Œ

#### è·è²¬
- ç”Ÿæˆæ¨™æº–åŒ–æŠ•è³‡çµ„åˆå ±å‘Š
- æ”¯æ´ 14 æ¬„ä½æ‘˜è¦ + 21 æ¬„ä½è©³ç´°æ ¼å¼
- æ•´åˆ GitHub Raw URL é€£çµ
- ç”Ÿæˆçµ±è¨ˆå ±å‘Š

#### æ ¸å¿ƒé¡åˆ¥
```python
class ReportGenerator:
    def __init__(self, github_repo_base="https://raw.githubusercontent.com/..."):
        self.github_repo_base = github_repo_base
        self.output_dir = "data/reports"
        
        # æ¬„ä½å®šç¾©
        self.portfolio_summary_columns = [
            'ä»£è™Ÿ', 'åç¨±', 'è‚¡ç¥¨ä»£è™Ÿ', 'MDæœ€èˆŠæ—¥æœŸ', 'MDæœ€æ–°æ—¥æœŸ', 'MDè³‡æ–™ç­†æ•¸',
            'åˆ†æå¸«æ•¸é‡', 'ç›®æ¨™åƒ¹', '2025EPSå¹³å‡å€¼', '2026EPSå¹³å‡å€¼', '2027EPSå¹³å‡å€¼',
            'å“è³ªè©•åˆ†', 'ç‹€æ…‹', 'æ›´æ–°æ—¥æœŸ'
        ]
        
        self.detailed_report_columns = [
            'ä»£è™Ÿ', 'åç¨±', 'è‚¡ç¥¨ä»£è™Ÿ', 'MDæ—¥æœŸ', 'åˆ†æå¸«æ•¸é‡', 'ç›®æ¨™åƒ¹',
            '2025EPSæœ€é«˜å€¼', '2025EPSæœ€ä½å€¼', '2025EPSå¹³å‡å€¼',
            '2026EPSæœ€é«˜å€¼', '2026EPSæœ€ä½å€¼', '2026EPSå¹³å‡å€¼',
            '2027EPSæœ€é«˜å€¼', '2027EPSæœ€ä½å€¼', '2027EPSå¹³å‡å€¼',
            'å“è³ªè©•åˆ†', 'ç‹€æ…‹', 'MD File', 'æ›´æ–°æ—¥æœŸ'
        ]
    
    def generate_portfolio_summary(self, processed_companies: List[Dict]) -> pd.DataFrame:
        """ç”ŸæˆæŠ•è³‡çµ„åˆæ‘˜è¦ (14 æ¬„ä½)"""
    
    def generate_detailed_report(self, processed_companies: List[Dict]) -> pd.DataFrame:
        """ç”Ÿæˆè©³ç´°å ±å‘Š (21 æ¬„ä½)"""
    
    def save_reports(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame) -> Dict[str, str]:
        """å„²å­˜å ±å‘Šç‚º CSV"""
```

#### GitHub Raw URL æ ¼å¼åŒ–
```python
def _format_md_file_link(self, filename: str) -> str:
    """æ ¼å¼åŒ– MD æª”æ¡ˆç‚º GitHub Raw URL"""
    # è¼¸å‡ºæ ¼å¼: [filename.md](GitHub_Raw_URL)
    encoded_filename = urllib.parse.quote(filename, safe='')
    raw_url = f"{self.github_repo_base}/data/md/{encoded_filename}"
    return f"[{filename}]({raw_url})"
```

#### å ±å‘Šæ ¼å¼ç¯„ä¾‹
```csv
# Portfolio Summary (14 æ¬„ä½)
ä»£è™Ÿ,åç¨±,è‚¡ç¥¨ä»£è™Ÿ,MDæœ€èˆŠæ—¥æœŸ,MDæœ€æ–°æ—¥æœŸ,MDè³‡æ–™ç­†æ•¸,åˆ†æå¸«æ•¸é‡,ç›®æ¨™åƒ¹,2025EPSå¹³å‡å€¼,2026EPSå¹³å‡å€¼,2027EPSå¹³å‡å€¼,å“è³ªè©•åˆ†,ç‹€æ…‹,æ›´æ–°æ—¥æœŸ
2330,å°ç©é›»,2330-TW,2025/06/24,2025/06/24,1,42,650.5,46.00,23.56,23.56,10,ğŸŸ¢ å®Œæ•´,2025-06-24 10:45:00

# Detailed Report (21 æ¬„ä½)
ä»£è™Ÿ,åç¨±,è‚¡ç¥¨ä»£è™Ÿ,MDæ—¥æœŸ,åˆ†æå¸«æ•¸é‡,ç›®æ¨™åƒ¹,2025EPSæœ€é«˜å€¼,2025EPSæœ€ä½å€¼,2025EPSå¹³å‡å€¼,2026EPSæœ€é«˜å€¼,2026EPSæœ€ä½å€¼,2026EPSå¹³å‡å€¼,2027EPSæœ€é«˜å€¼,2027EPSæœ€ä½å€¼,2027EPSå¹³å‡å€¼,å“è³ªè©•åˆ†,ç‹€æ…‹,MD File,æ›´æ–°æ—¥æœŸ
2330,å°ç©é›»,2330-TW,2025/06/23,42,,59.66,6.00,46.00,32.34,6.00,23.56,32.34,6.00,23.56,10,ğŸŸ¢ å®Œæ•´,[2330_å°ç©é›»_factset_abc123.md](https://raw.github...),2025-06-24 05:52:02
```

---

### 6. Sheets Uploader (`sheets_uploader.py`) - 400 è¡Œ

#### è·è²¬
- ä¸Šå‚³å ±å‘Šåˆ° Google Sheets
- è¨­å®šå·¥ä½œè¡¨æ ¼å¼å’Œæ¨£å¼
- è™•ç† Google Sheets API é€£ç·š
- æ”¯æ´é€£ç·šæ¸¬è©¦

#### æ ¸å¿ƒé¡åˆ¥
```python
class SheetsUploader:
    def __init__(self, github_repo_base="https://raw.githubusercontent.com/..."):
        self.github_repo_base = github_repo_base
        self.client = None
        self.spreadsheet = None
    
    def upload_reports(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame) -> bool:
        """ä¸»è¦ä¸Šå‚³æ–¹æ³•"""
    
    def test_connection(self) -> bool:
        """æ¸¬è©¦ Google Sheets é€£ç·š"""
    
    def _setup_connection(self) -> bool:
        """è¨­å®š Google Sheets é€£ç·š"""
    
    def _upload_portfolio_summary(self, portfolio_df: pd.DataFrame) -> bool:
        """ä¸Šå‚³æŠ•è³‡çµ„åˆæ‘˜è¦"""
    
    def _upload_detailed_report(self, detailed_df: pd.DataFrame) -> bool:
        """ä¸Šå‚³è©³ç´°å ±å‘Š"""
```

#### ç’°å¢ƒè®Šæ•¸éœ€æ±‚
```python
# éœ€è¦çš„ç’°å¢ƒè®Šæ•¸
GOOGLE_SHEET_ID=your_sheet_id
GOOGLE_SHEETS_CREDENTIALS={"type": "service_account", ...}
```

#### ä¾è³´å¥—ä»¶
```python
# requirements éœ€è¦
gspread>=5.0.0
google-auth>=2.0.0
pandas>=1.3.0
python-dotenv>=0.19.0
```

---

## ğŸ”— æ¨¡çµ„æ•´åˆæ¨¡å¼

### 1. Process CLI æ•´åˆæ¨¡å¼
```python
class ProcessCLI:
    def process_all_md_files(self, **kwargs):
        # 1. æƒææª”æ¡ˆ
        md_files = self.md_scanner.scan_all_md_files()
        
        # 2. è§£ææ¯å€‹æª”æ¡ˆ
        processed_companies = []
        for md_file in md_files:
            parsed_data = self.md_parser.parse_md_file(md_file)
            quality_data = self.quality_analyzer.analyze(parsed_data)
            company_data = {**parsed_data, **quality_data}
            processed_companies.append(company_data)
        
        # 3. ç”Ÿæˆå ±å‘Š
        portfolio_summary = self.report_generator.generate_portfolio_summary(processed_companies)
        detailed_report = self.report_generator.generate_detailed_report(processed_companies)
        
        # 4. ä¸Šå‚³ (å¯é¸)
        if upload_sheets:
            self.sheets_uploader.upload_reports(portfolio_summary, detailed_report)
```

### 2. éŒ¯èª¤è™•ç†æ¨¡å¼
```python
def _init_optional_components(self):
    """Graceful degradation æ¨¡å¼"""
    components = [
        ('md_parser', MDParser),
        ('quality_analyzer', QualityAnalyzer),
        ('report_generator', ReportGenerator),
        ('sheets_uploader', SheetsUploader)
    ]
    
    for name, cls in components:
        try:
            setattr(self, name, cls())
        except ImportError:
            setattr(self, name, None)
            print(f"âš ï¸ {name} æ¨¡çµ„æœªè¼‰å…¥")
```

### 3. è³‡æ–™æµå‹•æ¨¡å¼
```
MD Files â†’ MDScanner â†’ ProcessCLI â†’ MDParser â†’ QualityAnalyzer â†’ ReportGenerator â†’ SheetsUploader
   â†“           â†“           â†“           â†“            â†“               â†“              â†“
æª”æ¡ˆæ¸…å–®    æª”æ¡ˆè³‡è¨Š    è§£æè³‡æ–™    å“è³ªè©•åˆ†     çµæ§‹åŒ–è³‡æ–™      CSVå ±å‘Š      Google Sheets
```

## ğŸ§ª æ¸¬è©¦å’Œé©—è­‰

### 1. å–®å…ƒæ¸¬è©¦æ¨¡å¼
```python
# æ¯å€‹æ¨¡çµ„éƒ½æ”¯æ´ç¨ç«‹æ¸¬è©¦
if __name__ == "__main__":
    # å»ºç«‹æ¸¬è©¦è³‡æ–™
    # åŸ·è¡Œæ ¸å¿ƒåŠŸèƒ½
    # é¡¯ç¤ºæ¸¬è©¦çµæœ
```

### 2. æ•´åˆæ¸¬è©¦æ¨¡å¼
```python
# process_cli.py ä¸­çš„é©—è­‰å‘½ä»¤
def validate_setup(self):
    """é©—è­‰æ‰€æœ‰çµ„ä»¶"""
    results = {}
    
    # æ¸¬è©¦æª”æ¡ˆæƒæ
    md_files = self.md_scanner.scan_all_md_files()
    results['md_scanner'] = f"æ‰¾åˆ° {len(md_files)} å€‹æª”æ¡ˆ"
    
    # æ¸¬è©¦å…¶ä»–çµ„ä»¶...
    return results
```

### 3. ä½¿ç”¨è€…æ¸¬è©¦æ¨¡å¼
```bash
# åŸºæœ¬åŠŸèƒ½æ¸¬è©¦
python process_cli.py validate
python process_cli.py stats

# å®Œæ•´åŠŸèƒ½æ¸¬è©¦
python process_cli.py process --no-upload
python process_cli.py analyze-quality
```

## ğŸ“¦ ä¾è³´å’Œå®‰è£

### 1. å¿…è¦ä¾è³´
```txt
# æ ¸å¿ƒä¾è³´ (process_requirements.txt)
pandas>=1.3.0
python-dotenv>=0.19.0

# Google Sheets ä¾è³´ (å¯é¸)
gspread>=5.0.0
google-auth>=2.0.0
```

### 2. å®‰è£æŒ‡ä»¤
```bash
# åŸºæœ¬å®‰è£
pip install pandas python-dotenv

# å®Œæ•´å®‰è£ (åŒ…å« Google Sheets)
pip install pandas python-dotenv gspread google-auth
```

### 3. ç’°å¢ƒè¨­å®š
```bash
# .env æª”æ¡ˆ
GOOGLE_SHEET_ID=your_sheet_id_here
GOOGLE_SHEETS_CREDENTIALS={"type": "service_account", ...}
```

## ğŸš€ éƒ¨ç½²å’Œä½¿ç”¨

### 1. åŸºæœ¬ä½¿ç”¨æµç¨‹
```bash
# 1. æª¢æŸ¥ç’°å¢ƒ
python process_cli.py validate

# 2. æŸ¥çœ‹çµ±è¨ˆ
python process_cli.py stats

# 3. è™•ç†æª”æ¡ˆ
python process_cli.py process --no-upload

# 4. å“è³ªåˆ†æ
python process_cli.py analyze-quality
```

### 2. é«˜ç´šä½¿ç”¨æµç¨‹
```bash
# è™•ç†æœ€è¿‘æª”æ¡ˆ
python process_cli.py process-recent --hours=12

# è™•ç†å–®ä¸€å…¬å¸
python process_cli.py process-single --company=2330

# å®Œæ•´è™•ç† (åŒ…å«ä¸Šå‚³)
python process_cli.py process
```

### 3. æ•…éšœæ’é™¤
```bash
# æª¢æŸ¥æ¨¡çµ„è¼‰å…¥ç‹€æ…‹
python process_cli.py validate

# æ¸¬è©¦ Google Sheets é€£ç·š
python sheets_uploader.py --test-connection

# æª¢æŸ¥æª”æ¡ˆç‹€æ…‹
python process_cli.py stats
```

## ğŸ“‹ å¯¦ä½œæª¢æŸ¥æ¸…å–®

### âœ… å¿…é ˆå¯¦ä½œçš„åŠŸèƒ½
- [ ] `MDScanner` æª”æ¡ˆæƒæå’Œçµ±è¨ˆ
- [ ] `ProcessCLI` å‘½ä»¤åˆ—ä»‹é¢å’Œå”èª¿
- [ ] `MDParser` MD å…§å®¹è§£æ 
- [ ] `QualityAnalyzer` å“è³ªè©•åˆ†ç³»çµ±
- [ ] `ReportGenerator` å ±å‘Šç”Ÿæˆ
- [ ] `SheetsUploader` Google Sheets ä¸Šå‚³

### âœ… å¿…é ˆæ”¯æ´çš„æ ¼å¼
- [ ] 14 æ¬„ä½æŠ•è³‡çµ„åˆæ‘˜è¦æ ¼å¼
- [ ] 21 æ¬„ä½è©³ç´°å ±å‘Šæ ¼å¼
- [ ] GitHub Raw URL MD æª”æ¡ˆé€£çµ
- [ ] 0-10 æ¨™æº–åŒ–å“è³ªè©•åˆ†
- [ ] ğŸŸ¢ğŸŸ¡ğŸŸ ğŸ”´ å“è³ªç‹€æ…‹æŒ‡æ¨™

### âœ… å¿…é ˆæä¾›çš„å‘½ä»¤
- [ ] `process` - è™•ç†æ‰€æœ‰æª”æ¡ˆ
- [ ] `process-recent` - è™•ç†æœ€è¿‘æª”æ¡ˆ
- [ ] `process-single` - è™•ç†å–®ä¸€å…¬å¸
- [ ] `analyze-quality` - å“è³ªåˆ†æ
- [ ] `stats` - çµ±è¨ˆè³‡è¨Š
- [ ] `validate` - ç’°å¢ƒé©—è­‰

### âœ… å¿…é ˆè™•ç†çš„éŒ¯èª¤
- [ ] æ¨¡çµ„è¼‰å…¥å¤±æ•— (graceful degradation)
- [ ] æª”æ¡ˆä¸å­˜åœ¨æˆ–æ ¼å¼éŒ¯èª¤
- [ ] Google Sheets é€£ç·šå¤±æ•—
- [ ] è§£æéŒ¯èª¤å’Œè³‡æ–™å“è³ªå•é¡Œ

---

**v3.5.0 Process Group ç¸½çµ**: é€™æ˜¯ä¸€å€‹å®Œå…¨ç¨ç«‹çš„è™•ç†ç¾¤çµ„ï¼Œé€éæª”æ¡ˆå¤¾ä»‹é¢èˆ‡ Search Group é€šè¨Šï¼Œæ¯å€‹æª”æ¡ˆå°ˆæ³¨å–®ä¸€è·è²¬ï¼Œæ”¯æ´å®Œæ•´çš„è²¡å‹™è³‡æ–™è™•ç†æµç¨‹ï¼Œå¾ MD æª”æ¡ˆæƒæåˆ° Google Sheets å ±å‘Šç”Ÿæˆã€‚