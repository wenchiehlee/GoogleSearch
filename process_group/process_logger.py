#!/usr/bin/env python3
"""
Process Logger - FactSet Pipeline v3.6.1
æ—¥èªŒç³»çµ± (å¯é¸) - ~120 è¡Œ
"""

import os
import logging
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

class ProcessLogger:
    """è™•ç†ç¾¤çµ„æ—¥èªŒç³»çµ± - v3.6.1 å¯é¸çµ„ä»¶"""
    
    def __init__(self, log_dir="logs/process", enable_file_logging=True, enable_console_logging=True):
        """åˆå§‹åŒ–æ—¥èªŒç³»çµ±"""
        self.log_dir = log_dir
        self.enable_file_logging = enable_file_logging
        self.enable_console_logging = enable_console_logging
        
        # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
        Path(self.log_dir).mkdir(parents=True, exist_ok=True)
        
        # è¨­å®šæ—¥èªŒæ ¼å¼
        self.log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        self.date_format = '%Y-%m-%d %H:%M:%S'
        
        # åˆå§‹åŒ– logger
        self.logger = self._setup_logger()
        
        # æ“ä½œçµ±è¨ˆ
        self.operation_stats = {
            'start_time': datetime.now().isoformat(),
            'operations_logged': 0,
            'errors_logged': 0,
            'warnings_logged': 0
        }
        
        self.info("ProcessLogger v3.6.1 å·²åˆå§‹åŒ–")

    def _setup_logger(self) -> logging.Logger:
        """è¨­å®š logger"""
        logger = logging.getLogger('FactSetProcess')
        logger.setLevel(logging.DEBUG)
        
        # æ¸…é™¤ç¾æœ‰çš„ handlers
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # æª”æ¡ˆæ—¥èªŒ handler
        if self.enable_file_logging:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_file = os.path.join(self.log_dir, f'process_log_{timestamp}.log')
            
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setLevel(logging.DEBUG)
            file_formatter = logging.Formatter(self.log_format, self.date_format)
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)
        
        # æ§åˆ¶å°æ—¥èªŒ handler
        if self.enable_console_logging:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_formatter = logging.Formatter('%(levelname)s: %(message)s')
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)
        
        return logger

    def info(self, message: str, extra_data: Optional[Dict] = None):
        """è¨˜éŒ„ä¿¡æ¯"""
        self._log_with_stats(logging.INFO, message, extra_data)

    def warning(self, message: str, extra_data: Optional[Dict] = None):
        """è¨˜éŒ„è­¦å‘Š"""
        self.operation_stats['warnings_logged'] += 1
        self._log_with_stats(logging.WARNING, message, extra_data)

    def error(self, message: str, extra_data: Optional[Dict] = None):
        """è¨˜éŒ„éŒ¯èª¤"""
        self.operation_stats['errors_logged'] += 1
        self._log_with_stats(logging.ERROR, message, extra_data)

    def debug(self, message: str, extra_data: Optional[Dict] = None):
        """è¨˜éŒ„èª¿è©¦ä¿¡æ¯"""
        self._log_with_stats(logging.DEBUG, message, extra_data)

    def _log_with_stats(self, level: int, message: str, extra_data: Optional[Dict] = None):
        """è¨˜éŒ„æ—¥èªŒä¸¦æ›´æ–°çµ±è¨ˆ"""
        self.operation_stats['operations_logged'] += 1
        
        # å¦‚æœæœ‰é¡å¤–æ•¸æ“šï¼Œæ ¼å¼åŒ–è¨Šæ¯
        if extra_data:
            formatted_message = f"{message} | Data: {json.dumps(extra_data, default=str, ensure_ascii=False)}"
        else:
            formatted_message = message
        
        self.logger.log(level, formatted_message)

    def log_company_processing(self, company_code: str, company_name: str, 
                             status: str, quality_score: float, **kwargs):
        """è¨˜éŒ„å…¬å¸è™•ç†ç‹€æ…‹"""
        extra_data = {
            'company_code': company_code,
            'company_name': company_name,
            'status': status,
            'quality_score': quality_score,
            **kwargs
        }
        
        if status == 'success':
            self.info(f"âœ… å…¬å¸è™•ç†æˆåŠŸ: {company_name} ({company_code}) - å“è³ª: {quality_score}", extra_data)
        elif status == 'warning':
            self.warning(f"âš ï¸ å…¬å¸è™•ç†æœ‰è­¦å‘Š: {company_name} ({company_code})", extra_data)
        else:
            self.error(f"âŒ å…¬å¸è™•ç†å¤±æ•—: {company_name} ({company_code})", extra_data)

    def log_validation_result(self, company_code: str, validation_result: Dict):
        """è¨˜éŒ„é©—è­‰çµæœ"""
        validation_status = validation_result.get('overall_status', 'unknown')
        validation_errors = validation_result.get('errors', [])
        
        extra_data = {
            'company_code': company_code,
            'validation_result': validation_result
        }
        
        if validation_status == 'valid':
            self.info(f"âœ… é©—è­‰é€šé: {company_code}", extra_data)
        elif validation_status == 'error':
            error_preview = str(validation_errors[0])[:50] if validation_errors else "æœªçŸ¥éŒ¯èª¤"
            self.error(f"âŒ é©—è­‰å¤±æ•—: {company_code} - {error_preview}...", extra_data)
        else:
            self.warning(f"âš ï¸ é©—è­‰ç‹€æ…‹æœªçŸ¥: {company_code}", extra_data)

    def log_keyword_analysis(self, total_keywords: int, unique_keywords: int, 
                           top_keywords: list, **kwargs):
        """è¨˜éŒ„é—œéµå­—åˆ†æçµæœ"""
        extra_data = {
            'total_keywords': total_keywords,
            'unique_keywords': unique_keywords,
            'top_keywords': top_keywords[:5],  # åªè¨˜éŒ„å‰5å€‹
            **kwargs
        }
        
        self.info(f"ğŸ” é—œéµå­—åˆ†æå®Œæˆ: ç¸½æ•¸ {total_keywords}, å”¯ä¸€ {unique_keywords}", extra_data)

    def log_watchlist_analysis(self, total_companies: int, coverage_rate: float, 
                             success_rate: float, **kwargs):
        """è¨˜éŒ„è§€å¯Ÿåå–®åˆ†æçµæœ"""
        extra_data = {
            'total_companies': total_companies,
            'coverage_rate': coverage_rate,
            'success_rate': success_rate,
            **kwargs
        }
        
        self.info(f"ğŸ“‹ è§€å¯Ÿåå–®åˆ†æå®Œæˆ: {total_companies} å®¶å…¬å¸, è¦†è“‹ç‡ {coverage_rate}%, æˆåŠŸç‡ {success_rate}%", extra_data)

    def log_report_generation(self, report_type: str, record_count: int, 
                            file_path: str, **kwargs):
        """è¨˜éŒ„å ±å‘Šç”Ÿæˆ"""
        extra_data = {
            'report_type': report_type,
            'record_count': record_count,
            'file_path': file_path,
            **kwargs
        }
        
        self.info(f"ğŸ“„ å ±å‘Šç”Ÿæˆå®Œæˆ: {report_type} ({record_count} ç­†è¨˜éŒ„) -> {file_path}", extra_data)

    def log_sheets_upload(self, report_type: str, success: bool, **kwargs):
        """è¨˜éŒ„ Google Sheets ä¸Šå‚³"""
        extra_data = {
            'report_type': report_type,
            'success': success,
            **kwargs
        }
        
        if success:
            self.info(f"â˜ï¸ Google Sheets ä¸Šå‚³æˆåŠŸ: {report_type}", extra_data)
        else:
            self.error(f"âŒ Google Sheets ä¸Šå‚³å¤±æ•—: {report_type}", extra_data)

    def get_stats(self) -> Dict[str, Any]:
        """å–å¾—æ—¥èªŒçµ±è¨ˆ"""
        current_time = datetime.now()
        start_time = datetime.fromisoformat(self.operation_stats['start_time'])
        duration = current_time - start_time
        
        return {
            **self.operation_stats,
            'current_time': current_time.isoformat(),
            'duration_seconds': duration.total_seconds(),
            'log_directory': self.log_dir,
            'file_logging_enabled': self.enable_file_logging,
            'console_logging_enabled': self.enable_console_logging
        }

    def save_stats(self):
        """å„²å­˜çµ±è¨ˆè³‡è¨Š"""
        stats = self.get_stats()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        stats_file = os.path.join(self.log_dir, f'process_stats_{timestamp}.json')
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
        
        self.info(f"ğŸ“Š çµ±è¨ˆè³‡è¨Šå·²å„²å­˜: {stats_file}")
        return stats_file

    def close(self):
        """é—œé–‰æ—¥èªŒç³»çµ±"""
        # è¨˜éŒ„æœ€çµ‚çµ±è¨ˆ
        final_stats = self.get_stats()
        self.info(f"ğŸ“Š ProcessLogger é—œé–‰ - ç¸½æ“ä½œ: {final_stats['operations_logged']}, éŒ¯èª¤: {final_stats['errors_logged']}, è­¦å‘Š: {final_stats['warnings_logged']}")
        
        # å„²å­˜çµ±è¨ˆ
        self.save_stats()
        
        # é—œé–‰æ‰€æœ‰ handlers
        for handler in self.logger.handlers[:]:
            handler.close()
            self.logger.removeHandler(handler)


# å…¨åŸŸ logger å¯¦ä¾‹ (å¯é¸ä½¿ç”¨)
_global_logger: Optional[ProcessLogger] = None

def get_logger() -> ProcessLogger:
    """å–å¾—å…¨åŸŸ logger å¯¦ä¾‹"""
    global _global_logger
    if _global_logger is None:
        _global_logger = ProcessLogger()
    return _global_logger

def init_logger(**kwargs) -> ProcessLogger:
    """åˆå§‹åŒ–å…¨åŸŸ logger"""
    global _global_logger
    _global_logger = ProcessLogger(**kwargs)
    return _global_logger

def close_logger():
    """é—œé–‰å…¨åŸŸ logger"""
    global _global_logger
    if _global_logger:
        _global_logger.close()
        _global_logger = None


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    print("=== Process Logger æ¸¬è©¦ v3.6.1 ===")
    
    # å»ºç«‹ logger
    logger = ProcessLogger()
    
    # æ¸¬è©¦å„ç¨®æ—¥èªŒè¨˜éŒ„
    logger.info("æ¸¬è©¦ä¿¡æ¯è¨˜éŒ„")
    logger.warning("æ¸¬è©¦è­¦å‘Šè¨˜éŒ„")
    logger.error("æ¸¬è©¦éŒ¯èª¤è¨˜éŒ„")
    logger.debug("æ¸¬è©¦èª¿è©¦è¨˜éŒ„")
    
    # æ¸¬è©¦æ¥­å‹™æ—¥èªŒ
    logger.log_company_processing("2330", "å°ç©é›»", "success", 9.5, 
                                validation_passed=True, files_processed=3)
    
    logger.log_validation_result("6462", {
        'overall_status': 'valid',
        'confidence_score': 8.5,
        'warnings': []
    })
    
    logger.log_keyword_analysis(150, 45, ['factset', 'eps', 'å°ç©é›»', 'é ä¼°', 'ç›®æ¨™åƒ¹'])
    
    logger.log_watchlist_analysis(100, 85.5, 78.2, 
                                health_grade='B+', missing_companies=12)
    
    logger.log_report_generation("portfolio_summary", 50, "data/reports/portfolio_latest.csv")
    
    logger.log_sheets_upload("watchlist_summary", True, worksheet_name="Watchlist Summary")
    
    # é¡¯ç¤ºçµ±è¨ˆ
    stats = logger.get_stats()
    print(f"\nğŸ“Š æ—¥èªŒçµ±è¨ˆ:")
    print(f"   ç¸½æ“ä½œæ•¸: {stats['operations_logged']}")
    print(f"   éŒ¯èª¤æ•¸: {stats['errors_logged']}")
    print(f"   è­¦å‘Šæ•¸: {stats['warnings_logged']}")
    print(f"   é‹è¡Œæ™‚é–“: {stats['duration_seconds']:.1f} ç§’")
    
    # é—œé–‰ logger
    logger.close()
    
    print("\nâœ… Process Logger æ¸¬è©¦å®Œæˆ!")