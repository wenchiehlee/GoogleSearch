#!/usr/bin/env python3
"""
Report Generator - FactSet Pipeline v3.5.1 (Fixed - Complete Implementation)
ä¿®æ­£ detailed_report_columns å±¬æ€§å®šç¾©ä½ç½®éŒ¯èª¤
ä¿®æ­£è§€å¯Ÿåå–®é©—è­‰éæ¿¾é‚è¼¯ï¼Œæº–ç¢ºè­˜åˆ¥éœ€è¦æ’é™¤çš„è³‡æ–™
å®Œæ•´å¯¦ä½œç‰ˆæœ¬ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦åŠŸèƒ½
"""

import os
import re
import pandas as pd
import urllib.parse
from datetime import datetime
from typing import Dict, Any, List, Optional
import pytz

class ReportGenerator:
    """å ±å‘Šç”Ÿæˆå™¨ v3.5.1 - ä¿®æ­£è§€å¯Ÿåå–®é©—è­‰éæ¿¾å®Œæ•´ç‰ˆ"""
    
    def __init__(self, github_repo_base="https://raw.githubusercontent.com/wenchiehlee/GoogleSearch/refs/heads/main"):
        self.github_repo_base = github_repo_base
        self.output_dir = "data/reports"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è¨­å®šå°åŒ—æ™‚å€
        self.taipei_tz = pytz.timezone('Asia/Taipei')
        
        # æŠ•è³‡çµ„åˆæ‘˜è¦æ¬„ä½ (14 æ¬„ä½)
        self.portfolio_summary_columns = [
            'ä»£è™Ÿ', 'åç¨±', 'è‚¡ç¥¨ä»£è™Ÿ', 'MDæœ€èˆŠæ—¥æœŸ', 'MDæœ€æ–°æ—¥æœŸ', 'MDè³‡æ–™ç­†æ•¸',
            'åˆ†æå¸«æ•¸é‡', 'ç›®æ¨™åƒ¹', '2025EPSå¹³å‡å€¼', '2026EPSå¹³å‡å€¼', '2027EPSå¹³å‡å€¼',
            'å“è³ªè©•åˆ†', 'ç‹€æ…‹', 'æ›´æ–°æ—¥æœŸ'
        ]

        # ğŸ”§ ä¿®æ­£ï¼šè©³ç´°å ±å‘Šæ¬„ä½ (22 æ¬„ä½ - åŒ…å«é©—è­‰ç‹€æ…‹) - ç§»å‹•åˆ° __init__ æ–¹æ³•ä¸­
        self.detailed_report_columns = [
            'ä»£è™Ÿ', 'åç¨±', 'è‚¡ç¥¨ä»£è™Ÿ', 'MDæ—¥æœŸ', 'åˆ†æå¸«æ•¸é‡', 'ç›®æ¨™åƒ¹',
            '2025EPSæœ€é«˜å€¼', '2025EPSæœ€ä½å€¼', '2025EPSå¹³å‡å€¼',
            '2026EPSæœ€é«˜å€¼', '2026EPSæœ€ä½å€¼', '2026EPSå¹³å‡å€¼',
            '2027EPSæœ€é«˜å€¼', '2027EPSæœ€ä½å€¼', '2027EPSå¹³å‡å€¼',
            'å“è³ªè©•åˆ†', 'ç‹€æ…‹', 'é©—è­‰ç‹€æ…‹', 'MD File', 'æ›´æ–°æ—¥æœŸ'
        ]

    def _get_taipei_time(self) -> str:
        """å–å¾—å°åŒ—æ™‚é–“çš„å­—ä¸²æ ¼å¼"""
        taipei_time = datetime.now(self.taipei_tz)
        return taipei_time.strftime('%Y-%m-%d %H:%M:%S')

    def _should_include_in_report(self, company_data: Dict[str, Any]) -> bool:
        """ğŸ”§ å‘ä¸‹ç›¸å®¹æ€§ï¼šèˆŠæ–¹æ³•åç¨±çš„åˆ¥å"""
        return self._should_include_in_report_v351(company_data)

    def generate_portfolio_summary(self, processed_companies: List[Dict], filter_invalid=True) -> pd.DataFrame:
        """ğŸ”§ v3.5.1 ç”ŸæˆæŠ•è³‡çµ„åˆæ‘˜è¦ - ä¿®æ­£éæ¿¾é‚è¼¯"""
        try:
            # ğŸ”§ éæ¿¾é‚è¼¯ä¿®æ­£
            if filter_invalid:
                original_count = len(processed_companies)
                valid_companies = [c for c in processed_companies if self._should_include_in_report_v351(c)]
                filtered_count = original_count - len(valid_companies)
                
                print(f"ğŸ“Š æŠ•è³‡çµ„åˆæ‘˜è¦éæ¿¾çµæœ:")
                print(f"   åŸå§‹å…¬å¸æ•¸: {original_count}")
                print(f"   ä¿ç•™å…¬å¸æ•¸: {len(valid_companies)}")
                print(f"   éæ¿¾å…¬å¸æ•¸: {filtered_count}")
                
                # ğŸ”§ é¡¯ç¤ºéæ¿¾è©³æƒ…
                if filtered_count > 0:
                    filtered_companies = [c for c in processed_companies if not self._should_include_in_report_v351(c)]
                    print(f"   éæ¿¾åŸå› åˆ†æ:")
                    
                    filter_reasons = {}
                    for company in filtered_companies:
                        reason = self._get_filter_reason(company)
                        filter_reasons[reason] = filter_reasons.get(reason, 0) + 1
                    
                    for reason, count in filter_reasons.items():
                        print(f"     {reason}: {count} å®¶")
            else:
                valid_companies = processed_companies
                print(f"ğŸ“Š æŠ•è³‡çµ„åˆæ‘˜è¦ï¼šæœªå•Ÿç”¨éæ¿¾ï¼ŒåŒ…å«æ‰€æœ‰ {len(valid_companies)} å®¶å…¬å¸")
            
            # æŒ‰å…¬å¸åˆ†çµ„ï¼Œå–å¾—æ¯å®¶å…¬å¸çš„æœ€ä½³å“è³ªè³‡æ–™
            company_summary = {}
            
            for company_data in valid_companies:
                company_code = company_data.get('company_code', 'Unknown')
                
                if company_code not in company_summary:
                    company_summary[company_code] = {
                        'files': [],
                        'best_quality_data': None
                    }
                
                company_summary[company_code]['files'].append(company_data)
                
                # é¸æ“‡æœ€ä½³å“è³ªè³‡æ–™
                current_best = company_summary[company_code]['best_quality_data']
                
                if current_best is None:
                    company_summary[company_code]['best_quality_data'] = company_data
                else:
                    current_quality = company_data.get('quality_score', 0)
                    best_quality = current_best.get('quality_score', 0)
                    
                    if current_quality > best_quality:
                        company_summary[company_code]['best_quality_data'] = company_data
                        print(f"ğŸ”„ {company_code} æ›´æ–°æœ€ä½³å“è³ªè³‡æ–™: {best_quality:.1f} â†’ {current_quality:.1f}")
                    elif current_quality == best_quality:
                        if self._is_more_recent_content_date_only(company_data, current_best):
                            company_summary[company_code]['best_quality_data'] = company_data
                            print(f"ğŸ”„ {company_code} å“è³ªç›¸åŒ({current_quality:.1f})ï¼Œä½¿ç”¨è¼ƒæ–°æ—¥æœŸ")
            
            # ç”Ÿæˆæ‘˜è¦è³‡æ–™
            summary_rows = []
            
            for company_code, company_info in company_summary.items():
                best_data = company_info['best_quality_data']
                all_files = company_info['files']
                
                # é¡¯ç¤ºé¸æ“‡çš„è³‡æ–™è³‡è¨Š
                selected_date = self._get_content_date_only(best_data)
                selected_quality = best_data.get('quality_score', 0)
                print(f"ğŸ“Š {company_code}: é¸æ“‡å“è³ª {selected_quality:.1f} çš„è³‡æ–™ (æ—¥æœŸ: {selected_date})")
                
                # è¨ˆç®—æ—¥æœŸç¯„åœ
                oldest_date, newest_date = self._calculate_date_range_content_date_only(all_files)
                
                # ä½¿ç”¨æœ€ä½³å“è³ªè³‡æ–™ç”Ÿæˆæ‘˜è¦
                clean_code = self._clean_stock_code_for_display(company_code)
                
                summary_row = {
                    'ä»£è™Ÿ': clean_code,
                    'åç¨±': best_data.get('company_name', 'Unknown'),
                    'è‚¡ç¥¨ä»£è™Ÿ': f"{clean_code}-TW",
                    'MDæœ€èˆŠæ—¥æœŸ': oldest_date or selected_date,
                    'MDæœ€æ–°æ—¥æœŸ': newest_date or selected_date,
                    'MDè³‡æ–™ç­†æ•¸': len(all_files),
                    'åˆ†æå¸«æ•¸é‡': best_data.get('analyst_count', 0),
                    'ç›®æ¨™åƒ¹': best_data.get('target_price', ''),
                    '2025EPSå¹³å‡å€¼': self._format_eps_value(best_data.get('eps_2025_avg')),
                    '2026EPSå¹³å‡å€¼': self._format_eps_value(best_data.get('eps_2026_avg')),
                    '2027EPSå¹³å‡å€¼': self._format_eps_value(best_data.get('eps_2027_avg')),
                    'å“è³ªè©•åˆ†': best_data.get('quality_score', 0),
                    'ç‹€æ…‹': best_data.get('quality_status', 'ğŸ”´ ä¸è¶³'),
                    'æ›´æ–°æ—¥æœŸ': self._get_taipei_time()
                }
                
                summary_rows.append(summary_row)
            
            # å»ºç«‹ DataFrame
            df = pd.DataFrame(summary_rows, columns=self.portfolio_summary_columns)
            df = df.sort_values('ä»£è™Ÿ')
            
            print("âœ… æŠ•è³‡çµ„åˆæ‘˜è¦å·²ä½¿ç”¨æœ€ä½³å“è³ªè³‡æ–™ç”Ÿæˆ")
            
            return df
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ•è³‡çµ„åˆæ‘˜è¦å¤±æ•—: {e}")
            return pd.DataFrame(columns=self.portfolio_summary_columns)

    def generate_detailed_report(self, processed_companies: List[Dict], filter_invalid=True) -> pd.DataFrame:
        """ğŸ”§ v3.5.1 ç”Ÿæˆè©³ç´°å ±å‘Š - ä¿®æ­£éæ¿¾é‚è¼¯"""
        try:
            detailed_rows = []
            filtered_count = 0
            
            for company_data in processed_companies:
                # ğŸ”§ æª¢æŸ¥æ˜¯å¦æ‡‰è©²éæ¿¾æ­¤è³‡æ–™
                if filter_invalid and not self._should_include_in_report_v351(company_data):
                    filtered_count += 1
                    print(f"ğŸš« éæ¿¾æ‰: {company_data.get('company_name', 'Unknown')}({company_data.get('company_code', 'Unknown')}) - é©—è­‰å¤±æ•—")
                    continue
                
                # åŸæœ‰çš„å ±å‘Šç”Ÿæˆé‚è¼¯
                md_date = self._get_content_date_only(company_data)
                
                # ç”Ÿæˆé©—è­‰ç‹€æ…‹æ¨™è¨˜
                validation_status = self._generate_validation_status_marker_v351(company_data)
                
                # è™•ç† MD æª”æ¡ˆé€£çµ
                md_file_url = self._format_md_file_url_with_warning(company_data)
                
                detailed_row = {
                    'ä»£è™Ÿ': company_data.get('company_code', 'Unknown'),
                    'åç¨±': company_data.get('company_name', 'Unknown'),
                    'è‚¡ç¥¨ä»£è™Ÿ': f"{company_data.get('company_code', 'Unknown')}-TW",
                    'MDæ—¥æœŸ': md_date,
                    'åˆ†æå¸«æ•¸é‡': company_data.get('analyst_count', 0),
                    'ç›®æ¨™åƒ¹': company_data.get('target_price', ''),
                    '2025EPSæœ€é«˜å€¼': self._format_eps_value(company_data.get('eps_2025_high')),
                    '2025EPSæœ€ä½å€¼': self._format_eps_value(company_data.get('eps_2025_low')),
                    '2025EPSå¹³å‡å€¼': self._format_eps_value(company_data.get('eps_2025_avg')),
                    '2026EPSæœ€é«˜å€¼': self._format_eps_value(company_data.get('eps_2026_high')),
                    '2026EPSæœ€ä½å€¼': self._format_eps_value(company_data.get('eps_2026_low')),
                    '2026EPSå¹³å‡å€¼': self._format_eps_value(company_data.get('eps_2026_avg')),
                    '2027EPSæœ€é«˜å€¼': self._format_eps_value(company_data.get('eps_2027_high')),
                    '2027EPSæœ€ä½å€¼': self._format_eps_value(company_data.get('eps_2027_low')),
                    '2027EPSå¹³å‡å€¼': self._format_eps_value(company_data.get('eps_2027_avg')),
                    'å“è³ªè©•åˆ†': company_data.get('quality_score', 0),
                    'ç‹€æ…‹': company_data.get('quality_status', 'ğŸ”´ ä¸è¶³'),
                    'é©—è­‰ç‹€æ…‹': validation_status,
                    'MD File': md_file_url,
                    'æ›´æ–°æ—¥æœŸ': self._get_taipei_time()
                }
                
                detailed_rows.append(detailed_row)
            
            # å»ºç«‹ DataFrame
            df = pd.DataFrame(detailed_rows, columns=self.detailed_report_columns)
            df = df.sort_values(['ä»£è™Ÿ', 'MDæ—¥æœŸ'], ascending=[True, False])
            
            # è¨˜éŒ„éæ¿¾çµ±è¨ˆ
            if filter_invalid and filtered_count > 0:
                print(f"ğŸ“Š è©³ç´°å ±å‘Šéæ¿¾äº† {filtered_count} ç­†é©—è­‰å¤±æ•—çš„è³‡æ–™")
            
            print(f"ğŸ“Š è©³ç´°å ±å‘ŠåŒ…å« {len(detailed_rows)} ç­†æœ‰æ•ˆè³‡æ–™")
            
            return df
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè©³ç´°å ±å‘Šå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame(columns=self.detailed_report_columns)

    def _should_include_in_report_v351(self, company_data: Dict[str, Any]) -> bool:
        """ğŸ”§ v3.5.1 ä¿®æ­£ç‰ˆåˆ¤æ–·æ˜¯å¦æ‡‰è©²å°‡æ­¤è³‡æ–™åŒ…å«åœ¨å ±å‘Šä¸­"""
        
        # ğŸ”§ æª¢æŸ¥ 1: åŸºæœ¬è³‡æ–™å®Œæ•´æ€§
        company_code = company_data.get('company_code')
        company_name = company_data.get('company_name')
        
        if not company_code or company_code == 'Unknown':
            print(f"ğŸ“ æ’é™¤ç¼ºå°‘å…¬å¸ä»£è™Ÿçš„è³‡æ–™: {company_name}")
            return False
        
        if not company_name or company_name == 'Unknown':
            print(f"ğŸ“ æ’é™¤ç¼ºå°‘å…¬å¸åç¨±çš„è³‡æ–™: {company_code}")
            return False
        
        # ğŸ”§ æª¢æŸ¥ 2: é©—è­‰çµæœæª¢æŸ¥ (å¤šå±¤æª¢æŸ¥)
        validation_result = company_data.get('validation_result', {})
        validation_status = validation_result.get('overall_status', 'unknown')
        validation_method = validation_result.get('validation_method', 'unknown')
        
        # ğŸ”§ æª¢æŸ¥ validation_result ä¸­çš„éŒ¯èª¤ç‹€æ…‹
        if validation_status == 'error':
            validation_errors = validation_result.get('errors', [])
            if validation_errors:
                main_error = str(validation_errors[0])
                print(f"ğŸš¨ æ’é™¤é©—è­‰éŒ¯èª¤ (validation_result): {company_name}({company_code}) - {main_error[:60]}...")
                return False
        
        # ğŸ”§ æª¢æŸ¥ 3: content_validation_passed å­—æ®µ
        validation_passed = company_data.get('content_validation_passed', True)
        if not validation_passed:
            validation_errors = company_data.get('validation_errors', [])
            main_error = str(validation_errors[0]) if validation_errors else "é©—è­‰å¤±æ•—"
            print(f"ğŸš¨ æ’é™¤é©—è­‰å¤±æ•— (content_validation_passed): {company_name}({company_code}) - {main_error[:60]}...")
            return False
        
        # ğŸ”§ æª¢æŸ¥ 4: ç›´æ¥æª¢æŸ¥ validation_errors ä¸­çš„é—œéµéŒ¯èª¤
        validation_errors = company_data.get('validation_errors', [])
        if validation_errors:
            critical_error_keywords = [
                'ä¸åœ¨è§€å¯Ÿåå–®ä¸­',
                'å…¬å¸åç¨±ä¸ç¬¦è§€å¯Ÿåå–®',
                'è§€å¯Ÿåå–®é¡¯ç¤ºæ‡‰ç‚º',
                'æ„›æ´¾å¸.*æ„›ç«‹ä¿¡',
                'æ„›ç«‹ä¿¡.*æ„›æ´¾å¸',
                'å…¬å¸ä»£è™Ÿæ ¼å¼ç„¡æ•ˆ'
            ]
            
            for error in validation_errors:
                error_str = str(error)
                if any(re.search(keyword, error_str, re.IGNORECASE) for keyword in critical_error_keywords):
                    print(f"ğŸš¨ æ’é™¤é—œéµé©—è­‰éŒ¯èª¤: {company_name}({company_code}) - {error_str[:60]}...")
                    return False
        
        # ğŸ”§ æª¢æŸ¥ 5: å“è³ªè©•åˆ†ç‚º 0 ä¸”æœ‰ âŒ é©—è­‰å¤±æ•—ç‹€æ…‹
        quality_score = company_data.get('quality_score', 0)
        quality_status = company_data.get('quality_status', '')
        
        if quality_score == 0 and 'âŒ é©—è­‰å¤±æ•—' in quality_status:
            print(f"ğŸš¨ æ’é™¤ 0 åˆ†é©—è­‰å¤±æ•—: {company_name}({company_code}) - å“è³ªè©•åˆ†ç‚º 0 ä¸”ç‹€æ…‹ç‚ºé©—è­‰å¤±æ•—")
            return False
        
        # ğŸ”§ æª¢æŸ¥ 6: é¡å¤–çš„å“è³ªç‹€æ…‹æª¢æŸ¥
        if 'âŒ' in quality_status and quality_score <= 1.0:
            print(f"ğŸš¨ æ’é™¤æ¥µä½å“è³ªè©•åˆ†: {company_name}({company_code}) - å“è³ªè©•åˆ†: {quality_score}, ç‹€æ…‹: {quality_status}")
            return False
        
        # é€šéæ‰€æœ‰æª¢æŸ¥
        return True

    def _get_filter_reason(self, company_data: Dict[str, Any]) -> str:
        """ğŸ”§ v3.5.1 å–å¾—éæ¿¾åŸå› """
        company_code = company_data.get('company_code', 'Unknown')
        company_name = company_data.get('company_name', 'Unknown')
        
        # æª¢æŸ¥åŸºæœ¬è³‡æ–™
        if not company_code or company_code == 'Unknown':
            return "ç¼ºå°‘å…¬å¸ä»£è™Ÿ"
        if not company_name or company_name == 'Unknown':
            return "ç¼ºå°‘å…¬å¸åç¨±"
        
        # æª¢æŸ¥é©—è­‰éŒ¯èª¤
        validation_errors = company_data.get('validation_errors', [])
        if validation_errors:
            main_error = str(validation_errors[0])
            if "ä¸åœ¨è§€å¯Ÿåå–®" in main_error:
                return "ä¸åœ¨è§€å¯Ÿåå–®"
            elif "å…¬å¸åç¨±ä¸ç¬¦è§€å¯Ÿåå–®" in main_error or "è§€å¯Ÿåå–®é¡¯ç¤ºæ‡‰ç‚º" in main_error:
                return "è§€å¯Ÿåå–®åç¨±ä¸ç¬¦"
            elif "æ„›æ´¾å¸" in main_error or "æ„›ç«‹ä¿¡" in main_error:
                return "å…¬å¸åç¨±æ··äº‚"
            elif "æ ¼å¼ç„¡æ•ˆ" in main_error:
                return "æ ¼å¼ç„¡æ•ˆ"
            else:
                return "å…¶ä»–é©—è­‰éŒ¯èª¤"
        
        # æª¢æŸ¥é©—è­‰ç‹€æ…‹
        validation_passed = company_data.get('content_validation_passed', True)
        if not validation_passed:
            return "é©—è­‰å¤±æ•—"
        
        # æª¢æŸ¥å“è³ªè©•åˆ†
        quality_score = company_data.get('quality_score', 0)
        quality_status = company_data.get('quality_status', '')
        
        if quality_score == 0 and 'âŒ' in quality_status:
            return "å“è³ªè©•åˆ†ç‚º 0"
        
        return "æœªçŸ¥åŸå› "

    def _generate_validation_status_marker_v351(self, company_data: Dict[str, Any]) -> str:
        """ğŸ”§ v3.5.1 ç”Ÿæˆé©—è­‰ç‹€æ…‹æ¨™è¨˜"""
        validation_result = company_data.get('validation_result', {})
        validation_status = validation_result.get('overall_status', 'unknown')
        validation_method = validation_result.get('validation_method', 'unknown')
        validation_passed = company_data.get('content_validation_passed', True)
        validation_errors = company_data.get('validation_errors', [])
        validation_warnings = company_data.get('validation_warnings', [])
        validation_enabled = company_data.get('validation_enabled', False)
        
        # ğŸ”§ å¤šå±¤é©—è­‰ç‹€æ…‹åˆ¤æ–·
        if validation_status == 'error' or not validation_passed:
            # æª¢æŸ¥éŒ¯èª¤é¡å‹
            if validation_errors:
                main_error = str(validation_errors[0])
                if "ä¸åœ¨è§€å¯Ÿåå–®" in main_error:
                    return "ğŸš« ä¸åœ¨è§€å¯Ÿåå–®"
                elif "å…¬å¸åç¨±ä¸ç¬¦è§€å¯Ÿåå–®" in main_error:
                    return "ğŸ“ åç¨±ä¸ç¬¦"
                elif "æ„›æ´¾å¸" in main_error or "æ„›ç«‹ä¿¡" in main_error:
                    return "ğŸ”„ åç¨±æ··äº‚"
                else:
                    return "âŒ é©—è­‰å¤±æ•—"
            else:
                return "âŒ é©—è­‰å¤±æ•—"
        
        elif validation_method == 'disabled' or not validation_enabled:
            return "âš ï¸ é©—è­‰åœç”¨"
        
        elif validation_warnings:
            return "âš ï¸ æœ‰è­¦å‘Š"
        
        else:
            return "âœ… é€šé"

    def generate_validation_report(self, processed_companies: List[Dict]) -> pd.DataFrame:
        """ğŸ”§ v3.5.1 ç”Ÿæˆå°ˆé–€çš„é©—è­‰å ±å‘Š"""
        try:
            validation_rows = []
            
            for company_data in processed_companies:
                validation_result = company_data.get('validation_result', {})
                
                validation_row = {
                    'ä»£è™Ÿ': company_data.get('company_code', 'Unknown'),
                    'åç¨±': company_data.get('company_name', 'Unknown'),
                    'æª”æ¡ˆåç¨±': company_data.get('filename', ''),
                    'é©—è­‰ç‹€æ…‹': validation_result.get('overall_status', 'unknown'),
                    'é©—è­‰æ–¹æ³•': validation_result.get('validation_method', 'unknown'),
                    'ä¿¡å¿ƒåˆ†æ•¸': validation_result.get('confidence_score', 0),
                    'éŒ¯èª¤æ•¸é‡': len(company_data.get('validation_errors', [])),
                    'è­¦å‘Šæ•¸é‡': len(company_data.get('validation_warnings', [])),
                    'å“è³ªè©•åˆ†': company_data.get('quality_score', 0),
                    'åŒ…å«åœ¨å ±å‘Š': self._should_include_in_report_v351(company_data),
                    'éæ¿¾åŸå› ': self._get_filter_reason(company_data) if not self._should_include_in_report_v351(company_data) else "ç„¡",
                    'ä¸»è¦å•é¡Œ': self._get_main_validation_issue(company_data),
                    'æª¢æŸ¥æ™‚é–“': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                validation_rows.append(validation_row)
            
            # å»ºç«‹ DataFrame
            validation_columns = [
                'ä»£è™Ÿ', 'åç¨±', 'æª”æ¡ˆåç¨±', 'é©—è­‰ç‹€æ…‹', 'é©—è­‰æ–¹æ³•', 'ä¿¡å¿ƒåˆ†æ•¸', 'éŒ¯èª¤æ•¸é‡', 
                'è­¦å‘Šæ•¸é‡', 'å“è³ªè©•åˆ†', 'åŒ…å«åœ¨å ±å‘Š', 'éæ¿¾åŸå› ', 'ä¸»è¦å•é¡Œ', 'æª¢æŸ¥æ™‚é–“'
            ]
            
            df = pd.DataFrame(validation_rows, columns=validation_columns)
            df = df.sort_values(['åŒ…å«åœ¨å ±å‘Š', 'é©—è­‰ç‹€æ…‹', 'ä¿¡å¿ƒåˆ†æ•¸'], ascending=[False, True, False])
            
            return df
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé©—è­‰å ±å‘Šå¤±æ•—: {e}")
            return pd.DataFrame()

    def _get_main_validation_issue(self, company_data: Dict[str, Any]) -> str:
        """å–å¾—ä¸»è¦é©—è­‰å•é¡Œ"""
        validation_errors = company_data.get('validation_errors', [])
        validation_warnings = company_data.get('validation_warnings', [])
        
        if validation_errors:
            main_error = str(validation_errors[0])[:80]
            return main_error + "..." if len(str(validation_errors[0])) > 80 else main_error
        
        elif validation_warnings:
            main_warning = str(validation_warnings[0])[:80]
            return main_warning + "..." if len(str(validation_warnings[0])) > 80 else main_warning
        
        else:
            return "ç„¡å•é¡Œ"

    def _clean_stock_code_for_display(self, code):
        """æ¸…ç†è‚¡ç¥¨ä»£è™Ÿï¼Œç¢ºä¿é¡¯ç¤ºç‚ºç´”æ•¸å­—ï¼ˆç„¡å¼•è™Ÿï¼‰"""
        if pd.isna(code) or code is None or code == '':
            return ''
        
        code_str = str(code).strip()
        
        # ç§»é™¤ä»»ä½•ç¾æœ‰çš„å‰å°å–®å¼•è™Ÿ
        if code_str.startswith("'"):
            code_str = code_str[1:]
        
        # å¦‚æœæ˜¯ç´”æ•¸å­—ï¼Œç›´æ¥è¿”å›ï¼ˆè®“ Google Sheets ç•¶ä½œæ•¸å­—è™•ç†ï¼‰
        if code_str.isdigit():
            return code_str
        
        return code_str

    def _format_md_file_url_with_warning(self, company_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ– MD æª”æ¡ˆé€£çµ"""
        filename = company_data.get('filename', '')
        
        if not filename:
            return ""
        
        # ç¢ºä¿æª”æ¡ˆåç¨±æœ‰ .md å‰¯æª”å
        if not filename.endswith('.md'):
            filename += '.md'
        
        # URL ç·¨ç¢¼æª”æ¡ˆåç¨±
        encoded_filename = urllib.parse.quote(filename, safe='')
        raw_url = f"{self.github_repo_base}/data/md/{encoded_filename}"
        
        return raw_url

    def _get_content_date_only(self, company_data: Dict[str, Any]) -> str:
        """çµ•å°åªä½¿ç”¨ content_dateï¼Œç„¡ä»»ä½• fallback"""
        content_date = company_data.get('content_date')
        
        if content_date and str(content_date).strip() and str(content_date).strip().lower() != 'none':
            try:
                if isinstance(content_date, str) and '/' in content_date:
                    parts = content_date.split('/')
                    if len(parts) == 3:
                        year, month, day = parts
                        if (year.isdigit() and month.isdigit() and day.isdigit() and
                            1900 <= int(year) <= 2100 and 1 <= int(month) <= 12 and 1 <= int(day) <= 31):
                            return f"{year}-{int(month):02d}-{int(day):02d}"
                
                elif isinstance(content_date, datetime):
                    return content_date.strftime('%Y-%m-%d')
                    
            except Exception as e:
                pass
        
        return ""

    def _calculate_date_range_content_date_only(self, all_files: List[Dict]) -> tuple:
        """è¨ˆç®—æ—¥æœŸç¯„åœ - åªè€ƒæ…®æœ‰ content_date çš„æª”æ¡ˆ"""
        valid_dates = []
        
        for file_data in all_files:
            content_date = self._get_content_date_only(file_data)
            if content_date:
                valid_dates.append(content_date)
        
        if valid_dates:
            valid_dates.sort()
            return valid_dates[0], valid_dates[-1]
        
        return "", ""

    def _is_more_recent_content_date_only(self, data1: Dict, data2: Dict) -> bool:
        """æ¯”è¼ƒå…©ç­†è³‡æ–™çš„æ–°èˆŠ - åªç”¨ content_date"""
        date1 = self._get_content_date_only(data1)
        date2 = self._get_content_date_only(data2)
        
        if not date1 and not date2:
            return True
        
        if date1 and not date2:
            return True
        if date2 and not date1:
            return False
        
        try:
            dt1 = datetime.strptime(date1, '%Y-%m-%d')
            dt2 = datetime.strptime(date2, '%Y-%m-%d')
            return dt1 > dt2
        except:
            return True

    def _format_eps_value(self, eps_value) -> str:
        """æ ¼å¼åŒ– EPS æ•¸å€¼"""
        if eps_value is None or eps_value == '':
            return ''
        try:
            eps = float(eps_value)
            return f"{eps:.2f}"
        except (ValueError, TypeError):
            return str(eps_value)

    def save_reports(self, portfolio_df: pd.DataFrame, detailed_df: pd.DataFrame, validation_df: pd.DataFrame = None) -> Dict[str, str]:
        """ğŸ”§ v3.5.1 å„²å­˜å ±å‘Šç‚º CSV - å¯é¸åŒ…å«é©—è­‰å ±å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æª”æ¡ˆè·¯å¾‘
        portfolio_path = os.path.join(self.output_dir, f'portfolio_summary_v351_{timestamp}.csv')
        detailed_path = os.path.join(self.output_dir, f'detailed_report_v351_{timestamp}.csv')
        latest_portfolio_path = os.path.join(self.output_dir, 'portfolio_summary_latest.csv')
        latest_detailed_path = os.path.join(self.output_dir, 'detailed_report_latest.csv')
        
        try:
            # ç¢ºä¿ç©ºå­—ç¬¦ä¸²åœ¨ CSV ä¸­æ­£ç¢ºè™•ç†
            portfolio_df_clean = portfolio_df.copy()
            detailed_df_clean = detailed_df.copy()
            
            portfolio_df_clean = portfolio_df_clean.replace('', pd.NA)
            detailed_df_clean = detailed_df_clean.replace('', pd.NA)
            
            # å„²å­˜ä¸»è¦å ±å‘Š
            portfolio_df_clean.to_csv(portfolio_path, index=False, encoding='utf-8-sig')
            detailed_df_clean.to_csv(detailed_path, index=False, encoding='utf-8-sig')
            portfolio_df_clean.to_csv(latest_portfolio_path, index=False, encoding='utf-8-sig')
            detailed_df_clean.to_csv(latest_detailed_path, index=False, encoding='utf-8-sig')
            
            saved_files = {
                'portfolio_summary': portfolio_path,
                'detailed_report': detailed_path,
                'portfolio_summary_latest': latest_portfolio_path,
                'detailed_report_latest': latest_detailed_path
            }
            
            # å„²å­˜é©—è­‰å ±å‘Š
            if validation_df is not None and not validation_df.empty:
                validation_path = os.path.join(self.output_dir, f'validation_report_v351_{timestamp}.csv')
                latest_validation_path = os.path.join(self.output_dir, 'validation_report_latest.csv')
                
                validation_df_clean = validation_df.replace('', pd.NA)
                validation_df_clean.to_csv(validation_path, index=False, encoding='utf-8-sig')
                validation_df_clean.to_csv(latest_validation_path, index=False, encoding='utf-8-sig')
                
                saved_files['validation_report'] = validation_path
                saved_files['validation_report_latest'] = latest_validation_path
            
            print(f"ğŸ“ v3.5.1 å ±å‘Šå·²å„²å­˜:")
            print(f"   æŠ•è³‡çµ„åˆæ‘˜è¦: {portfolio_path}")
            print(f"   è©³ç´°å ±å‘Š: {detailed_path}")
            if validation_df is not None:
                print(f"   é©—è­‰å ±å‘Š: {saved_files.get('validation_report', 'N/A')}")
            
            # æª¢æŸ¥ç©ºæ—¥æœŸè™•ç†
            empty_dates = detailed_df_clean[detailed_df_clean['MDæ—¥æœŸ'].isna()]
            if len(empty_dates) > 0:
                print(f"ğŸ“Š æª¢æ¸¬åˆ° {len(empty_dates)} å€‹ç©ºæ—¥æœŸæ¢ç›®")
            
            return saved_files
            
        except Exception as e:
            print(f"âŒ å„²å­˜å ±å‘Šå¤±æ•—: {e}")
            return {}

    def generate_statistics_report(self, processed_companies: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ğŸ”§ v3.5.1 ç”Ÿæˆçµ±è¨ˆå ±å‘Š - åŒ…å«ä¿®æ­£çš„é©—è­‰çµ±è¨ˆ"""
        total_companies = len(processed_companies)
        
        if total_companies == 0:
            return {
                'total_companies': 0,
                'companies_with_data': 0,
                'success_rate': 0
            }
        
        # åŸºæœ¬çµ±è¨ˆ
        companies_with_data = len([c for c in processed_companies if c.get('quality_score', 0) > 0])
        success_rate = (companies_with_data / total_companies) * 100
        
        # å“è³ªåˆ†æ
        quality_scores = [c.get('quality_score', 0) for c in processed_companies]
        
        # content_date æå–åˆ†æ
        companies_with_content_date = len([c for c in processed_companies if self._get_content_date_only(c)])
        content_date_success_rate = (companies_with_content_date / total_companies) * 100
        
        # ğŸ”§ v3.5.1 ä¿®æ­£çš„é©—è­‰çµ±è¨ˆ
        validation_passed = 0
        validation_failed = 0
        validation_disabled = 0
        
        for company in processed_companies:
            validation_result = company.get('validation_result', {})
            validation_method = validation_result.get('validation_method', 'unknown')
            
            if validation_method == 'disabled':
                validation_disabled += 1
            elif self._should_include_in_report_v351(company):
                validation_passed += 1
            else:
                validation_failed += 1
        
        validation_success_rate = (validation_passed / total_companies) * 100
        
        # éæ¿¾çµ±è¨ˆ
        companies_included_in_report = len([c for c in processed_companies if self._should_include_in_report_v351(c)])
        inclusion_rate = (companies_included_in_report / total_companies) * 100
        
        # ğŸ”§ é—œéµå•é¡Œçµ±è¨ˆ (æ›´æº–ç¢º)
        critical_issues = 0
        filter_reasons = {}
        
        for company in processed_companies:
            if not self._should_include_in_report_v351(company):
                critical_issues += 1
                reason = self._get_filter_reason(company)
                filter_reasons[reason] = filter_reasons.get(reason, 0) + 1
        
        statistics = {
            'version': '3.5.1_fixed_validation',
            'report_type': 'watch_list_validation_fixed',
            'timestamp': datetime.now().isoformat(),
            
            # åŸºæœ¬çµ±è¨ˆ
            'total_companies': total_companies,
            'companies_with_data': companies_with_data,
            'success_rate': round(success_rate, 1),
            'companies_with_content_date': companies_with_content_date,
            'content_date_success_rate': round(content_date_success_rate, 1),
            
            # ğŸ”§ ä¿®æ­£çš„é©—è­‰çµ±è¨ˆ
            'validation_statistics': {
                'validation_passed': validation_passed,
                'validation_failed': validation_failed,
                'validation_disabled': validation_disabled,
                'validation_success_rate': round(validation_success_rate, 1),
                'critical_issues': critical_issues,
                'companies_included_in_report': companies_included_in_report,
                'inclusion_rate': round(inclusion_rate, 1),
                'filtered_out': total_companies - companies_included_in_report,
                'filter_reasons': filter_reasons
            },
            
            # å“è³ªåˆ†æ
            'quality_analysis': {
                'average_quality_score': round(sum(quality_scores) / len(quality_scores), 1) if quality_scores else 0,
                'highest_quality_score': max(quality_scores) if quality_scores else 0,
                'lowest_quality_score': min(quality_scores) if quality_scores else 0
            }
        }
        
        return statistics

    def save_statistics_report(self, statistics: Dict[str, Any]) -> str:
        """å„²å­˜çµ±è¨ˆå ±å‘Šç‚º JSON æª”æ¡ˆ"""
        import json
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        stats_path = os.path.join(self.output_dir, f'statistics_v351_{timestamp}.json')
        latest_stats_path = os.path.join(self.output_dir, 'statistics_latest.json')
        
        try:
            with open(stats_path, 'w', encoding='utf-8') as f:
                json.dump(statistics, f, ensure_ascii=False, indent=2, default=str)
            
            with open(latest_stats_path, 'w', encoding='utf-8') as f:
                json.dump(statistics, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ“Š v3.5.1 çµ±è¨ˆå ±å‘Šå·²å„²å­˜: {stats_path}")
            
            # é¡¯ç¤ºé‡è¦çµ±è¨ˆ
            validation_stats = statistics.get('validation_statistics', {})
            print(f"ğŸ“Š é©—è­‰æˆåŠŸç‡: {validation_stats.get('validation_success_rate', 0)}%")
            print(f"ğŸ“Š å ±å‘ŠåŒ…å«ç‡: {validation_stats.get('inclusion_rate', 0)}%")
            print(f"ğŸ“Š é©—è­‰åœç”¨: {validation_stats.get('validation_disabled', 0)} å€‹")
            if validation_stats.get('critical_issues', 0) > 0:
                print(f"ğŸš¨ éæ¿¾å•é¡Œ: {validation_stats['critical_issues']} å€‹")
                filter_reasons = validation_stats.get('filter_reasons', {})
                for reason, count in filter_reasons.items():
                    print(f"   {reason}: {count} å€‹")
            
            return stats_path
            
        except Exception as e:
            print(f"âŒ å„²å­˜çµ±è¨ˆå ±å‘Šå¤±æ•—: {e}")
            return ""

    def test_filtering_logic(self, test_companies: List[Dict]) -> Dict[str, Any]:
        """ğŸ”§ v3.5.1 æ–°å¢ï¼šæ¸¬è©¦éæ¿¾é‚è¼¯çš„æ–¹æ³•"""
        test_results = {
            'total_companies': len(test_companies),
            'included_companies': [],
            'excluded_companies': [],
            'filter_reasons': {}
        }
        
        for company in test_companies:
            include = self._should_include_in_report_v351(company)
            company_name = company.get('company_name', 'Unknown')
            company_code = company.get('company_code', 'Unknown')
            
            if include:
                test_results['included_companies'].append({
                    'name': company_name,
                    'code': company_code,
                    'quality_score': company.get('quality_score', 0)
                })
            else:
                reason = self._get_filter_reason(company)
                test_results['excluded_companies'].append({
                    'name': company_name,
                    'code': company_code,
                    'reason': reason,
                    'quality_score': company.get('quality_score', 0)
                })
                test_results['filter_reasons'][reason] = test_results['filter_reasons'].get(reason, 0) + 1
        
        return test_results


# æ¸¬è©¦åŠŸèƒ½
if __name__ == "__main__":
    generator = ReportGenerator()
    
    print("=== ğŸ”’ v3.5.1 ä¿®æ­£ç‰ˆè§€å¯Ÿåå–®é©—è­‰éæ¿¾çš„å ±å‘Šç”Ÿæˆå™¨æ¸¬è©¦ ===")
    
    # æ¸¬è©¦æ•¸æ“š - åŒ…å«å„ç¨®é©—è­‰ç‹€æ…‹
    test_companies = [
        # æ­£å¸¸è³‡æ–™
        {
            'company_name': 'å°ç©é›»',
            'company_code': '2330',
            'filename': '2330_å°ç©é›»_factset_abc123.md',
            'content_date': '2025/6/24',
            'analyst_count': 42,
            'target_price': 650.5,
            'eps_2025_avg': 46.00,
            'quality_score': 10.0,
            'quality_status': 'ğŸŸ¢ å®Œæ•´',
            'content_validation_passed': True,
            'validation_enabled': True,
            'validation_result': {
                'overall_status': 'valid',
                'validation_method': 'strict',
                'confidence_score': 10.0
            },
            'validation_errors': [],
            'validation_warnings': [],
            'content_length': 5000
        },
        
        # ä¸åœ¨è§€å¯Ÿåå–®çš„éŒ¯èª¤è³‡æ–™
        {
            'company_name': 'å¨å‰›',
            'company_code': '1122',
            'filename': '1122_å¨å‰›_yahoo_def456.md',
            'content_date': '2025/6/19',
            'analyst_count': 0,
            'target_price': None,
            'eps_2025_avg': None,
            'quality_score': 0.0,
            'quality_status': 'âŒ é©—è­‰å¤±æ•—',
            'content_validation_passed': False,
            'validation_enabled': True,
            'validation_result': {
                'overall_status': 'error',
                'validation_method': 'strict',
                'errors': ['ä»£è™Ÿ1122ä¸åœ¨è§€å¯Ÿåå–®ä¸­ï¼Œä¸å…è¨±è™•ç†']
            },
            'validation_errors': ['ä»£è™Ÿ1122ä¸åœ¨è§€å¯Ÿåå–®ä¸­ï¼Œä¸å…è¨±è™•ç†'],
            'validation_warnings': [],
            'content_length': 1000
        }
    ]
    
    print("æ¸¬è©¦ 1: éæ¿¾é‚è¼¯æ¸¬è©¦")
    test_results = generator.test_filtering_logic(test_companies)
    
    print(f"   ç¸½å…¬å¸æ•¸: {test_results['total_companies']}")
    print(f"   åŒ…å«å…¬å¸: {len(test_results['included_companies'])}")
    print(f"   æ’é™¤å…¬å¸: {len(test_results['excluded_companies'])}")
    
    print("\n   åŒ…å«çš„å…¬å¸:")
    for company in test_results['included_companies']:
        print(f"     âœ… {company['name']} ({company['code']}) - å“è³ª: {company['quality_score']}")
    
    print("\n   æ’é™¤çš„å…¬å¸:")
    for company in test_results['excluded_companies']:
        print(f"     âŒ {company['name']} ({company['code']}) - åŸå› : {company['reason']}")
    
    print("\næ¸¬è©¦ 2: ç”Ÿæˆè©³ç´°å ±å‘Š")
    detailed_df = generator.generate_detailed_report(test_companies, filter_invalid=True)
    print(f"   åŸå§‹è³‡æ–™: {len(test_companies)} ç­†")
    print(f"   è©³ç´°å ±å‘ŠåŒ…å«: {len(detailed_df)} ç­†è¨˜éŒ„")
    
    expected_included = 1  # åªæœ‰å°ç©é›»
    if len(detailed_df) == expected_included:
        print(f"\nâœ… ä¿®æ­£çµæœæ­£ç¢º:")
        print(f"   å°ç©é›»: æ­£å¸¸é€šé")
        print(f"   å¨å‰›: æ­£ç¢ºéæ¿¾ (ä¸åœ¨è§€å¯Ÿåå–®)")
    else:
        print(f"\nâŒ éæ¿¾çµæœç•°å¸¸ï¼Œéœ€è¦æª¢æŸ¥é‚è¼¯")
        print(f"   é æœŸåŒ…å«: {expected_included} å®¶")
        print(f"   å¯¦éš›åŒ…å«: {len(detailed_df)} å®¶")
    
    print(f"\nğŸ‰ v3.5.1 ä¿®æ­£ç‰ˆæ¸¬è©¦å®Œæˆ!")
    print(f"ğŸ”§ detailed_report_columns å±¬æ€§å®šç¾©ä½ç½®å·²ä¿®æ­£")