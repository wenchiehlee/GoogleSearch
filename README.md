# FactSet Pipeline v3.6.1 - Two-Stage Architecture

[![Pipeline Status](https://img.shields.io/badge/Pipeline-v3.6.1-brightgreen)](https://github.com/your-repo/factset-pipeline)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20Linux%20%7C%20macOS-lightgrey)](https://github.com/your-repo/factset-pipeline)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Search Group](https://img.shields.io/badge/Search%20Group-v3.5.1-orange)](https://github.com/your-repo/factset-pipeline/tree/main/search_group)
[![Process Group](https://img.shields.io/badge/Process%20Group-v3.6.1-blue)](https://github.com/your-repo/factset-pipeline/tree/main/process_group)

## ðŸŽ¯ Overview

**FactSet Pipeline v3.6.1** is a production-ready two-stage system that automates the collection and analysis of FactSet financial data for Taiwan stock market companies, featuring **API key rotation**, **content validation**, **query pattern analysis**, and **watchlist management**.

### ðŸ—ï¸ Two-Stage Architecture

```
Stage 1: Search Group (v3.5.1)          Stage 2: Process Group (v3.6.1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“¥ StockID_TWSE_TPEX.csv (116+ Taiwan stocks) â”‚    â”‚ ðŸ“ data/md/*.md (Validated files) â”‚
â”‚          â†“                          â”‚    â”‚          â†“                       â”‚
â”‚ ðŸ” Enhanced Search + Key Rotation   â”‚    â”‚ ðŸ“Š Analysis & Report Generation  â”‚
â”‚   â”œâ”€ API Key Rotation (up to 7)     â”‚    â”‚   â”œâ”€ Quality Analysis            â”‚
â”‚   â”œâ”€ Content Validation             â”‚    â”‚   â”œâ”€ Query Pattern Analysis      â”‚
â”‚   â”œâ”€ Pure Content Hash Filenames    â”‚    â”‚   â”œâ”€ Watchlist Coverage Analysis â”‚
â”‚   â””â”€ REFINED_SEARCH_PATTERNS        â”‚    â”‚   â””â”€ Report Generation           â”‚
â”‚          â†“                          â”‚    â”‚          â†“                       â”‚
â”‚ ðŸ’¾ data/md/*.md (High quality)      â”‚â”€â”€â”€â”€â”‚ ðŸ“ˆ Google Sheets Dashboard      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŒŸ Key Features

#### Search Group (v3.5.1)
- **ðŸ”„ API Key Rotation**: Support up to 7 Google API keys with automatic rotation
- **ðŸ›¡ï¸ Content Validation**: Validate search results match target company
- **ðŸ”— Pure Content Hash**: Deterministic filenames based on content fingerprint
- **ðŸŽ¯ REFINED_SEARCH_PATTERNS**: Optimized Taiwan financial data search patterns
- **ðŸ“Š Production-Ready**: 700+ searches/day capacity with automatic quota management

#### Process Group (v3.6.1)
- **ðŸ“‹ Query Pattern Analysis**: Analyze search effectiveness with REFINED_SEARCH_PATTERNS
- **ðŸ“Š Watchlist Management**: Complete coverage analysis of StockID_TWSE_TPEX.csv companies
- **ðŸ“ˆ Quality Scoring**: Standardized 0-10 quality scoring with visual indicators
- **ðŸ“ Multiple Report Types**: Portfolio, detailed, query pattern, and watchlist reports
- **â˜ï¸ Google Sheets Integration**: Automated upload with formatted worksheets

## ðŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/your-repo/factset-pipeline.git
cd factset-pipeline

# Install dependencies
pip install -r requirements.txt

# Setup environment variables (multiple API keys supported)
cp .env.example .env
# Edit .env with your API keys (see Configuration section)
```

### 2. Two-Stage Usage

#### Stage 1: Search Group
```bash
# Navigate to search group
cd search_group

# Validate setup with API key rotation
python search_cli.py validate

# Search all companies with automatic quota management
python search_cli.py search --all --count 2 --min-quality 4

# Check search results
python search_cli.py status
```

#### Stage 2: Process Group
```bash
# Navigate to process group  
cd process_group

# Process all MD files with full analysis
python process_cli.py process

# Generate specific reports
python process_cli.py keyword-summary     # Query pattern analysis
python process_cli.py watchlist-summary   # Watchlist coverage analysis

# Analyze quality only
python process_cli.py analyze-quality
```

### 3. View Results

- **ðŸ“Š Google Sheets Dashboard**: Multi-worksheet dashboard with all reports
- **ðŸ“ Local CSV Files**: `data/reports/` with standardized formats
- **ðŸ”— MD File Access**: Direct GitHub Raw URLs for immediate file viewing
- **ðŸ“ˆ Analytics**: Quality distribution, pattern effectiveness, watchlist coverage

## ðŸ“Š System Architecture

### File Structure

```
FactSet-Pipeline/
â”œâ”€â”€ search_group/                      # ðŸ” Search Group (v3.5.1)
â”‚   â”œâ”€â”€ search_cli.py                 # CLI with key rotation support
â”‚   â”œâ”€â”€ search_engine.py              # Content validation + Taiwan search
â”‚   â”œâ”€â”€ api_manager.py                # Multiple API key management
â”‚   â””â”€â”€ README.md                     # Search group documentation
â”œâ”€â”€ process_group/                     # ðŸ“Š Process Group (v3.6.1)
â”‚   â”œâ”€â”€ process_cli.py                # Processing CLI interface
â”‚   â”œâ”€â”€ md_scanner.py                 # File system interface
â”‚   â”œâ”€â”€ md_parser.py                  # MD content + metadata parsing
â”‚   â”œâ”€â”€ quality_analyzer.py           # Quality scoring system
â”‚   â”œâ”€â”€ keyword_analyzer.py           # Query pattern analysis
â”‚   â”œâ”€â”€ watchlist_analyzer.py         # Watchlist coverage analysis
â”‚   â”œâ”€â”€ report_generator.py           # Multi-format report generation
â”‚   â”œâ”€â”€ sheets_uploader.py            # Google Sheets integration
â”‚   â””â”€â”€ README.md                     # Process group documentation
â”œâ”€â”€ data/                             # ðŸ“ Data Directory
â”‚   â”œâ”€â”€ md/                          # Generated MD files (Search â†’ Process)
â”‚   â”œâ”€â”€ reports/                     # Generated CSV reports
â”‚   â””â”€â”€ cache/                       # Search cache and progress
â”œâ”€â”€ StockID_TWSE_TPEX.csv                      # Input watchlist (116+ companies)
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ .env.example                     # Environment variables template
â””â”€â”€ README.md                        # This file
```

### Communication Pattern

```
Search Group                Process Group
     â†“                           â†‘
data/md/*.md â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
(File-based communication - no direct API calls)
```

## ðŸ”§ Configuration

### Enhanced Environment Variables

```bash
# MULTIPLE API KEYS FOR ROTATION (Search Group)
GOOGLE_SEARCH_API_KEY=your_primary_api_key_here
GOOGLE_SEARCH_CSE_ID=your_custom_search_engine_id_here

# ADDITIONAL KEYS FOR ROTATION (up to 6 more)
GOOGLE_SEARCH_API_KEY1=your_second_api_key_here
GOOGLE_SEARCH_API_KEY2=your_third_api_key_here
GOOGLE_SEARCH_API_KEY3=your_fourth_api_key_here
GOOGLE_SEARCH_API_KEY4=your_fifth_api_key_here
GOOGLE_SEARCH_API_KEY5=your_sixth_api_key_here
GOOGLE_SEARCH_API_KEY6=your_seventh_api_key_here

# GOOGLE SHEETS INTEGRATION (Process Group)
GOOGLE_SHEET_ID=your_sheet_id_here
GOOGLE_SHEETS_CREDENTIALS={"type":"service_account",...}

# PERFORMANCE TUNING
SEARCH_RATE_LIMIT_PER_SECOND=1.0
MIN_QUALITY_THRESHOLD=4
LOG_LEVEL=INFO
```

## ðŸ“ˆ Search Group (v3.5.1) Features

### API Key Rotation
- **Multiple Keys**: Support up to 7 Google Search API keys
- **Automatic Rotation**: Seamless failover on quota exceeded (429 errors)
- **Production Capacity**: 700+ searches/day (100 per key Ã— 7 keys)
- **Zero Downtime**: Continuous operation with intelligent key management

### Content Validation
- **Company Matching**: Validate search results match target company
- **Quality Override**: Automatic score 0 for wrong company content
- **Enhanced Patterns**: REFINED_SEARCH_PATTERNS optimized for Taiwan financial sites

### Pure Content Hash Filenames
```bash
# Deterministic naming based on content fingerprint
2330_å°ç©é›»_factset_7796efd2.md    # Content hash ensures perfect deduplication
2330_å°ç©é›»_factset_9c2b8e1a.md    # Different content = different hash
2454_è¯ç™¼ç§‘_factset_4f3a7d5c.md    # Each unique content gets unique filename
```

### Search Commands
```bash
# Single company with rotation
python search_cli.py search --company 2330 --count 3 --min-quality 4

# All companies with quota management
python search_cli.py search --all --count 2 --min-quality 4

# Resume interrupted searches
python search_cli.py search --resume --min-quality 4

# Check key rotation status
python search_cli.py status
```

## ðŸ“Š Process Group (v3.6.1) Features

### Query Pattern Analysis
- **REFINED_SEARCH_PATTERNS Integration**: Analyze effectiveness of standardized search patterns
- **Pattern Normalization**: Convert queries to `{name} {symbol}` format
- **Effectiveness Scoring**: Rate pattern performance with quality correlation
- **Pattern Categories**: FactSet direct, cnyes.com, EPS forecast, analyst consensus

### Watchlist Management
- **Coverage Analysis**: Track processing status of all StockID_TWSE_TPEX.csv companies
- **Status Categories**: Processed, not found, validation failed, low quality, multiple files
- **Missing Company Reports**: Identify companies needing search attention
- **Quality Statistics**: Average scores, distribution analysis per company

### Report Generation
Four comprehensive report types:

1. **Portfolio Summary** (14 columns): High-level investment overview
2. **Detailed Report** (22 columns): Complete data with validation status
3. **Query Pattern Summary** (10 columns): Search effectiveness analysis
4. **Watchlist Summary** (12 columns): Company coverage and status

### Process Commands
```bash
# Complete processing with all analysis
python process_cli.py process

# Specific analysis types
python process_cli.py analyze-keywords      # Query pattern analysis
python process_cli.py analyze-watchlist    # Watchlist coverage analysis
python process_cli.py analyze-quality      # Quality distribution analysis

# Generate specific reports
python process_cli.py keyword-summary      # Query pattern effectiveness
python process_cli.py watchlist-summary    # Company coverage status

# Processing options
python process_cli.py process-recent --hours=12    # Recent files only
python process_cli.py process-single --company=2330 # Single company
```

## ðŸ“‹ Report Formats

### 1. Portfolio Summary (14 columns)
```csv
ä»£è™Ÿ,åç¨±,è‚¡ç¥¨ä»£è™Ÿ,MDæœ€èˆŠæ—¥æœŸ,MDæœ€æ–°æ—¥æœŸ,MDè³‡æ–™ç­†æ•¸,åˆ†æžå¸«æ•¸é‡,ç›®æ¨™åƒ¹,2025EPSå¹³å‡å€¼,2026EPSå¹³å‡å€¼,2027EPSå¹³å‡å€¼,å“è³ªè©•åˆ†,ç‹€æ…‹,æ›´æ–°æ—¥æœŸ
2330,å°ç©é›»,2330-TW,2025/06/24,2025/06/24,1,42,650.5,46.00,23.56,23.56,10,ðŸŸ¢ å®Œæ•´,2025-06-24 10:45:00
```

### 2. Query Pattern Summary (10 columns)
```csv
Query pattern,ä½¿ç”¨æ¬¡æ•¸,å¹³å‡å“è³ªè©•åˆ†,æœ€é«˜å“è³ªè©•åˆ†,æœ€ä½Žå“è³ªè©•åˆ†,ç›¸é—œå…¬å¸æ•¸é‡,å“è³ªç‹€æ…‹,åˆ†é¡ž,æ•ˆæžœè©•ç´š,æ›´æ–°æ—¥æœŸ
{name} {symbol} factset åˆ†æžå¸«,30,7.89,8.7,4.3,15,ðŸŸ¡ è‰¯å¥½,FactSetç›´æŽ¥,è‰¯å¥½ â­â­,2025-06-30 13:32:00
```

### 3. Watchlist Summary (12 columns)
```csv
å…¬å¸ä»£è™Ÿ,å…¬å¸åç¨±,MDæª”æ¡ˆæ•¸é‡,è™•ç†ç‹€æ…‹,å¹³å‡å“è³ªè©•åˆ†,æœ€é«˜å“è³ªè©•åˆ†,æœå°‹é—œéµå­—æ•¸é‡,ä¸»è¦é—œéµå­—,é—œéµå­—å¹³å‡å“è³ª,æœ€æ–°æª”æ¡ˆæ—¥æœŸ,é©—è­‰ç‹€æ…‹,æ›´æ–°æ—¥æœŸ
2330,å°ç©é›»,3,âœ… å·²è™•ç†,9.2,10.0,4,å°ç©é›» factset eps é ä¼°,8.5,2025-06-24,âœ… é©—è­‰é€šéŽ,2025-06-24 10:45:00
```

## ðŸŽ¯ Quality Scoring System

### Standardized 0-10 Scale

| Score Range | Indicator | Description | Criteria |
|-------------|-----------|-------------|----------|
| **9-10** | ðŸŸ¢ å®Œæ•´ | Complete | EPS data 90%+, 20+ analysts, data â‰¤7 days |
| **8** | ðŸŸ¡ è‰¯å¥½ | Good | EPS data 70%+, 10+ analysts, data â‰¤30 days |
| **3-7** | ðŸŸ  éƒ¨åˆ† | Partial | EPS data 30%+, 5+ analysts, data â‰¤90 days |
| **0-2** | ðŸ”´ ä¸è¶³ | Insufficient | Limited or missing data |

## ðŸš¨ Troubleshooting

### Search Group Issues

```bash
# All API keys exhausted
python search_cli.py status  # Check key rotation status

# Content validation issues  
python search_cli.py search --company 2330 --count 1  # Test single company

# API connection problems
python search_cli.py validate  # Test all keys
```

### Process Group Issues

```bash
# Module loading problems
python process_cli.py validate  # Check all components

# Missing watchlist
# Ensure StockID_TWSE_TPEX.csv exists in root directory

# Google Sheets connection
# Check GOOGLE_SHEETS_CREDENTIALS in .env
```

### Common Solutions

| Issue | Solution |
|-------|----------|
| 429 Quota Exceeded | Add more API keys to .env file |
| Wrong Company Content | Content validation automatically filters these |
| Missing MD Files | Run Search Group first to generate files |
| Watchlist Not Found | Place StockID_TWSE_TPEX.csv in project root |
| Sheets Upload Failed | Verify Google Sheets credentials |

## ðŸ“ˆ Performance Metrics

### Search Group Performance
- **Throughput**: 300-700 companies/hour (with 7 keys)
- **Success Rate**: > 70% companies with quality 4+ data
- **Cache Hit Rate**: > 25% for repeated searches
- **Rotation Efficiency**: < 2 second delay per key rotation
- **Quota Utilization**: 95%+ across all keys

### Process Group Performance
- **Processing Speed**: ~50 MD files/minute
- **Report Generation**: < 30 seconds for all reports
- **Quality Analysis**: 100% validation coverage
- **Memory Usage**: < 200MB peak for 1000+ files
- **Upload Speed**: < 60 seconds to Google Sheets

## ðŸ¤ Contributing

### Development Setup

```bash
# Clone and setup
git clone https://github.com/your-repo/factset-pipeline.git
cd factset-pipeline

# Install development dependencies
pip install -r requirements-dev.txt

# Test Search Group
cd search_group
python search_cli.py validate

# Test Process Group
cd process_group  
python process_cli.py validate
```

### Testing Workflow

```bash
# 1. Test Search Group independently
cd search_group
python search_cli.py search --company 2330 --count 1

# 2. Verify MD file generation
ls ../data/md/2330*.md

# 3. Test Process Group independently
cd process_group
python process_cli.py process-single --company 2330

# 4. Verify reports generation
ls ../data/reports/
```

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ”— Documentation Links

- **ðŸ” Search Group Guide**: [search_group/README.md](search_group/README.md)
- **ðŸ“Š Process Group Guide**: [process_group/README.md](process_group/README.md)
- **ðŸ“ˆ Live Dashboard**: [Google Sheets Dashboard](https://docs.google.com/spreadsheets/d/your_sheet_id/edit)
- **ðŸ› ï¸ API Reference**: [API Documentation](docs/api.md)
- **â“ Troubleshooting**: [Troubleshooting Guide](docs/troubleshooting.md)

---

**FactSet Pipeline v3.6.1 - Two-Stage Architecture**

*A production-ready financial data automation system featuring API key rotation, content validation, query pattern analysis, and comprehensive watchlist management for Taiwan stock market analysis.*

For questions or support, please [open an issue](https://github.com/your-repo/factset-pipeline/issues) or contact the development team.